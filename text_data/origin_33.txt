b'ABSTRACT\nRecently Viola et al. [5] have introduced a rapid object detection\nscheme based on a boosted cascade of simple features. In this paper\n\nwe introduce a novel set of rotated haar-like features, which\nsignificantly enrich this basic set of simple haar-like features and\nwhich can also be calculated very efficiently. At a given hit rate our\n\nsample face detector shows off on average a 10% lower false alarm\nrate by means of using these additional rotated features. We also\npresent a novel post optimization procedure for a given boosted\n\ncascade improving on average the false alarm rate further by 12.5%.\nUsing both enhancements the number of false detections is only 24\nat a hit rate of 82.3% on the CMU face set [7].\n1  Introduction\nRecently Viola et al. have proposed a multi-stage classification\n\nprocedure that reduces the processing time substantially while\n\nachieving almost the same accuracy as compared to a much slower\nand more complex single stage classifier [5]. This paper extends\ntheir rapid object detection framework in two important ways:\n\nFirstly, their basic and over-complete set of haar-like feature is\nextended by an efficient set of 45 rotated features, which add\nadditional domain-knowledge to the learning framework and which\n\nis otherwise hard to learn. These novel features can be computed\nrapidly at all scales in constant time. Secondly, we derive a new post-\noptimization procedure for a given boosted classifier that improves\n\nits performance significantly.\n2  Feature Pool\nThe main purpose of using features instead of raw pixel values as the\n\ninput to a learning algorithm is to reduce the in-class while\nincreasing the out-of-class variability compared to the raw data and\nthus making classification easier. Features usually encode\n\nknowledge about the domain, which is difficult to learn from the raw\nand finite set of input data. A very large and general pool of simple\nhaar-like features combined with feature selection therefore can\n\nincrease the capacity of the learning algorithm. \nThe speed of feature evaluation is also a very important aspect since\nalmost all object detection algorithms slide a fixed-size window at\nall scales over the input image. As we will see, our features can be\ncomputed at any position and any scale in the same constant time.\n\nOnly 8 table lookups are needed.\n2.1 Feature Family\nOur feature pool was inspired by the over-complete haar-like\n\nfeatures used by Papageorgiou \net al\n. in [4,3] and their very fast\ncomputation scheme proposed by Viola \net al.\n in [5], and is a\ngeneralization of their work.\nLet us assume that the basic unit for testing for the presence of an\nobject is a window of  pixels. Also assume that we have a very\nfast way of computing the sum of pixels of any upright and 45\n\nrotated rectangle inside the window. A rectangle is specified by the\ntuple  with , , ,\n, and  and its pixel sum is denoted by\n. Two examples of such rectangles are given in Figure 1.\nOur raw feature set is then the set of all possible features of the form \n ,where the weights , the rectangles , and \nN are arbitrarily\nchosen.\nThis raw feature set is (almost) infinitely large. For practical reasons,\nit is reduced as follows:\n1.Only weighted combinations of pixel sums of two rectangles are\nconsidered (i.e., ).\n2.The weights have opposite signs, and are used to compensate for\nthe difference in area size between the two rectangles. Thus, for\nnon-overlapping rectangles we have\n. Without restrictions we can set\n and get .\n3.The features mimic haar-like features and early features of the\nhuman visual pathway such as center surround and directional\n\nresponses.\nThese restrictions lead us to the 14 feature prototypes shown in\nFigure 2:\nFour edge features,\nEight line features, and\nTwo center-surround features.\nThese prototypes are scaled independently in vertical and horizontal\ndirection in order to generate a rich, over complete set of features.\nNote that the line features can be calculated by two rectangles only.\nHereto it is assumed that the first rectangle  encompasses the\n\nblack and white rectangle and the second rectangle  represents the\nblack area. For instance, line feature (2a) with total height of 2 and\nwidth of 6 at the top left corner (5,3) can be written as\n.Only features (1a), (1b), (2a), (2c) and (4a) of Figure 2 have been\nused by [3,4,5]. In our experiments the additional features\nsignificantly enhanced the expressional power of the learning\n\nsystem and consequently improved the performance of the object\ndetection system. Feature (4a) was not used since it is well\napproximated by feature (2g) and (2e).\nNUMBER\n OF FEATURES\n. The number of features derived from each\nprototype is quite large and differs from prototype to prototype and\nWHrxywh\n\n=0xxwW\n+0yyhH\n+xy0wh0045RecSumr\nFigure 1.Examples of an upright and 45 rotated rectangle.\nupright rectangle\n45 rotated rectangle\nWindow\nwhwhWHhwfeature\nIiRecSumr\niiI1N==iriN2=w0Arear\n0w1Arear\n1=w01=w1Arear\n0Arear\n1=r0r1feature\nI1RecSum\n53620\n3RecSum73220+=An Extended Set of Haar-like Features for Rapid Object Detection\nRainer Lienhart and Jochen Maydt\nIntel Labs, Intel Corporation, Santa Clara, CA 95052, USA\nRainer.Lienhart@intel.com\n'b"can be calculated as follows. Let  and  be the\nmaximum scaling factors in \nx and \ny direction. A upright feature of\nsize \nwxh then generates\nfeatures for an image of size \nWxH, while a  rotated feature\ngenerates\n with \nz=w+h.\nTable 1 lists the number of features for a window size of 24x24.\n2.2 Fast Feature Computation\nAll our features can be computed very fast and in constant time for\nany size by means of two auxiliary images. For upright rectangles\n\nthe auxiliary image is the \nSummed Area Table . \nis defined as the sum of the pixels of the upright rectangle ranging\nfrom the top left corner at (0,0) to the bottom right corner at (\nx,y\n)(see Figure 3a) [5]:\n.It can be calculated with one pass over all pixels from left to right\nand top to bottom by means of\nwithFrom this the pixel sum of any upright rectangle  can\nbe determined by four table lookups (see also Figure 3(c):\nThis insight was first published in [5].\nFor 45\n rotated rectangles the auxiliary image is defined as the\nRotated Summed Area Table\n . It gives the sum of the\npixels of the rectangle rotated by  with the right most corner at\n(x,y\n) and extending till the boundaries of the image (see Figure 3b):\n.It can be calculated with two passes over all pixels. The first pass\nfrom left to right and top to bottom determines\nwith,whereas the second pass from the right to left and bottom to top\ncalculates\nFrom this the pixel sum of any rotated rectangle \ncan be determined by four table lookups (see also Figure 3(d) and\nFigure 4):\n.2.3 Fast Lighting Correction\nThe special properties of the haar-like features also enable fast\ncontrast stretching of the form\n, .Feature \nType\nw/hX/Y#1a ; 1b2/1 ; 1/2\n12/24 ; 24/1243,200\n1c ; 1d2/1 ; 1/2\n8/88,464\n2a ; 2c3/1 ; 1/3\n8/24 ; 24/827,600\n2b ; 2d4/1 ; 1/4\n6/24 ; 24/620,736\n2e ; 2g3/1 ; 1/3\n6/64,356\n2f ; 2h4/1 ; 1/4\n4/43,600\n3a3/3\n8/88,464\n3b3/3\n3/31,521\nSum\n117,941\nTable 1: \nNumber of features inside of a 24x24 window for \neach prototype.\nFigure 2.Feature prototypes of simple haar-like and center-sur-\nround features. Black areas have negative and white ar-\neas positive weights.\n1. Edge features\n3. Center-surround features\n2. Line features\n4. Not used, but used in \n[3,2,4]\n(a)\n(b)(c)\n(d)\n(a)(b)\n(c)\n(d)(e)(f)\n(g)\n(h)(a)\n(b)XWw\n=YHh\n=XYW\n1wX1+2----------\n+H1hY1+2---------\n-+45XYW\n1zX1+2----------\n+H1zY1+2---------\n-+SATxy\nSATxy\nSATxy\nIx'y'xxyy=SATxy\nSATxy\n1SATx\n1yIxy\nSATx\n1y1++=Figure 3.(a) Upright \nSummed Area Table\n (SAT\n) and (b) \nRotated Summed Area Table\n (RSAT\n); calcula-\ntion scheme of the pixel sum of upright (c) and rotat-\ned (d) rectangles.\nTSAT\n(x,y)\n(a)\n(b)\nSAT\n(x,y)\n(c)\n-++++---SAT\n1ySATx\n10==rxywh\n0\n=RecSumr\nSATx\n1y1SATxw\n1yh1+++=SATx\n1yh1+SATxw\n1y1+RSATxy\n45RSATxy\nIx'y'xxxxyy\n=RSATxy\nRSATx\n1y1+RSATx\n1yIxy\nRSATx\n2y1+=RSAT\n1yRSAT\n2yRSATx\n10===\nRSATxy\nRSATxy\nRSATx\n1y1+RSATx\n2y+=rxywh\n45\n=RecSumr\nRSATxw\n+yw+RSATxh\nyh++=RSATxy\nRSATxwh\nywh\n+++Ixy\nIxy\n\nc-------------------\n-=cR+"b' can easily be determined by means of \nSAT\n(x,y). Computing ,\nhowever, involves the sum of squared pixels. It can easily be\nderived by calculating a second set of \nSAT\n and \nRSAT\n auxiliary\nimages for . Then, calculating  for any window requires\n\nonly 4 additional table lookups. In our experiments \nc was set to 2.\n3  Cascade of Classifiers\nA cascade of classifiers is degenerated decision tree where at each\nstage a classifier is trained to detect almost all objects of interest\n(frontal faces in our example) while rejecting a certain fraction of\n\nthe non-object patterns [5] (see Figure 5). For instance, in our case\neach stage was trained to eliminated 50% of the non-face patterns\nwhile falsely eliminating only 0.2% of the frontal face patterns; 13\n\nstages were trained. In the optimal case, we can expect a false alarm\nrate about  and a hit rate about .\nEach stage was trained using the Discrete Adaboost algorithm [1].\nDiscrete Adaboost is a powerful machine learning algorithm It can\n\nlearn a strong classifier based on a (large) set of weak classifiers by\nre-weighting the training samples. Weak classifiers are only\nrequired to be slightly better than chance. Our set of weak\n\nclassifiers are all classifiers which use one feature from our feature\npool in combination with a simple binary thresholding decision. At\neach round of boosting, the feature-based classifier is added that\n\nbest classifies the weighted training samples. With increasing stage\nnumber the number of weak classifiers, which are needed to achieve\nthe desired false alarm rate at the given hit rate, increases (for more\ndetail see [5]).\n4  Stage Post-Optimization\nGiven a discrete AdaBoost stage classifier\n with \nwe can easily construct an non-optimal ROC by smoothly varying\noffset \nb (see Figure 6). While this stage classifiers is designed to\nyield a low error rate (= miss + false alarms) on the training data, it\nin general performs unfavorable for \nb!=0, specially in our case\nwhere we want to achieve the miss rate close to zero.\nHowever, any given stage classifier can be post-optimized for a\ngiven hit rate. The free parameters are , while  must be chosen\naccording to the AdaBoost loss function to preserve the properties\nof AdaBoost. We use the iterative procedure shown in Figure 7 for\n\noptimization, where step 4.2.1. is implemented in a gradient decent-\nlike manner: Starting with the original  value,  is first slowly\nincreased then decreased as long as the performance does not\n\ndegrade. A true gradient decent cannot be implemented since the\nc(x) is not continuos. Note that any change in the threshold \nrequires recomputation of ,  for .\n5  Experimental Results\n5.1 Basic vs. Extended Haar-like Features\nTwo face detection systems were trained: One with the basic and\none with the extended haar-like feature set. On average the false\nalarm rate was about 10% lower for the extended haar-like feature\n\nset at comparable hit rates. Figure 7 shows the ROC for both\nclassifiers using 12 stages. At the same time the computational\ncomplexity was comparable. The average number of features\n\nevaluation per patch was about 31.\nThese results suggest that although the larger haar-like feature set\nusually complicates learning, it was more than paid of by the added\ndomain knowledge. In principle, the center surround feature would\nhave been sufficient to approximate all other features, however, it is\n\nin general hard for any machine learning algorithm to learn joint\nbehavior in a reliable way.\n5.2 Stage Post-Optimization\nA third face detection system was trained using the extended feature\n(x,y)\n+RSAT(x+w-1,y+w-1)\nwwhh+RSAT(x-h-1,y+h-1)\n-RSAT(x+w-1-h,y+w-1+h)\n-RSAT(x-1,y-1)\nFigure 4.Calculation scheme for rotated areas.\nI2xy\n0.5\n131.2\ne040.998\n130.97\nFigure 5.Cascade of Classifiers with \nN stages. At each stage a clas-\nsifier is trained to achieve a hit rate off \nh and a false alarm \nrate of \nf.stage123  ......N  \nhitrateh\nN=falsealarmsf\nN=hhhhh\ninput pattern classified as a non-object\n1-f\n1-f\n1-f1-f\ncxsign\nmfmxtmb+m1=Mc\n=b0=tiitititnjwj1+ijnFigure 6.Comparison of the ROCs of a discrete Adaboost classifi-\ner with 11 features at stage 0 without and with stage post-\noptimization.\n00.0020.0040.0060.0080.010.0120.0140.20.30.40.50.60.70.80.91miss rate = 1 - hit rate\nfalse alarm rateOriginal AdaBoost result (minimizing error)Post-optimized for a miss rate of 0.002'b'set as well as our novel post-optimization procedure for each\ncompleted stage classifier. On average the false alarm rate was\nabout 12.5% lower for the post-optimized classifier at comparable\nhit rates. Figure 8 shows the ROC for both classifiers\n1. At the same\ntime the computational complexity was also comparable. The\naverage number of features evaluation per patch was about 28. \nFrontal faces are detected in CIF images (320x240) at 5fps on a\nPentium\n-4 2Ghz while searching at all scales with a rescaling\nfactor of 1.2 using a pure C++-based implementation.\n6  Conclusion\nThe paper introduced an novel and fast to compute set of rotated\n\nhaar-like features as well as a novel post-optimization procedure for\n\nboosted classifiers. It was shown that the overall performance could\nbe improved by about 23.8% of which 10% could be constributed\nto the rotated features and 12.5% to the stage post-optimization\n\nscheme.\n7  REFERENCES\n[1]Freund, Y. & Schapire, R. E. (1996b). Experiments with a new\nboosting algorithm. In Machine Learning: Proceedings of the\nThirteenth International Conference, Morgan Kauman, San\nFrancisco, pp. 148-156, 1996.\n[2]Chulhee Lee and David A. Landgrebe. Fast Likelihood Classi-\nfication. IEEE Transactions on Geoscience and Remote Sens-\ning, Vol. 29, No. 4, July 1991.\n[3]A. Mohan, C. Papageorgiou, T. Poggio. Example-based object\ndetection in images by components. IEEE Transactions on Pat-\ntern Analysis and Machine Intelligence, Vol. 23, No. 4, pp. 349\n\n-361, April 2001.\n[4]C. Papageorgiou, M. Oren, and T. Poggio. A general frame-\nwork for Object Detection. In \nInternational Conference on\nComputer Vision\n, 1998.\n[5]Paul Viola and Michael J. Jones. Rapid Object Detection using\na Boosted Cascade of Simple Features. IEEE CVPR, 2001.\n[6]P. Pudil, J. Novovicova, S. Blaha, and J. Kittler. Multistage\npattern recognition with reject option. 11th IAPR International\nConference on Pattern Recognition, Vol.2, pp. 92 -95, 1992.\n[7]H. Rowley, S. Baluja, and T. Kanade. Neural network-based\nface detection. In IEEE Patt. Anal. Mach. Intell., Vol. 20, pp.\n22-38, 1998.\n1.Define\n and \n2.Given \n2.1.Positive and negative examples  and \n where  and \n2.2.Stage classifier \n2.3.Desired target hit rate \nh3.Initialize \n3.1.with \nb subject to \n3.2.\n4.While ( < )\n4.1.\n4.2.Repeat for \nj=1, 2, ..., \nM:4.2.1Find combinationthat minimizes the expected \nweighted false alarm rate at target hit rate \nh: with \nsubject to\nand\n,  set according to Adaboost rule. The superscript \np and \nn denotes that the expectation value and error is calcu-\nlated with respect to the weighted positive and nega-\n\ntive samples only. \n4.3.Determine  combination with smallest expected \nweighted false alarm rate at given hit rate:\n4.4., update  and  according to Adaboost \nrule, \nFMx\nmfmxtm;m1=M=FMjx\nmfmxtm;m1mj=M=x1py1\np\nxNppyNppx1ny1\nn\nxNnnyNnnyip1=yin1=cxsignF\nMb+=errE\nwn1yincxi\nnEwp1yipcxi\np=Ewp1herrOlderr\n1+=errerrOld\nerrOlderr\n=tjbtjbjmin\ntjberrnjtjbargerrnjtjbEwn1yinsignF\nM\njjfjxi\nntj;b++Ewn1=Ewp1yipsignF\nM\njjfjxi\nptj;bj++=Ewp1hjwjitjbjjminjerrnjtjbjargtjtjbjbjjwtjerrerr\nnjtjbjFigure 7.Post-optimization procedure of a given boosted classifier \nfor a given target hit rate.\nFigure 7.Basic versus extended feature set: On average the false \nalarm rate of the face detector exploiting the extended fea-\n\nture set was about 10% better at the hit rate.\n0.90.910.920.930.940.950.960.0010.00150.0020.00250.0030.00350.0040.00450.005hit rate\nfalse alarmsPerformance comparison between basic and extented feature setUsing Basic FeaturesUsing Extended Features1. In Figure 8 only 9 stages were used. In the final paper, the data \nfor a 13 stage classifier will be given.\nFigure 8.Stage post-optimization improves performance of the \nboosted detection cascade by about 12.5%.\n0.890.90.910.920.930.940.950.960.0010.00150.0020.00250.0030.00350.0040.00450.005hit rate\nfalse alarmsPerformance comparison between basic and extented feature setExtended Features with Post-OptimizationExtended Features'