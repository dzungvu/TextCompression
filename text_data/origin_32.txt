b'ConvolutionalNeuralNetworkCommitteesForHandwrittenCharacter\n\nDanClaudiuCiresanandUeliMeierandLucaMariaGambardellaandJ\n\nurgenSchmidhuber\nIDSIA\nUSI,SUPSI\n6928Manno-Lugano,Switzerland\nf\ndan,ueli,luca,juergen\ng\n@idsia.ch\nAbstract\nIn2010,aftermanyyearsofstagnation,the\nMNISThandwritingrecognitionbenchmarkrecorddropped\nfrom0.39%errorrateto0.35%.Herewereport0.27%\n\n0.02\nforacommitteeofsevendeepCNNstrainedongraphicscards,\nnarrowingthegaptohumanperformance.Wealsoapply\nthesamearchitecturetoNISTSD19,amorechallenging\ndatasetincludingloweranduppercaseletters.Acommitteeof\nsevenCNNsobtainsthebestresultspublishedsofarforboth\nNISTdigitsandNISTletters.Therobustnessofourmethod\nisvbyanalyzing78125different7-netcommittees.\nKeywords\n-ConvolutionalNeuralNetworks;GraphicsPro-\ncessingUnit;HandwrittenCharacterRecognition;Committee\nI.I\nNTRODUCTION\nCurrentautomatichandwritingrecognitionalgorithmsare\nnotbadatlearningtorecognizehandwrittencharacters.\nConvolutionalNeuralNetworks(CNNs)[1]areamongthe\nmostsuitablearchitecturesforthistask.RecentCNNwork\nfocusedoncomputervisionproblemssuchasrecognitionof\n3Dobjects,naturalimagesandtrafcsigns[2][4],image\ndenoising[5]andimagesegmentation[6].Convolutional\narchitecturesalsoseemtounsupervisedlearning\nalgorithmsappliedtoimagedata[7][9].[10]reportedan\nerrorrateof0.4%ontheMNISThandwrittencharacter\nrecognitiondataset[1],usingafairlysimpleCNN,plus\nelastictrainingimagedeformationstoincreasethetraining\ndatasize.In2010,usinggraphicscards(GPUs)togreatly\nspeeduptrainingofplainbutdeepMultilayerPerceptrons\n(MLPs),anerrorrateof0.35%wasobtained[11].Such\nanMLPhasmanymorefreeparametersthanaCNN.Here\nwereportexperimentsusingCNNstrainedonMNISTas\nwellasonthemorechallengingNISTSD19database[12],\nwhichcontains482,925trainingand82,587testcharacters\n(i.e.upper-andlower-caselettersaswellasdigits).On\nGPUs,CNNscanbesuccessfullytrainedonsuchextensive\ndatabaseswithinreasonabletime(\n\n1to6hoursoftraining,\ndependingonthetask).\nAtsomestageinthedesignprocessoneusually\nhascollectedasetofreasonableTypicallyone\nofthemyieldsbestperformance.Intriguingly,however,the\nsetsofpatternsbydifferentdonot\nnecessarilygreatlyoverlap.Herewefocusonimproving\nrecognitionratesusingcommitteesofneuralnetworks.Our\ngoalistoproduceagroupofwhoseerrors\nonvariouspartsofthetrainingsetdifferasmuchas\npossible.Weshowthatforhandwrittendigitrecognition\nthiscanbeachievedbytrainingidenticalon\ndatapre-processed/normalizedindifferentways[13].Other\napproachesaimingatoptimallycombiningneuralnetworks\n[14],[15]donotdothis,thusfacingtheproblemofstrongly\ncorrelatedindividualpredictors.Furthermore,wesimply\naverageindividualcommitteememberoutputs,insteadof\noptimizingtheircombinations[15],[16],whichwouldcost\nadditionalvaluabletrainingdata.\nII.T\nRAININGTHEINDIVIDUALNETS\nCNNsareusedasbase[3].Thesamearchitec-\ntureisusedforexperimentsonNISTSD19andMNIST.\nThenetshaveaninputlayerof\n29\n\n29\nneuronsfollowed\nbyaconvolutionlayerwith20mapsof\n26\n\n26\nneurons\nandofsize\n4\n\n4\n.Thenexthiddenlayerisamax-\npoolinglayer[17],[18]witha\n2\n\n2\nkernelwhichhasits\noutputsconnectedtoanotherconvolutionlayercontaining\n40mapsof\n9\n\n9\nneuronseach.Thelastmax-poolinglayer\nisreducingthemapsizeto\n3\n\n3\nbyusingofsize\n3\n\n3\n.Afullyconnectedlayerof150neuronsisconnected\ntothemax-poolinglayer.Theoutputlayerhasoneneuron\nperclass,e.g.62forNISTSD19and10forMNIST.\nAllCNNsaretrainedinfullonlinemodewithanannealed\nlearningrateandcontinuallydeformeddatatheimages\nfromthetrainingsetaredistortedatthebeginningofevery\nepoch.Thefollowingelasticdeformationparameters\n\n=6\nand\n\n=36\nareusedtogetherwithindependenthorizontal\nandverticalscalingofatmost\n15%\nandatmost\n\n15\n\nof\nrotationforallexperiments[11].Deformationsareessential\ntopreventovandgreatlyimprovegeneralization.\nGPUsacceleratethedeformationroutinebyafactorof\n10(onlyelasticdeformationsareGPU-optimized),andthe\nnetworktrainingprocedurebyafactorof60[3].Wepickthe\ntrainedCNNwiththelowestvalidationerror,andevaluate\nitonthecorrespondingtestset.\n'b'III.F\nORMINGACOMMITTEE\nWeperformexperimentsontheoriginalandsixprepro-\ncesseddatasets.Preprocessingismotivatedbywritingstyle\nvariationsresultingindifferentaspectratiosofthehandwrit-\ntencharacters.Priortotraining,wethereforenormalizethe\nwidthofallcharactersto10,12,14,16,18and20pixels,\nexceptforcharactersin\nf\n1,i,l,I\ng\nandintheoriginaldata[13].\nThetrainingprocedureofanetworkissummarizedin\nFigure1a.Eachnetworkistrainedseparatelyonnormalized\nororiginaldata.Thenormalizationisdoneforalldigitsin\nthetrainingsetpriortotraining(normalizationstage).Dur-\ningeachtrainingepocheverysinglecharacterisdistorted\ninadifferentway.Thecommitteesareformedbysimply\naveragingthecorrespondingoutputsasshowninFigure1b.\nForeachofthepreprocessedororiginaldatasets,ve\ndifferentlyinitializedCNNsaretrainedforthesamenumber\nofepochs.Thisallowsforperforminganerroranalysis\noftheoutputsofthe\n5\n7\n=78125\npossiblecommitteesof\nsevennets,eachtrainedononeofthesevendatasets.We\nreportmeanandstandarddeviationaswellasminimumand\nmaximumrecognitionrate.\nFigure1.\na)Trainingacommitteemember:\nOriginaltrainingdata(left\ndigit)isnormalized(W10)priortotraining(middledigit).Thenormalized\ndataisdistorted(D)foreachtrainingepoch(rightdigit)andfedtothe\nneuralnetwork(NN).Eachdepicteddigitrepresentsthewholetraining\nset.\nb)Testingwithacommittee:\nIfrequired,theinputdigitsarewidth-\nnormalized(Wblocks)andthenprocessedbythecorrespondingNNs.A\ncommitteeaveragestheoutputsofitsCNNs.\nIV.E\nXPERIMENTS\nWeuseasystemwithaCorei7-920(2.66GHz),12GB\nDDR3andfourgraphicscards:2xGTX480and2xGTX\n580.DetailsofourGPUimplementationareexplainedin\n[3],[11].\nOurmethodisappliedtotwohandwrittencharacter\ndatasets:subsetsfromNISTSD19anddigitsfromMNIST\n(TableI).\nTableI\nD\nATASETS\n.\nName\nTypeTrainingsetTestset#Classes\nMNIST\ndigits600001000010\nNISTSD19\ndigits&letters4829258258762\nNISTSD19\ndigits3443075864610\nNISTSD19\nletters1386182394152\nNISTSD19\nmerged1386182394137\nNISTSD19\nlowercase690961200026\nNISTSD19\nuppercase695221194126\nA.ExperimentswithNISTSpecialDatabase19\nNISTSD19containsover800,000handwrittencharac-\nters.Wefollowtherecommendationsoftheauthorsand\nbuildstandardtrainingandtestsets.The\n128\n\n128\ncharacter\nimagesareuncompressed;theirbounding-boxesareresized\nto\n20\n\n20\n.Theresultingcharactersarecenteredwithina\n29\n\n29\nimage.Thisnormalizesallthecharactersinthesame\nwayMNISTdigitsarealreadynormalized.\n1)Digits&letters:\nWetrainvedifferentlyinitialized\nnetsoneachpreprocesseddatasetaswellasontheoriginal\ndata,foratotalof35CNNs(TableII).EachCNNistrained\nfor30epochsbyon-linegradientdescent,decreasingthe\nlearningrate(initially0.001)byafactorof0.993perepoch.\nThenumberofepochsislimitedduetothesizeofNIST\nSD19:trainingasinglenetforthe62classproblemtakes\nalmostsixhours.\nTableII\nT\nESTERRORRATE\n[%]\nOFTHE\n35CNN\nSTRAINEDON\nNISTSD19,62\nCLASSTASK\n.W\nXX\n-\nWIDTHOFTHECHARACTERISNORMALIZEDTO\nXXPIXELS\n.\nTrial\nW10W12W14W16W18W20ORIG\n1\n14.7214.1213.7213.5513.7713.8214.32\n2\n14.7314.2113.8014.2013.9313.0414.73\n3\n13.9214.1213.5013.5713.8114.1514.57\n4\n14.0714.4213.4613.4713.7613.6314.05\n5\n14.1413.6913.9113.9213.5013.6013.72\nCommittees\nAverage11.88\n\n0.09Min11.68Max12.12\nTheaveragecommitteeisbetterthananyof\ntheindividualCNNs.Eventheworstcommitteeisbetter\nthanthebestnet.Recognitionerrorsofaround12%maystill\nseemlarge,butoneshouldconsiderthatmosterrorsstem\nfromconfusionsofclassesthatlookverysimilar:\nf\n0,o,O\ng\n,\nf\n1,l,i,I\ng\n,\nf\n6,G\ng\n,\nf\n9,g\ng\n,andallconfusionsbetweensimilar\nuppercaseandlowercaseletters(seebelow).Withoutany\nadditionalcontextualinformation,itisliterallyimpossible\ntodistinguishthose.\nWethereforealsotrainvariousnetsondigits,allletters,\namergedletterset,andalsoonlowercaseanduppercase\nlettersseparately.Thisdrasticallydecreasesthenumberof\nconfusedclassesandalsomakesitpossibletocompareour\nresultstootherpublishedresults.Wearenotawareofany\npreviousstudypublishingresultsonthechallengingfull62\nclassproblem.\n'b'2)Digits:\nTableIIIsummarizestheresultsof35identical\nCNNstrainedfor30epochsondigits.\nTableIII\nT\nESTERRORRATE\n[%]\nOFTHE\n35CNN\nSTRAINEDON\nNISTSD19\nDIGITS\n.W\nXX\n-\nWIDTHOFTHECHARACTERISNORMALIZEDTOXX\nPIXELS\n.\nTrial\nW10W12W14W16W18W20ORIG\n1\n1.371.421.221.141.221.121.34\n2\n1.401.351.351.211.121.131.40\n3\n1.521.281.241.191.161.151.36\n4\n1.471.351.431.291.241.211.49\n5\n1.631.391.391.251.161.271.42\nCommittees\nAverage0.81\n\n0.02Min0.73Max0.91\nOuraverageerrorrateof0.81%ondigitscompares\nfavorablytootherpublishedresults,1.88%[19],2.4%[20]\nand3.71%[21].Again,asforthe62classproblem,the\ncommitteesoutperformtheindividualnets.\n3)Letters:\nTable(IV)summarizestheresultsof35\nidenticalCNNstrainedfor30epochsonletters.Againthe\nsamearchitectureisused.\nTableIV\nT\nESTERRORRATE\n[%]\nOFTHE\n35CNN\nSTRAINEDON\nNISTSD19\nLETTERS\n.W\nXX\n-\nWIDTHOFTHECHARACTERISNORMALIZEDTOXX\nPIXELS\n.\nTrial\nW10W12W14W16W18W20ORIG\n1\n24.6924.7624.1224.5023.9823.0124.49\n2\n25.5324.9724.0824.0623.5223.3524.93\n3\n25.0925.1424.0624.2824.2023.5824.62\n4\n25.2724.7424.5324.5924.5123.8724.45\n5\n25.6525.9124.7425.1224.3923.6925.38\nCommittees\nAverage21.41\n\n0.16Min20.80Max22.13\nClassboundariesoflettersingeneralanduppercaseand\nlowercaselettersinparticularareseparatedlessclearly\nthanthoseofdigits.However,manyobviouserrortypes\nareavoidablebydifferentexperimentalset-ups,i.e.,by\nignoringcase,mergingclasses,andconsideringuppercase\nandlowercaseclassesindependently.Ignoringcase,average\nerroristhreetimessmaller(7.58%).\n4)Mergedletters:\nTableVsummarizesresults\nof35identicalCNNstrainedfor30epochson\nmergedletters.Uppercaseandlowercaselettersin\nf\nC,I,J,K,L,M,O,P,S,U,V,W,X,Y,Z\ng\naremergedassuggested\nintheNISTSD19documentation[12],resultingin37\ndistinctclassesforthistask.\nIgnoringcaseforonly15outof26letterssufstoavoid\nmostcaseconfusions.Ignoringcasecompletelyreduces\nerroronlyslightly,underlossofabilitytodistinguishthe\ncaseofthe11remainingletters.\n5)Upper-orlowercaseletters:\nFurthersimplifyingthe\ntaskbyconsideringuppercaseandlowercaselettersinde-\npendentlyyieldsevenlowererrorrates(TablesVI,VII).\nUppercaselettersaremucheasiertoclassifythanlower-\ncaseletterserrorratesarefourtimessmaller.Shapesof\nTableV\nT\nESTERRORRATE\n[%]\nOF\n35CNN\nSTRAINEDON\nNISTSD19\nMERGEDLETTERS\n.W\nXX\n-\nWIDTHOFTHECHARACTERISNORMALIZED\nTOXXPIXELS\n.\nTrial\nW10W12W14W16W18W20ORIG\n1\n10.4010.119.549.679.309.3810.01\n2\n10.3810.209.999.479.689.3410.25\n3\n10.6910.239.509.529.559.8710.08\n4\n11.1010.2110.209.959.869.7610.21\n5\n10.8710.8010.359.469.7110.0310.64\nCommittees\nAverage8.21\n\n0.11Min7.83Max8.56\nTableVI\nT\nESTERRORRATE\n[%]\nOF\n35CNN\nSTRAINEDON\nNISTSD19\nUPPERCASELETTERS\n.W\nXX\n-\nWIDTHOFTHECHARACTERIS\nNORMALIZEDTOXXPIXELS\n.\nTrial\nW10W12W14W16W18W20ORIG\n1\n3.082.902.802.512.602.552.79\n2\n3.032.732.842.702.782.532.70\n3\n3.332.962.832.652.842.652.68\n4\n3.293.222.962.652.652.602.87\n5\n3.232.972.702.782.862.642.70\nCommittees\nAverage1.91\n\n0.06Min1.71Max2.15\nuppercaselettersarebetterandin-classvariability\nduetodifferentwritingstylesisgenerallysmaller.\nTableVII\nT\nESTERRORRATE\n[%]\nOF\n35CNN\nSTRAINEDON\nNISTSD19\nLOWERCASELETTERS\n.W\nXX\n-\nWIDTHOFTHECHARACTERIS\nNORMALIZEDTOXXPIXELS\n.\nTrial\nW10W12W14W16W18W20ORIG\n1\n10.229.309.429.259.088.879.44\n2\n10.309.759.919.639.199.328.84\n3\n10.519.889.959.188.889.829.29\n4\n10.129.7310.399.639.0510.0510.04\n5\n10.829.5610.089.539.589.5910.24\nCommittees\nAverage7.71\n\n0.14Min7.16Max8.28\nB.ExperimentsonMNIST\nTheMNISTdataisalreadypreprocessedsuchthatthe\nwidthorheightofeachdigitis20pixels.OurCNNsare\ntrainedforaround800epochs.Ineveryepochwemultiply\nthelearningrate(initially0.001)byafactorof0.993untilit\nreaches0.00003.Usually,thereislittlefurtherimprovement\nafter500trainingepochs.Trainingonenettakesalmost14\nhours.\nTheaverageerrorrateof\n0\n:\n27\n\n0\n:\n02\n%isbyfarthebest\nresultpublishedonthisbenchmark.InFigure2all69errors\nofallcommitteesareshown,togetherwiththetruelabels\nandthemajorityvotesofthecommittees.Digitsaresorted\nindescendingorderofhowmanycommitteescommitted\nthesameerror,indicatedaspercentagesatthebottom\nofeachdigit.Thesixerrorswerecommittedbyall\ncommitteesobviouslythecorrespondingdigitsareeither\nwronglylabeledorveryambiguous,andthemajorityvote\n'b"TableVIII\nT\nESTERRORRATE\n[%]\nOFTHE\n35CNN\nSTRAINEDON\nMNIST.W\nXX\n-\nWIDTHOFTHECHARACTERISNORMALIZEDTOXXPIXELS\n.\nTrial\nW10W12W14W16W18W20ORIG\n1\n0.490.390.400.400.390.360.52\n2\n0.480.450.450.390.500.410.44\n3\n0.590.510.410.410.380.430.40\n4\n0.550.440.420.430.390.500.53\n5\n0.510.390.480.400.360.290.46\nCommittees\nAverage0.27\n\n0.02Min0.17Max0.37\nseemscorrect.Eachcommitteefailstorecognizebetween\n17to37digitsoutofthe69presentederrors.\nFigure2.The69errorsofallcommittees,thelabel(upleft),thecommittee\nmajorityvote(upright),andthepercentageofcommitteescommittinga\nparticularerror(downleft).\nC.Summaryofexperiments\nTableIXsummarizesourresultsandcomparestoprevi-\nouslypublishedresultswhereavailable.Forlettersitwas\ndiftoanypublicationsreportingresultsforsimilar\nexperimentalset-ups.Tothebestofourknowledge,our\nresultsarefarbetter(30-350%)thananyalreadypublished\nresult.\nTableIX\nA\nVERAGEERRORRATESOFCOMMITTEESFORALLTHEEXPERIMENTS\n,\n\nONESTANDARDDEVIATION\n[%],\nPLUSRESULTSFROMTHE\nLITERATURE\n.*\nCASEINSENSITIVE\nData\nCommitteePublishedresults\nMNIST\n0.27\n\n0.020.40[22]0.39[23]0.35[11]\nNIST:\nall(62)\n11.88\n\n0.09\ndigits(10)\n0.81\n\n0.025.06[24]3.71[21]1.88[19]\nletters(52)\n21.41\n\n0.1630.91[25]\nletters*(26)\n7.58\n\n0.0913.00[26]13.66[25]\nmerged(37)\n8.21\n\n0.11\nuppercase(26)\n1.91\n\n0.0610.00[26]6.44[27]11.51[25]\nlowercase(26)\n7.71\n\n0.1416.00[26]13.27[25]\nErrorratesfordigitsarelowerthanthose\nforletters.Trainingnetswithcase-insensitiveletterlabels\nmakeserrorratesdropconsiderably,indicatingthatmost\nerrorsofnetstrainedon52lowercaseanduppercaseletters\nareduetoconfusionsbetweensimilarclasses.Ageneric\nletterrecognizershouldthereforebetrainedonamerged\nletterdataset.Ifrequired,casehavetoberesolved\naposteriori,usingadditional(e.g,contextual)information.\nAllexperimentsusethesamenetworkarchitectureand\ndeformationparameters,whicharenottoincrease\naccuracy.Instead,werelyoncommitteesto\nimproverecognitionrates.Additionaltests,however,show\nthatourdeformationparametersaretoobigforsmall\nlettersusing20%lowervaluesdecreaseserrorratesby\nanother1.5%.\nForcommercialOCR,recognitionspeedisofgreatinter-\nest.Ournetscheckalmost10000characterspersecond.At\nglance,acommitteeofsevensuchnetsisseventimes\nslowerthanasinglenet,butwecanrunthenetsinpar-\nallelonsevendifferentGPUs,thuskeepingthecommittee\nthroughputatthesinglenetlevel.\nV.C\nONCLUSION\nSimpletrainingdatapre-processinggaveusexpertswith\nerrorslesscorrelatedthanthoseofdifferentnetstrained\nonthesameorbootstrappeddata.Hencecommitteesthat\nsimplyaveragetheexpertoutputsconsiderablyimprove\nrecognitionrates.Ourcommittee-basedofisolated\nhandwrittencharactersaretheonparwithhuman\nperformance[28],[29],andcanbeusedasbasicbuilding\nblocksofanyOCRsystem(allourresultswereachievedby\nsoftwarerunningonpowerfulyetcheapgamingcards).It\nlookslikewehavereachedtherecognitionlimitofisolated\ncharacters.\nA\nCKNOWLEDGMENT\nThisworkwaspartiallysupportedbySwissCTI,Com-\nmissionforTechnologyandInnovation,Projectn.9688.1\nIFF:IntelligentFillinForm.\nR\nEFERENCES\n[1]Y.LeCun,L.Bottou,Y.Bengio,andP.Haffner,Gradient-\nbasedlearningappliedtodocumentrecognition,\nProceedings\noftheIEEE\n,vol.86,no.11,pp.22782324,November1998.\n[2]F.-J.HuangandY.LeCun,Large-scalelearningwithsvm\nandconvolutionalnetsforgenericobjectcategorization,in\nProc.ComputerVisionandPatternRecognitionConference\n(CVPR'06)\n.IEEEPress,2006.\n[3]D.C.Ciresan,U.Meier,J.Masci,L.M.Gambardella,\nandJ.Schmidhuber,High-performanceneuralnetworksfor\nvisualobjectclasIstitutoDalleMollediStudi\nsull'Intelligenza(IDSIA),Tech.Rep.IDSIA-01-\n11,2011.\n"b"[4]D.C.Ciresan,U.Meier,J.Masci,andJ.Schmidhuber,A\ncommitteeofneuralnetworksfortrafsign\nin\nInternationalJointConferenceonNeuralNetworks\n,to\nappear,2011.\n[5]V.JainandH.S.Seung,Naturalimagedenoisingwith\nconvolutionalnetworks,in\nAdvancesinNeuralInformation\nProcessingSystems(NIPS2008)\n,2008.\n[6]S.C.Turaga,J.F.Murray,V.Jain,F.Roth,M.Helmstaedter,\nK.Briggman,W.Denk,andH.S.Seung,Convolutional\nnetworkscanlearntogenerateafgraphsforimage\nsegmentation,\nNeuralComputation\n,vol.22,pp.511538,\n2010.\n[7]H.Lee,R.Grosse,R.Ranganath,andA.Y.Ng,Convolu-\ntionaldeepbeliefnetworksforscalableunsupervisedlearning\nofhierarchicalrepresentations,in\nProceedingsofthe26th\nInternationalConferenceonMachineLearning\n,2009,pp.\n609616.\n[8]M.D.Zeiler,D.Krishnan,G.W.Taylor,andR.Fergus,\nDeconvolutionalNetworks,in\nProc.ComputerVisionand\nPatternRecognitionConference(CVPR2010)\n,2010.\n[9]K.Kavukcuoglu,P.Sermanet,Y.Boureau,K.Gregor,\nM.Mathieu,andY.LeCun,Learningconvolutionalfeature\nhierachiesforvisualrecognition,in\nAdvancesinNeural\nInformationProcessingSystems(NIPS2010)\n,2010.\n[10]P.Y.Simard,D.Steinkraus,andJ.C.Platt,Bestpractices\nforconvolutionalneuralnetworksappliedtovisualdocument\nanalysis,in\nSeventhInternationalConferenceonDocument\nAnalysisandRecognition\n,2003,pp.958963.\n[11]D.C.Ciresan,U.Meier,L.M.Gambardella,andJ.Schmid-\nhuber,Deepbigsimpleneuralnetsforhandwrittendigit\nrecognition,\nNeuralComputation\n,vol.22,no.12,pp.3207\n3220,2010.\n[12]P.J.Grother,Nistspecialdatabase19-handprintedforms\nandcharactersdatabase,NationalInstituteofStandardsand\nThechnology(NIST),Tech.Rep.,1995.\n[13]D.C.Ciresan,U.Meier,L.M.Gambardella,andJ.Schmid-\nhuber,Handwrittendigitrecognitionwithacommitteeof\ndeepneuralnetsongpus,IstitutoDalleMollediStudi\nsull'Intelligenza(IDSIA),Tech.Rep.IDSIA-03-\n11,2011.\n[14]L.Breiman,Baggingpredictors,\nMachineLearning\n,vol.24,\npp.123140,1996.\n[15]N.Ueda,Optimallinearcombinationofneuralnetworksfor\nimprovingperformance,\nIEEETrans.Pattern\nAnalysisandMach.Intelli.\n,vol.22,no.2,pp.207215,2000.\n[16]S.Hashem,Optimallinearcombinationofneuralnetworks,\nNeuralNetworks\n,vol.10,pp.599614,1997.\n[17]K.Jarrett,K.Kavukcuoglu,M.Ranzato,andY.LeCun,\nWhatisthebestmulti-stagearchitectureforobjectrecogni-\ntion?in\nProc.InternationalConferenceonComputerVision\n(ICCV'09)\n.IEEE,2009.\n[18]D.Scherer,A.M\n\nuller,andS.Behnke,Evaluationofpooling\noperationsinconvolutionalarchitecturesforobjectrecogni-\ntion,in\nInternationalConferenceonNeuralNet-\nworks\n,2010.\n[19]J.Milgram,M.Cheriet,andR.Sabourin,Estimatingaccu-\nratemulti-classprobabilitieswithsupportvectormachines,\nin\nInt.JointConf.onNeuralNetworks\n,2005,pp.19061911.\n[20]L.Oliveira,R.Sabourin,F.Bortolozzi,andC.Suen,Auto-\nmaticrecognitionofhandwrittennumericalstrings:arecogni-\ntionandvstrategy,\nIEEETransactionsonPattern\nAnalysisandMachineIntelligence\n,vol.24,no.11,pp.1438\n1454,Nov.2002.\n[21]E.Granger,P.Henniges,andR.Sabourin,SupervisedLearn-\ningofFuzzyARTMAPNeuralNetworksThroughParticle\nSwarmOptimization,\nPatternRecognition\n,vol.1,pp.27\n60,2007.\n[22]P.Simard,D.Steinkraus,andJ.Platt,Bestpracticesfor\nconvolutionalneuralnetworksappliedtovisualdocument\nanalysis,in\nSeventhInternationalConferenceonDocument\nAnalysisandRecognition\n,2003,pp.958963.\n[23]M.A.Ranzato,C.Poultney,S.Chopra,andY.Lecun,\nEflearningofsparserepresentationswithanenergy-\nbasedmodel,in\nAdvancesinNeuralInformationProcessing\nSystems(NIPS2006)\n,2006.\n[24]P.V.W.Radtke,R.Sabourin,andT.Wong,Usingtherrt\nalgorithmtooptimizesystemsforhandwritten\ndigitsandletters,in\nProceedingsofthe2008ACMsympo-\nsiumonAppliedcomputing\n.ACM,2008,pp.17481752.\n[25]A.L.KoerichandP.R.Kalva,Unconstrainedhandwritten\ncharacterrecognitionusingmetaclassesofcharacters,in\nIntl.\nConf.onImageProcessing(ICIP)\n,2005,pp.542545.\n[26]P.R.Cavalin,A.deSouzaBrittoJr.,F.Bortolozzi,\nR.Sabourin,andL.E.S.deOliveira,Animplicit\nsegmentation-basedmethodforrecognitionofhandwritten\nstringsofcharacters.in\nSAC'06\n,2006,pp.836840.\n[27]E.M.DosSantos,L.S.Oliveira,R.Sabourin,andP.Maupin,\nOvintheselectionofensembles:acompar-\nativestudybetweenpsoandga,in\nProceedingsofthe10th\nannualconferenceonGeneticandevolutionarycomputation\n.\nACM,2008,pp.14231424.\n[28]Y.LeCun,L.D.Jackel,L.Bottou,C.Cortes,J.S.Denker,\nH.Drucker,I.Guyon,U.A.Muller,E.Sackinger,P.Simard,\nandV.Vapnik,LearningalgorithmsforA\ncomparisononhandwrittendigitrecognition,in\nNeural\nNetworks:TheStatisticalMechanicsPerspective\n,J.H.Oh,\nC.Kwon,andS.Cho,Eds.World1995,pp.\n261276.\n[29]F.Kimura,N.Kayahara,Y.Miyake,andM.Shridhar,Ma-\nchineandhumanrecognitionofsegmentedcharactersfrom\nhandwrittenwords,in\nInt.Conf.onDocumentAnalysisand\nRecognition\n,1997,pp.866869.\n"