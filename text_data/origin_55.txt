b'OrientationInvariantFeatureEmbeddingandSpatialTemporalRegularization\nforVehicleRe-identication\nZhongdaoWang\n1,2,LumingTang\n1,2,XihuiLiu\n1,2,ZhuliangYao\n1,2,ShuaiYi\n1,JingShao\n1,JunjieYan\n1,ShengjinWang\n2,HongshengLi\n3,XiaogangWang\n31SenseTimeGroupLimited\n2TsinghuaUniversity\n3TheChineseUniversityofHongKong\nyishuai@sensetime.comhsli@ee.cuhk.edu.hk\nAbstractInthispaper,wetacklethevehicleRe-identication\n(ReID)problemwhichisofgreatimportanceinurban\n\nsurveillanceandcanbeusedformultipleapplications.In\n\nourvehicleReIDframework,anorientationinvariantfea-\n\ntureembeddingmoduleandaspatial-temporalregulariza-\n\ntionmoduleareproposed.Withorientationinvariantfea-\n\ntureembedding,localregionfeaturesofdifferentorienta-\n\ntionscanbeextractedbasedon20keypointlocationsand\n\ncanbewellalignedandcombined.Withspatial-temporal\n\nregularization,thelog-normaldistributionisadoptedto\n\nmodelthespatial-temporalconstraintsandtheretrievalre-\n\nsultscanberened.Experimentsareconductedonpublic\n\nvehicleReIDdatasetsandourproposedmethodachieves\n\nstate-of-the-artperformance.Investigationsoftheproposed\n\nframeworkisconducted,includingthelandmarkregressor\n\nandcomparisonswithattentionmechanism.Boththeorien-\n\ntationinvariantfeatureembeddingandthespatio-temporal\n\nregularizationachieveconsiderableimprovements.\n1231.Introduction\nInthispaper,wetargetontheproblemofvehiclere-\nidentication(ReID),whichaimstoidentifyalltheimages\n\nofthesamevehiclefromalargegallerydatabase.Sucha\n\ntaskisparticularlyusefulwhenthecarlicenceplateisoc-\n\ncludedorcannotbeseenclearly.VehicleReIDmethodscan\n\nbeusedinthesescenariostoeffectivelylocatevehiclesof\n\ninterestfromsurveillancedatabases.Theyhaveextensive\n1Z.WangandL.Tangshareequalcontribution.\n2S.YiandH.Liarethecorrespondingauthors.\n3ThisworkissupportedinpartbySenseTimeGroupLimited,inpartby\ntheGeneralResearchFundthroughtheResearchGrantsCouncilofHong\n\nKongunderGrantsCUHK14213616,CUHK14206114,CUHK14205615,\n\nCUHK419412,CUHK14203015,CUHK14239816,CUHK14207814,in\n\npartbytheHongKongInnovationandTechnologySupportProgramme\n\nGrantITS/121/15FX,andinpartbytheChinaPostdoctoralScienceFoun-\n\ndationunderGrant2014M552339.\n\n\nFigure1.DifcultiesoftheproblemofvehicleReID.(a-b)Vehicle\n\nimagepairsthatsharequitesimilaroverallappearances.Theycan\n\nonlybedistinguishedfromlocalregionslikethewheelsin(a)and\n\nthelogosin(b).(c-d)Differentfacesofonevehiclemayhavedif-\n\nferentvisibility,whichresultsindifcultiesinaligningthefeatures\n\nofdifferentfaces.Inourproposedorientationinvariantnetwork,\n\nvisiblefacessuchastherightfacesin(c)andthebackfacesin(d)\n\nareassignedwithalargerweightinthenalfeatureembedding\n\nprocess.(e)Spatio-temporalconstraintsofavehiclesappearance\n\nshouldbesatised,\ne.g\n.around39.66secondsbetweenAandB\nand44.33secondsbetweenBandC.\n\napplicationsinintelligentsurveillanceandattractincreas-\n\ningattentioninrecentyears.Comparedwiththeproblem\n\nofpersonReID,whichhasbeenstudiedforyears,vehicle\n\nReIDisarecentlyproposedresearchtopic.Thereexistspe-\n\nciccharacteristicsandchallengesforthisproblem.\nFirstly,somespecicregionsinvehicleimagesareim-\nportantforvehicleReID.Differentfrompersonimages,\n\nwhichcontainrichtextures,thevehiclesaregenerallysolid-\n\ncoloredandsometimesthecolorpatternsbetweendifferent\n\nvehiclescanbequitesimilar.Forexample,asshownin\n\nFig.1(a-b),thecarsareallredandaredifculttodis-\ntinguishbasedontheirgeneralappearances.Thewheelre-\n\ngionsin(a)andthelogoregionsin(b)arekeystodetermine\n\nwhetherthosevehiclesarethesameones.Mostexisting\n1379\n'b'vehicleReIDapproaches[\n8,9,17]focusonthewholeim-\nageandsuchsubtledifferencescannotbewelltakeninto\n\naccount.Inourproposedmethod,regionfeaturesarecalcu-\n\nlatedbasedon20vehiclekeypointlocations.Inthisway,\n\nvehicleswithsubtledifferencescanbewelldistinguished.\nSecondly,therearealwayssomekeypointsnotvisible\nforvehicleimagesinoneview.Ifwesimplyconsiderave-\n\nhicleasacubewithfoursides,atmosttwoofthemcould\n\nbevisibleateachtime.AsshowninFig.\n1(c),thesame\ncariscapturedintwoviews.Thefrontalfaceisinvisible\n\nin(c1)whiletheleftfaceisinvisiblein(c2).Itissimi-\n\nlarforthebusshowninFig.\n1(d).Therefore,comparing\nwhole-imagefeaturesbetweenvehicleimageswithdiffer-\n\nentviewsisgenerallynotoptimal.Inourframework,the\n\n20keypointsareclusteredintofoursetsbasedontheirori-\n\nentations(front,back,left,andright),sothatthekeypoints\n\nineachsetsharethesamevisibility(allvisibleorallinvis-\n\nible).Inordertodistinguishthevisiblekeypointsetsfrom\n\ntheinvisibleones,anorientationbasedfeaturecalculation\n\nmoduleisproposedinourframework.Differentlearnable\n\nweightsareassignedtodifferentkeypointsetsaccording\n\ntotheorientationoftheinputvehicleimage.Forinstance,\n\nlargeweightsareassignedtotherightfacein(c),aswellas\n\nthebackfacein(d).Inthisway,thevisiblekeypointscan\n\ncontributemoretothenaldecisionwhiletheinuencesof\n\ninvisiblekeypointsareweakenedbylowerweights.Inad-\n\ndition,orientationinvariantfeatureembeddingisproposed\n\ntotransformtheweightedregionfeaturesintothenalori-\n\nentationinvariantfeaturevector.\nLastly,spatio-temporalconstraintsarealsohelpfulfor\nvehicleReID.AsshowninFig.\n1(e),ifacarisobserved\nincamera(A),itismorelikelytobeobservedincamera\n\n(B)withatimedelayaround39.66seconds.Inthepro-\n\nposedapproach,aconditionalspatio-temporaldistribution\n\nismodeledtoregularizethenalReIDresults.\nTheproposedframeworkisevaluatedontwostandard\nvehicleReIDdatasets,\ni.e.VeRi-776[\n9]andVehicleID[\n8].Ourproposedframeworkoutperformsstate-of-the-artvehi-\n\ncleReIDmethods.ItachievesamAPof\n0.514ontheVeri-\n776[\n9]dataset,\n86%higherthanthethebestresult(\n0.277)inliterature[\n9].FortheVehicleID[\n8]dataset,aTop-1ac-\ncuracyof\n67.0%canbeachieved,whichis\n75%higherthan\nthethebestresult(\n38.2%)inliterature[\n8].Thecontributionofthisworkcanbesummarizedasfol-\nlows.1)Adeeplearningframeworkisproposedforve-\n\nhicleReID,whichcontainsfourmaincomponents.The\n\norientation-basedregionproposalmoduleandfeatureex-\n\ntractionmoduleareproposedtocapturevehiclesregionap-\n\npearanceinformationthusdifferentvehiclesshowingsimi-\n\nlaroverallappearancescanbebetterdistinguished.Theori-\n\nentationinvariantfeatureaggregationmoduleisproposed\n\nsothattheregionfeaturesofdifferentviewscanbealigned\n\nandcombined.Thespatio-temporalregularizationmodule\nisproposedtoutilizespatio-temporalconstraintstoregular-\n\nizethenalReIDresults.2)Theproposedframeworkis\n\nevaluatedontwovehicleReIDdatasets.Signicantperfor-\n\nmanceimprovementsoverexistingmethodsareachieved.\n\n3)Ablationstudyoftheproposedframeworkisconducted\n\ntoinvestigatetheeffectivenessofitsindividualcompoents,\n\nwhichincludesinvestigationsonthekeypointregressorand\n\nthecomparisonswithattentionmechanism.\n2.RelatedWork\nRe-identication(ReID)\niswidelystudiedincomputer\nvisionwhichhasvariousimportantapplications.Mostex-\n\nistingReIDmethodsfocusedonthepersonReIDproblem,\n\nwhichaimstondtargetpersonsinalargegallerysetgiven\n\nprobeimages.Manyhand-craftedfeaturesareproposedto\n\ncapturevisualfeaturesforpedestrians[\n1,5,6,12,16,28].Re-\ncently,CNN-basedfeatures[\n2,21,22,27]havealsoachieved\ngreatprogressonpersonReID.\nVehicleReID\nisanewlyproposedresearchtopicand\nhasnotreceivedmuchattention.Recentworksonvehi-\n\ncleReIDmainlyconcentrateonbuildingretrievalpipelines\n\nandbenchmarks.Liu\netal\n.[9]releasedahigh-quality\nmulti-viewedvehicleReIDdataset(namedVeRi-776)with\n\n776vehicleidentities,andproposedaprogressiveretrieval\n\npipelinebycombiningvehicleappearancefeatures,li-\n\ncenseplates,andspatio-temporalinformation.Another\n\nlargesurveillance-naturevehicleReIDdataset(VehicleID)\n\nisproposedbyLiu\netal\n.[8],whichcontainsmorethan\n20,000identities.TheCoupledClustersLoss(CCL)is\n\nproposedforperformanceevaluationonthisbenchmark\n\ndataset.However,alltheseapproachesonvehicleReIDuti-\n\nlizeglobalappearancefeaturesoftheinputvehiclebutdo\n\nnotfocusonspeciclocaldiscriminativeregions.\nFine-grainedvehiclemodelclassication\nisrelevant\ntovehicleReID.Bothtasksfocusonlearningdiscrimina-\n\ntivefeaturerepresentationsforvehicleappearance.Yang\netal.[23]publishedalargescaledataset(CompCars)forne-\ngrainedvehiclemodelclassication,whichisthelargest\n\nvehiclemodeldataset.Dominik\netal\n.[25]andJakub\netal.[17]proposedtousing3D-boxesforaligningdifferent\nvehiclefacesandthreevisiblefacesareusedforaccurate\n\nfeatureextraction.However,thismethodmayintroduce\n\nambiguitieswhenthethreevisiblefacesaredifferent.In\n\nourproposedmethod,thelocalfeatureextractionandag-\n\ngregationmodulesisusedtosolvethisissue.\nObjectkeypointlocalization\nhasmanyimportantap-\nplications,e.g\n.,facealignment[\n14]andhumanposeestima-\ntion[\n13,20].Keypoint-basedfacealignmentisconducted\ninmostfacerecognitionframeworks[\n15,18].Locationsof\nkeypointsarehelpfulasthelearnedfeaturescanbewell\n\nalignedbythekeypoints.However,vehiclekeypointsare\n\nnotwellstudiedinexistingliterature.Ourproposedmethod\n\nshowsthatvehiclekeypointscanguidethelearningand\n380\n'b'\n\n\n\n\n\n\n\n\n\n\n\n\n\nFigure2.Illustrationoftheoverallfeatureembeddingpipeline,\n\nwhichconsistsof(a)theorientation-basedregionproposalmod-\n\nule,(b)theorientation-basedfeatureextractionmodule,and(c)\n\ntheorientation-invariantfeatureaggregationmodule.\n\nalignmentoflocalregionsininputvehicleimagesandim-\n\nprovetheoverallvehicleReIDperformance.\n\n3.Methodology\nOurframeworkconsistsoftwomaincomponents,the\norientationinvariantfeatureembeddingcomponentandthe\n\nspatial-temporalregularizationcomponent.Thepipelineof\n\ntheorientationinvariantfeatureembeddingcomponentis\n\npresentedinFig.\n2,includingthreesub-modules,\ni.e.the\norientation-basedregionproposalmodule(Sec.\n3.1),the\norientation-basedfeatureextractionmodule(Sec.\n3.2),and\ntheorientationinvariantfeatureaggregationmodule(Sec.\n3.3).Firstly,vehicleimagesarefedintotheregionpro-\nposalmodule,whichproducestheresponsemapsof20ve-\n\nhiclekeypoints.Thekeypointsarethenclusteredintofour\n\norientation-basedregionproposalmasks.Afterwards,the\n\noriginalimagetogetherwiththefourregionproposalmasks\n\nareutilizedbythefeaturelearningmoduletoobtainone\n\nglobalfeaturevectorandfourregionfeaturevectors.Fi-\n\nnally,thesefeaturesarefusedbytheaggregationmodule\n\nthatoutputsanorientationinvariantfeaturevector.Besides\n\nlearningtheabovementionedappearancefeaturerepresen-\n\ntations,aregularizationstrategy(Sec.\n3.4)isadoptedby\nmodelingthespatio-temporalrelationsbetweentheprobe\n\nandgalleryimages.Trainingdetailsoftheproposedframe-\n\nworkareintroducedinSec.\n3.5.3.1.Orientation-basedRegionProposal\nAsshowninFig.\n2(a),aregionproposalnetworkisin-\ntroducedinthissection,whichcontainstwosteps,\ni.e.vehi-\nclekeypointpredictionandorientation-basedregionmask\n\ngeneration.Theproposedregionproposalnetworktakes\n\ntheimageasinputandestimatesthevehiclekeypointlo-\n\ncations.Fourorientation-basedregionproposalmasksare\n\nthengeneratedbasedonthekeypoints.\nFigure3.Illustrationofthe20selectedvehiclekeypoints.The20\n\npointsareclusteredintofoursetsbasedontheirorientations,\ni.e.,thefrontface,thebackface,theleftfaceandtherightface.\nTherststepoftheregionproposalnetworkistopredict\noneresponsemapforeachvehiclekeypoint.Aslistedin\n\nTable.\n1andshowninFig.\n3,20keypointsarespeciedfor\nthevehicleReIDtask.Insteadofdirectlypredictingbound-\n\narypointsorcornerpoints,thesekeypointsarechosenas\n\nsomediscriminativelocationsorsomemainvehiclecom-\n\nponents,e.g.thewheels,thelamps,thelogos,therear-view\n\nmirrors,thelicenseplates.\nInspiredbytheStackedHourglassNetworkswhichgen-\nerateresponsemapsofhumanjointsinastackedcoarse-to-\n\nnemannerforhumanposeestimation[\n13],anhourglass-\nlikefullyconvolutionnetworkisadoptedtogenerateve-\n\nhiclekeypointresponsemaps.Thekeypointregressor\n\ntakestheimageasinputandoutputsoneresponsemap\n\nFiRXY(i1,...,\n20)foreachofthe20keypoints,\nwhereXandYarethehorizontalandverticaldimensions\nofthefeaturemaps.\nThetargetresponsemapshaveGaussian-likeresponses\naroundthegroundtruthlocationsofkeypointsandusedas\n\ntrainingsupervisions.However,theHourglassmodel[\n13]iscomputationalexpensive.Modicationstothenetwork\n\naremadetoreducemodelcomplexityandalsopreservethe\n\nqualityofoutputkeypointresponsemaps.Theinputim-\n\nagesize,thenumberofframeworkstagesandthechan-\n\nnelnumbersofconvolutionlayersareallreducedforfast\n\ncomputation.Theper-pixelcrossentropylossbetweenesti-\n\nmatedresponsemapsandthegroundtruthmapsisadopted\n\nfortrainingthenetwork.\nThesecondstepoftheregionproposalnetworkis\ntogeneratefourorientation-basedregionmasks.As\n\nintroducedinSec.\n1,therearealwayssomeinvisi-\nbleregionsforvehiclesinspecicorientations.Toad-\n\ndresstheissueofinvisiblekeypointsandmakefull\n\nuseofthegeometricalrelationshipsamongkeypoints,\n\nthe20keypointsindexedinTable\n1areassignedto\nfourclusters,\ni.e.,C1=[5\n,6,7,8,9,10,13,14],C2=[15,16,17,18,19,20],C3=[1\n,2,6,8,11,14,15,17],and\nC4=[3\n,4,5,7,12,13,16,18],correspondingtothekey\npointsbelongingtothevehiclesfrontface,backface,left\n381\n'b'1left-frontwheel11leftrear-viewmirror\n\n2left-backwheel12rightrear-viewmirror\n\n3right-frontwheel13right-frontcornerofvehicletop\n\n4right-backwheel14left-frontcornerofvehicletop\n\n5rightfoglamp15left-backcornerofvehicletop\n\n6leftfoglamp16right-backcornerofvehicletop\n\n7rightheadlight17leftrearlamp\n\n8leftheadlight18rightrearlamp\n\n9frontautologo19rearautologo\n10frontlicenseplate20rearlicenseplate\nTable1.Denitionofthe20selectedvehiclekeypoints.\n\n\nFigure4.Examplesofthefouroutputresponsemasksoftheori-\n\nentationbasedregionproposalmodule.Theinputimageandthe\n\ncorrespondingfourregionmasks,\ni.e.R1offrontface,\nR2ofthe\nrearface,\nR3oftheleftfaceand\nR4oftherightface,areshown\nineachrow,fromlefttorightrespectively.Featuresofinvisible\n\nfaces,\ne.g\n.,R2of(a)and(c),and\nR1of(b),generallyhavelowre-\nsponsemasks.Afeatureaggregationmethodisadoptedtoreduce\n\ntheirimpactonthenalfeaturevector.\n\nface,andrightface,respectively.Thenaloutputregion\n\nmasksarecomputedasthesummationofallthefeature\n\nmapsbelongingtoeachcluster,\ni.e.Ri=liFl,(i=1,2,3,4).(1)Examplesoftheoutputregionmasks\nRiareshowninFig.\n4.Fromtheresults,wecanobservethatvisibleregion\nmasksgenerallyhavelargerresponsesthantheinvisible\n\nones,whichdemonstratethatthelearnedkeypointlocal-\n\nizationmodelnotonlyestimatesthekeypointlocationsbut\n\nalsodiscriminatesthevisiblekeypointsfromtheinvisible\n\nones.Astheinvisibleregionmasksmaynotbesuitablefor\n\nfeatureextraction,theorientationinvariantfeatureaggrega-\n\ntionisproposedinSec.\n3.2tohandlesuchproblem.\n3.2.Orientation-basedFeatureExtraction\nInthefeatureextractionmodule,deepconvolutionalneu-\nralnetwork(CNN)isadoptedtoobtainonefeaturevec-\n\ntorfromthewholevehicleimageandfourorientation-\n\nrelatedregionfeaturevectorsfromthefourcorresponding\n\nregions.ThenetworkstructureisshowninFig.\n2(b),which\ncontainstwoconvolutionstages,\ni.e.Stage-1,andStage-\n2.Theglobalfeatureandlocalfeaturesareextractedina\n\nbackbone-branchfashion.\nInStage-1,inputimagesareresizedto\n192192andconvolvedbythreeconvolutionlayersandtwoinception\n\nmodules[\n19].Theoutputfeaturemapisdenotedas\nfC10withspatiosize\n1212.InStage-2,\nf10isassignedto\nvebranches,includingoneglobalbranchandfourlocal\n\nregionbranches.Fortheglobalbranch,theglobalfeature\n\nmapf10isconvolvedbyonemoreinceptionmodule,and\nresultsinasetof\n66featuremaps.Thenglobalaver-\nagepoolingisappliedonthesefeaturemapstoobtaina\n\n1536-dimensionalglobalfeaturevector\nf20.Foreachlocal\nbranch,thecorrespondingorientation-relatedregionmasks\n\nRi(i=1,2,3,4)isresizedtothesamesizeas\nf10,and\nf10iselement-wiselymultipliedbytheregionmaskstoobtain\n\nthelocalfeaturemaps,\ni.e.f1i=f10Ri(i=1,2,3,4).Theresults\nf1iisfurtherconvolvedbyonemoreinception\nmodule.Globalmaxpoolingisadoptedsincethemaximum\n\nresponsesaremoresuitableforguidingfeatureextraction\n\nfromlocalregions.Everyregionbranchoutputsa1536-\n\ndimensionalfeaturevector\nf2i(i=1,2,3,4).3.3.OrientationInvariantFeatureAggregation\nAsshowninFig.\n2(c),thefeatureaggregationmod-\nuletakestheve1536-dimensionalfeaturevectors,includ-\n\ningoneglobalfeature\nf20andfourlocalfeatures\nf2i,(i=1,2,3,4),asinputandcomputesone256-dimensionalfea-\nturevectorasoutput.Intheaggregationmodule,thefourlo-\n\ncalfeaturevectorsarerstconcatenatedandpassedthrough\n\nafullyconnectedlayer,yieldingasetofscalars\n{ei}.Then\n{ei}passthroughtheSoftmaxoperator,producingasetof\nweights{wi},where\niwi=1,(i=1,2,3,4).Thefour\nlocalfeaturevectorsareweightedby\n{wi}andconcatenated\ntogetherwiththeglobalfeaturevector\nf20.Theconcatena-\ntionresult\n[f20,w1f21,w2f22,w3f23,w4f24]T,isthenfedinto\nafullyconnectedlayerandtheoutputdimensionisreduced\n\nto256.The256-dimensionalfeaturevectoristhenalag-\n\ngregatedfeaturevectorofthewholeimage,includingthe\n\nfourlocalregionfeaturesandoneglobalregionfeature.\nExamplesinFig.\n5demonstratestheeffectivenessofthe\nproposedorientationinvariantfeatureaggregationmodule.\n\nFeaturesofselectedvehicleimagesintheVeRi-776testset\n\nareprojectedto2-dimensionalspaceusingt-SNE[\n10]and\narevisualizedinFig.\n5(b).Wecanobservethatfeatures\nofthesameidentitycanbeclusteredtogether,nomatter\n\nwhichorientationthevehicleimageis.Moreover,theinput\n\nvehicleimagesandthecorrespondinglearnedweightsof\n\ntwoclustersareshowninFigs.\n5(a)and(c).Foreachimage,\ntheweightsarelearnedforthefoursidefaces,\ni.e.front,\nback,left,andright,andthenthelocalfeaturesarefused\n\nbasedontheseweights.Wecanobservethatvisibleface\n\naremorelikelytohavehigherweightsthaninvisibleones.\n382\n'b'\n\n\n\nFigure5.Illustrationoftheorientationinvariantfeatureswith\n\nt-SNE[\n10].(a,c)Theinputimagesoftwodifferentvehicles\nandtheircorrespondinglearnedweightsfordifferentorientations,\n\nwherevisiblefacesaremorelikelytohavehigherweights.(b)2D\n\nfeatureprojectionsofselectedvehicleimagesintheVeRi-776test\n\nsetusingt-SNE.\n\n3.4.Regularizationbyspatio-temporalModeling\nInreal-worldscenarios,appearancefeaturesmaynotbe\nadequateenoughtodistinguishonevehiclefromothers,es-\n\npeciallywhenthevehiclesareofthesamemodelwithout\n\npersonalizeddecorations.However,insurveillanceappli-\n\ncations,thelocationandtimeinformationofavehicleis\n\neasytoobtain.Itispossibletorenevehiclesearchresults\n\nwiththehelpofsuchspatio-temporalinformation.\nInordertoinvestigatewhetherthespatio-temporalcon-\nstraintsareeffectiveforvehicleReID,weanalyzethevehi-\n\ncletransitionintervalbetweenpairsofcameras.Foreach\n\ncamerapair,thetransitionintervalcanbemodeledasa\n\nrandomvariablethatfollowssomeprobabilitydistribution.\n\nDuetotheGaussian-likeandlongtailpropertyofthetransi-\n\ntioninterval,thelogarithmicnormaldistributionisadopted\n\ntomodelthisrandomvariable.Given\nlandeastheleav-\ningandenteringcameras,theconditionalprobabilityofthe\n\ntransitioninterval\nbetweenlandecanbeestimatedasthe\nlog-normaldistribution\np(|l,e\n),p(|l,e\n;l,e\nl,e\n)=ln\nN(;l,e\nl,e\n)=1l,e\n2exp(lnl,e\n)222l,e\n,(2)wherel,e\nl,e\naretheparameterstobeestimatedfor\neachcamerapair\n(l,e\n).Themodelparameterscanbeesti-\nmatedbymaximizingthefollowinglog-likelihoodfunction,\nL(|l,e\n;l,e\nl,e\n)=Nn=11nN(lnn;l,e\nl,e\n),(3)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nFigure6.Illustrationoftheproposedspatio-temporalregulariza-\n\ntionstep.Imagesintherstrowarethequeryimageandthe\n\ntop-5retrievalresultswithoutspatio-temporalregularization.The\n\ngreenboxrepresentsthecorrecthitwhileredonesdenotenon-\n\ncorrespondingvehicles.Thespatio-temporaldistance\nDsbetweenprobeandgalleryimagesarecomputedusingtheestimatedlog-\n\nnormaldistribution.Thegalleryimagesareregularized,andthe\n\nresultsafterregularizationareshowninthebottomrow.\n\nwheren(n=1,2,3,...,N\n)istransitionintervalbe-\ntweencamerapair\n(l,e\n)sampledfromthetrainingset,and\ncontainsallthetimeintervalsamplesbetweenthetwo\ncamerasinthetrainingset.\nDuringtheretrievalprocess,theappearancedistance\nDaisrstcomputedviatheproposedorientation-invariantfea-\n\ntureaggregationframework.Thespatio-temporaldistance\n\nDsisthencomputedforregularization.AsshowninFig.\n6,thetransitiontimeintervalbetweentwocameras\n(l,e\n)canbecomputedas\n=|tlte|,where\ntl,tearetheap-\npearancetimeofthisvehicleatthesetwocameras.The\n\nspatio-temporalprobabilitycanbecomputedas\np(|l,e\n;l,e\nl,e\n)=ln\nN(;l,e\nl,e\n).(4)Highprobabilitiescorrespondstosmalldistances,thus\nDs=1/(1+\ne(p(|l,e\n;l,el,e)0.5)).(5)Finallytheoverallsimilaritydistancebetweentheprobeand\n\ngalleryimagesarecalculatedastheweightedsummation,\nD=Da+s,(6)whereissetto2and\nissetto0.1inourexperiments.\n3.5.TrainingScheme\nAnalternativetrainingstrategyisadoptedtotrainthe\nproposednetwork,whichincludethefollowingfoursteps.\n383\n'b'Figure7.Datasetsusedfortrainingtheproposedmodel,including\n\n(a)VeRi-776[\n9],(b)VehicleID[\n8],(c)BoxCars21k[\n17],and(d)\nCompCars[\n23].(i)ThebackboneofStage-1andtheglobalbranchofStage-\n\n2aretrainedfromrandominitialization,byapplyingsuper-\n\nvisiontotheglobalfeatureoffullimageregion.(ii)With\n\nStage-1xed,thefourorientationbranchesaretrainedwith\n\nparametersinitializedastheglobalbranchofStage-2,since\n\ntheglobalbranchandtheorientationbranchesinStage-2\n\nsharethesamestructure.Thefourbranchesaretrainedsep-\n\naratelybygivingtheclassicationlabelassupervision.(iii)\n\nWithStage-1andallbranchesofStage-2xed,theorienta-\n\ntioninvariantfeatureaggregationmoduleistrained.(iv)Ini-\n\ntializingallthemoduleswithparameterslearnedfromthe\n\nabovesteps,andalltheparametersarejointlyne-tuned.\n\nWhentrainingthemodel,existingvehicledatasetsareused\n\nandthecross-entropyclassicationlossisadopted.\n\n4.Experiments\n\n4.1.Datasets\nFourexistingvehicledatasetsareusedtotrainthepro-\nposedorientationinvariantnetwork,includingVeRi-776\n\n[9],VehicleID[\n8],BoxCars21k[\n17],andCompCars[\n23].VeRi-776[\n9]isabenchmarkdatesetforvehicleReIDthatis\ncollectedfromreal-worldsurveillancescenarios,withover\n\n50,000imagesof776vehiclesintotal.VehicleID[\n8]is\nasurveillancedataset,whichcontains26,267vehiclesand\n\n22,1763imagesintotal.BoxCars21k[\n17]isdesignedfor\nne-grainedvehiclemakeandmodelrecognition.Theim-\n\nagesofBoxCars21kareorderedbyidentitiesthuscanalso\n\nbeusedforvehicleReID.Thisdatasetcontains21,250vehi-\n\ncleidentitiesand63,750images.CompCars[\n23]isalsode-\nsignedforne-grainedvehiclemodelclassication,which\n\nconsistsofbothwebimagesandsurveillanceimages.How-\n\never,weonlyutilizeitssurveillancedatafortraining.Im-\n\nagesinthisdatasetaresortedbyvehiclemodelandcolor\n\nannotationsarealsoprovided.Wecanroughlyregardve-\n\nhicleswithspecicmodelandspeciccolorasaspecic\nDataset#TrnID/img\n#PrbID/img\n#GalID/img\nVeRi-776[\n9]576/30188200/1678200/11579VehicleID[\n8]13164/1001822400/176382400/2400BoxCars[\n17]21250/63750-/--/-CompCars[\n23]1118/31148-/--/-Table2.Statisticsofthefourdatasetsusedinourexperiment.The\n\nnumberoftrainidentitiesandimages,togetherwiththenumberof\n\nqueryandgalleryidentitiesandimagesarelisted.\n\nidentitytotrainourReIDnetwork.\nWemergethetrainingsamplesfromVeRi-776[\n9]and\nVehicleID[\n8],togetherwithallthesamplesfromBox-\nCars21k[\n17]andCompCars[\n23]intoonelargetrainingset\ntotrainourorientationinvariantnetwork.Thetrainingset\n\ncontainsaround225,268imagesof36,108identitiesinto-\n\ntal.SelectedsamplesofthesedatasetsareshowninFig.\n7andthestatisticalinformationarelistedinTable\n2.4.2.Evaluationresults\nTheproposedframeworkiscomparedwithtwostate-\nof-the-artvehicleReIDapproaches,\ni.e.PROVID[\n9]and\nDRDL[\n8],togetherwithseveralconventionalpersonReID\nmethods,i.e.BagofWordswithColorNameDescriptor\n(BOW-CN)[\n28],theLOMOfeature[\n6],andtheKEPLER\nmethod[\n11],whichlearnssalientregionsforconstruct-\ningdiscriminativefeatures.Performanceevaluationiscon-\n\nductedonVeRi-776[\n9]andVehicleID[\n8],andmultiple\nevaluationmetricsareapplied.\nFortheVeRi-776dataset,cumulativematchcurve\n(CMC)metric[\n3]isadoptedforevaluation.Foreachiden-\ntity,oneimageisrandomselectedfromallthegalleryim-\n\nagestogeneratethegalleryset,whiletheprobesetremains\n\nunchanged.Therandomselectionprocedurewasrepeated\n\nfor100timestoobtainanaverageCMCresult.Theimage-\n\nto-trackmetric(HIT)introducedin[\n9]isalsoevaluated,\nandthereisnorandomgalleryselectionprocessfortheHIT\n\nevaluation.Meanaverageprecision(mAP)isalsoadoptfor\n\nevaluationfollowing[\n9].FortheVehicleIDdataset,standardCMCmetricis\nadoptedwithrandomgalleryselection.Onlythe\nLarge\ntestsetofVehicleIDisevaluatedsinceitisthemostchallenging\n\nset.Duringtesting,oneimageisrandomlyselectedfrom\n\noneidentitytoobtainagallerysetwith2,400images,then\n\ntheremaining17,638imagesareallusedasprobeimages.\nEvaluationresultsonbothdatasetsarelistedinTable\n3.Theproposedapproachachievesthebestperformance\nonbothdatasets,whichismuchbetterthanthecompared\n\nmethods.Threeexperimentsareconductedtodemonstrate\n\ntheeffectivenessoftheproposedmainmodules.Firstly,\n\nabaselinesingle-branchappearancemodel(Baseline)is\n\nevaluatedtoinvestigatetheperformanceofourproposed\n\nnetwork.Signicantperformancegaincanbeobserved\n384\n'b'VeRi-776\nmAPHIT@1CMC@1CMC@5BOW-CN[\n28]12.2033.9--LOMO[\n6]9.6425.3--KEPLER[\n11]33.5368.748.264.3PROVID[\n9]27.7761.4--Baseline45.5088.6662.886.7Ours48.0089.4365.987.7Ours+ST\n51.4292.3568.389.7VehicleID\nCMC@1CMC@5KEPLER[\n11]45.468.9VGG+TripletLoss[\n8]31.950.3VGG+CCL[\n8]32.953.3MixedDiff+CCL[\n8]38.261.6Baseline63.280.6Ours67.082.9Table3.Experimentresultsoftheproposedmethodandother\n\ncomparedmethodsontheVeRi-776datasetandVehicleIDdataset.\n\nMultipleevaluationcriteriaareadopted,includingmAP,HITac-\n\ncuracy,andCMCaccuracy.Baselinereferstooursinglemain-\n\nbranchmodelwithoutregionfeatures,Oursdenotesthepro-\n\nposedorientationinvariantnetwork,andOurs+STindicatesthe\n\noverallpipelinewiththeproposedspatio-temporalregularization\n\nmodel.\ncomparedwithothermethods.Secondly,theproposedori-\n\nentationinvariantnetwork(Ours)istestedbyusingthe\n\nproposedorientationinvariantappearancefeatures.Region\n\nfeaturesareintroducedandtheperformancecanbefur-\n\ntherimproved.Finally,theoverallframework(Ours+ST)\n\nisevaluatedbyaddingthespatio-temporalregularization\n\nmodule.ThisexperimentisonlyconductedonVeRi-776\n\nsincenospatio-temporalinformationisprovidedonVehi-\n\ncleID.Experimentalresultdemonstratesthattheregulariza-\n\ntionmoduleresultsinsignicantimprovements.\nNotethattheHIT@1resultsoftheproposedmethod\ninTable\n3outperformexistingmethodsbylargemargins.\nThisisbecausetheHIT@1metricisbasedonimage-to-\n\ntracksearch,andallgalleryimages(whichcontainmultiple\n\ngroundtruthresults)aresearchedtoidentifytheprobeiden-\n\ntity.Ifthereexistsonegalleryimageofthisidentitythat\n\nsharessimilarorientationastheprobeimage,suchgallery\n\nimagescanbeeasilyfound.Inthiscase,CMCshouldbe\n\namorepropermetricforvehicleReIDevaluation,sincethe\n\nimage-to-tracksearchmayalwaysobtainsearchresultswith\n\nsimilarorientationastheprobeimage.\n\n5.AblationStudy\n\n5.1.InvestigationsontheKeypointRegressor\nInthissection,theproposedkeypointregressoristhor-\noughlyinvestigated,intermsoftheregressionaccuracyand\n\nrelationshipbetweenlandmarksandorientations.Inorder\n\ntotrainandevaluatethekeypointregressor,locationsof\nModelsr0=5r0=3L2-Loss90.5087.4Cross-EntropyLoss\n92.0588.8Table4.Evaluationresultsofthelandmarkregressor.\n\nFigure8.(a)Annotationexamples.(b)Regressionresults.\n20keypointsareannotatedmanuallyontheimagesofthe\n\nwholeVeRi-776[\n9]datasetandsomeannotationresultsare\nshowninFig.\n8(a).Duringthetestingstage,responsemaps\nofthetestingimagesareextractedandthekeypointsare\n\npredictedasthelocationswithmaximumresponsevalue.If\n\nthedistancebetweentheregressedlandmarklocationand\n\nthegroundtruthlocationissmallerthanathreshold\nr0,this\nkeypointisconsideredascorrectlypredicted,otherwisethe\n\nkeypointiswronglypredicted.Invisiblekeypointsareig-\n\nnoredintheevaluationstepsincetheyareexpectedtobe\n\nhandledbytheproposedorientationinvariantmodule.The\n\npredictionaccuracyofvisiblekeypointsarelistedinTable\n4,andtwolossfunctionsareadoptedtotrainthelandmark\nmodel.Wecanobservethat\n88.8%keypointscanbecor-\nrectlypredictedwithin\nr0=3pixelstothegroundtruth\n(thenalresponsemapisofsize\n4848).Somekeypoint\npredictionresultsareshowninFig.\n8(b).Investigationsarealsoconductedontherelationshipbe-\ntweenkeypointlocationsandorientationclasses.Since\n\nnoorientationinformationisprovidedfortheVeRi-776\n\ndataset,fourorientations,\ni.e.front,back,left,right,are\nmanuallyannotatedfortheVeRi-776dataset.Withthean-\n\nnotatedtrainingimages,avehicleorientationclassieris\n\ntrainedbyusingthe20landmarkresponsemapsasinput.\n\nThetrainedclassieryieldsa\n93.2%accuracyonthetesting\nimages,whichdemonstratesourkeypointresponsemaps\n\ncontainsufcientinformationtoinfervehiclesorientation.\n\nItalsovalidatesthatclusteringlandmarksbyorientation\n\nisreasonableintheproposedorientation-basedregionpro-\n\nposalmodule.\n5.2.ComparisonwithAttentionMechanism\nBesidestheproposedorientation-basedregionproposal\nmodule,attentionmechanismisanotherpossiblewaytose-\n\nlectthesalienceregionsandtoobtainlocalregionfeatures.\n\nExperimentsareconductedtocomparethesoftattention\n\nmechanismandtheproposedorientationbasedregionpro-\n\nposalframework.\nWefollowthestandardstrategyas[\n24]toimplementthe\n385\n'b'Figure9.Comparisonbetweenthelearnedsaliencemasksbythe\n\nattentionmechanism(inredboxes)andtheorientationbasedre-\n\ngionproposals(ingreenboxes).\n\nattentionmodule.\n11convolutionlayersareemployed\ntoproducesaliencemasksfromtheinputfeaturemaps.For\n\nthesesaliencemasks,locationswithlargervaluerepresent\n\nsalienceregionsthatareusefulforfeatureextraction.The\n\nsaliencemasksarethenpassedthroughasigmoidnonlinear\n\nunit,yieldingvaluesintherange\n(0,1).Finally,element-\nwisemultiplicationisappliedbetweentheinputfeature\n\nmapsandthesaliencemasktooutputthelocalfeaturemaps\n\nofthesalienceregions.\nThecomparedattentionnetworkissimilarwiththepro-\nposedpipelineintermsofnetworkarchitecture.Theonly\n\ndifferenceisthatthe4orientation-basedregionproposals\n\narereplacedwith\nNattentionmasks.Theattentionmodule\ntakesthefeaturemaps\nf10asinputandoutput\nNattentionmasks.Experimentsareconductedbysettingthenumber\n\nofattentionmask\nN=2,4,8forcomparisonandCMC\nresultsarereportedinTable\n5.Thecomparedattentionnetworkandtheproposedorien-\ntationinvariantnetworkisdifferent.Inattentionnetwork,\n\nthesalienceregionsarelearnedbytheattentionmodule\n\nautomatically,whileinourproposednetworktheregion\n\nmasksaredenedbasedonorientationinformation(four\n\nsidefacesofthevehiclewithdifferentlandmarkpoints)and\n\nthelandmarksareregressedbythetrainedlandmarkregres-\n\nsor.\nTheorientationbasedregionproposalsandthesalience\nmaskslearnedbytheattentionmodulesarevisualizedin\n\nFig.9,whicharealsodifferent.Attentionmasksarerea-\nsonablebutnotstable,\ni.e.,differentattentionblocksmay\nprovidequitesimilarsaliencemasks(therstandthelast\n\nmaskinFig.\n9(b)).However,ourorientationbasedregion\nproposalsismuchmorestable,becausetheyaredesigned\n\ntofocusondifferentfaces.ExperimentalresultsinTable\n5alsodemonstratethattheorientationbasedregionproposals\n\noutperformattentionmechanism.\nModelsVeRi-CMC@1\nVehicleID-CMC@1\nattention-2branch63.664.3attention-4branch64.865.6attention-8branch62.763.8Ours65.966.6Table5.Quantitativeresultsbyreplacingorientationbasedregion\n\nproposalwithattentionmasks.\nModelsVeRi-CMC@1\nVID-CMC@1base88.6663.2global+KISSME[\n4]89.0263.5global+MLAPG[\n7]87.8963.1global+Zhangetal\n.[26]89.1163.8nal89.4367.7nal+KISSME[\n4]89.7567.8nal+MLAPG[\n7]88.8967.1nal+Zhangetal\n.[26]90.0568.0Table6.Experimentalresultswithandwithoutmetriclearning.\n\nTherstgroupofexperimentsarebasedonourglobalfeatures\n\nwhilethesecondgrouparebasedonourglobal+localfeatures\n\n5.3.MetricLearningMethods\nInpersonRe-IDmethods,metriclearningisusuallyuti-\nlizedtorenethenalsearchresults.Inthissection,we\n\ntestedsomepopularmetriclearningmethodsutilizedinper-\n\nsonRe-IDmethods,includingKISSME[\n4],MLAPG[\n7]andZhang\netal\n.[26].Weutilizedthethreemetriclearn-\ningalgorithmsonfeaturesextractedfrombothourbaseline\n\nmodel(globalfeature)andnalmodel(global+localfea-\n\nture)andconductedtwogroupsofexperiments.Theresults\n\nonboththeVeRiandVehicleID(VID)datasetsarelistedin\n\nTable\n6:Asshowinthetable,metriclearningmethodsdolead\ntoadditionalperformancegainbasedonourfeatures.Note\n\nthatinthesecondgroupofexperimentsperformancegains\n\nbymetriclearningmethodsaresmaller,whichsuggestthat\n\nourglobal+localfeaturesaremorediscriminativethanthe\n\nglobalones.\n6.Conclusion\nInthispaper,anovelframeworkisproposedforve-\nhicleReID,whichconsistsoftwomaincomponents,\ni.e.theorientationinvariantfeatureembeddingandthespatial-\n\ntemporalregularization.Localregionfeaturesareextracted\n\nbasedonthelocationsofkeypoints.Thfeaturesarealigned\n\nandcombinedtoformorientationinvariantfeaturerepre-\n\nsentations.Spatiotemporalregularizationisadoptedforre-\n\nningtheretrievalresults.Theproposedframeworkiseval-\n\nuatedontwopublicvehicleReIDdatasetsandstate-of-the-\n\nartperformanceisachieved.Detailedinvestigationsofthe\n\nproposedmethodsareconductedintermsofthelandmark\n\nregressorandthecomparisonswithattentionmechanism.\n386\n'b'References\n[1]D.Chen,Z.Yuan,B.Chen,andN.Zheng.Similaritylearn-\ningwithspatialconstraintsforpersonre-identication.In\n\nCVPR,2016.\n2[2]D.Cheng,Y.Gong,S.Zhou,J.Wang,andN.Zheng.Per-\nsonre-identicationbymulti-channelparts-basedcnnwith\n\nimprovedtripletlossfunction.In\nCVPR,2016.\n2[3]D.Gray,S.Brennan,andH.Tao.Evaluatingappearance\nmodelsforrecognition,reacquisition,andtracking.In\nProc.\nIEEEInternationalWorkshoponPerformanceEvaluation\n\nforTrackingandSurveillance(PETS)\n,volume3,2007.\n6[4]M.Koestinger,M.Hirzer,P.Wohlhart,P.M.Roth,and\nH.Bischof.Largescalemetriclearningfromequivalence\n\nconstraints.In\nCVPR,pages22882295.IEEE,2012.\n8[5]W.LiandX.Wang.Locallyalignedfeaturetransforms\nacrossviews.In\nCVPR,2013.\n2[6]S.Liao,Y.Hu,X.Zhu,andS.Z.Li.Personre-identication\nbylocalmaximaloccurrencerepresentationandmetric\n\nlearning.In\nCVPR,June2015.\n2,6,7[7]S.LiaoandS.Z.Li.Efcientpsdconstrainedasymmetric\nmetriclearningforpersonre-identication.In\nICCV,pages\n36853693,2015.\n8[8]H.Liu,Y.Tian,Y.Wang,L.Pang,andT.Huang.Deep\nrelativedistancelearning:Tellthedifferencebetweensimilar\n\nvehicles.In\nCVPR,pages21672175,2016.\n2,6,7[9]M.T.M.H.LiuX.,LiuW.Adeeplearning-basedapproach\ntoprogressivevehiclere-identicationforurbansurveil-\n\nlance.In\nECCV,2016.\n2,6,7[10]L.v.d.MaatenandG.Hinton.Visualizingdatausingt-sne.\nJournalofMachineLearningResearch\n,9(Nov):25792605,\n2008.4,5[11]N.Martinel,C.Micheloni,andG.L.Foresti.Kernel-\nizedsaliency-basedpersonre-identicationthroughmultiple\n\nmetriclearning.\nIEEETransactionsonImageProcessing\n,24(12):56455658,2015.\n6,7[12]T.Matsukawa,T.Okabe,E.Suzuki,andY.Sato.Hierarchi-\ncalgaussiandescriptorforpersonre-identication.In\nCVPR,2016.2[13]A.Newell,K.Yang,andJ.Deng.Stackedhourglassnet-\nworksforhumanposeestimation.In\nECCV,pages483499.\nSpringer,2016.\n2,3[14]S.Ren,X.Cao,Y.Wei,andJ.Sun.Facealignmentat3000\nfpsviaregressinglocalbinaryfeatures.In\nCVPR,pages\n16851692,2014.\n2[15]F.Schroff,D.Kalenichenko,andJ.Philbin.Facenet:Auni-\nedembeddingforfacerecognitionandclustering.In\nCVPR,pages815823,2015.\n2[16]Z.Shi,T.M.Hospedales,andT.Xiang.Transferringase-\nmanticrepresentationforpersonre-identicationandsearch.\n\nInCVPR,2015.\n2[17]J.Sochor,A.Herout,andJ.Havel.BoxCars:3Dboxesas\nCNNinputforimprovedne-grainedvehiclerecognition.In\n\nCVPR,June2016.\n2,6[18]Y.Sun,D.Liang,X.Wang,andX.Tang.Deepid3:Face\nrecognitionwithverydeepneuralnetworks.\narXivpreprint\narXiv:1502.00873,2015.\n2[19]C.Szegedy,W.Liu,Y.Jia,P.Sermanet,S.Reed,\nD.Anguelov,D.Erhan,V.Vanhoucke,andA.Rabinovich.\n\nGoingdeeperwithconvolutions.In\nCVPR,June2015.\n4[20]S.-E.Wei,V.Ramakrishna,T.Kanade,andY.Sheikh.Con-\nvolutionalposemachines.In\nCVPR,pages47244732,\n2016.2[21]L.Wu,C.Shen,andA.v.d.Hengel.Personnet:Person\nre-identicationwithdeepconvolutionalneuralnetworks.\n\narXivpreprintarXiv:1601.07255\n,2016.\n2[22]T.Xiao,H.Li,W.Ouyang,andX.Wang.Learningdeepfea-\nturerepresentationswithdomainguideddropoutforperson\n\nre-identication.arXivpreprintarXiv:1604.07528\n,2016.\n2[23]L.Yang,P.Luo,C.ChangeLoy,andX.Tang.Alarge-scale\ncardatasetforne-grainedcategorizationandverication.\n\nInCVPR,June2015.\n2,6[24]Z.Yang,X.He,J.Gao,L.Deng,andA.Smola.Stacked\nattentionnetworksforimagequestionanswering.In\nCVPR,June2016.\n7[25]D.ZapletalandA.Herout.Vehiclere-identicationforauto-\nmaticvideotrafcsurveillance.In\nCVPRWorkshops\n,pages\n2531,2016.\n2[26]L.Zhang,T.Xiang,andS.Gong.Learningadiscrimina-\ntivenullspaceforpersonre-identication.In\nCVPR,pages\n12391248,2016.\n8[27]H.Zhao,M.Tian,S.Sun,J.Shao,J.Yan,S.Yi,X.Wang,\nandX.Tang.Spindlenet:Personre-identicationwithhu-\n\nmanbodyregionguidedfeaturedecompositionandfusion.\n\nInCVPR,2017.\n2[28]L.Zheng,L.Shen,L.Tian,S.Wang,J.Wang,andQ.Tian.\nScalablepersonre-identication:Abenchmark.In\nICCV,pages11161124,2015.\n2,6,7387\n'