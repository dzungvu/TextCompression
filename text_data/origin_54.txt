b'xviii IEEE Transactions \non Consumer Electronics, Vol. \n38, No. 1, FEBRUARY \n1992 THE JPEG STILL PICTURE COMPRESSION STANDARD \nGregory K. Wallace Multimedia Engineering Digital Equipment Corporation \nMay nard, Massachusetts This paper is a revised version \nof an article \nby the same \ntitle and author which appeared in the April I991 issue of Communications of the ACM. Abstract For the past \nfew years, a joint \nISO/CCITT committee known as JPEG (Joint Photographic Experts \nGroup) has been working to \nestablish the first international \ncompression standard for continuous-tone still images, \nboth grayscale and color. JPEGs proposed standard aims to be generic, to support a wide variety of applications for continuous-tone images. \nTo meet the \ndiffering needs of many applications, the JPEG standard includes \ntwo basic compression methods, \neach with various modes \nof operation. A DCT-based method \nis specified for \nlossy compression, and a predictive method for lossless \ncompression. JPEG features a simple lossy technique known as the Baseline method, a subset of the other DCT-based modes \nof operation. The Baseline method has been by far the most widely \nimplemented JPEG method to date, and is sufficient \nin its own right for \na large number of \napplications. This \narticle provides an overview of the JPEG standard, and focuses in detail on the Baseline \nmethod. 1 Introduction Advances over the past decade in many aspects of digital technology - especially devices for \nimage acquisition, data storage, \nand bitmapped ptlnting and display - have brought \nabout many applications of digital imaging. \nHowever, these applications \ntend to be specialized due to their relatively \nhigh cost. With the possible exception \nof facsimile, digital \nimages are not commonplace in general-purpose computing systems the way text and \ngeomemc graphics are. \nThe majority of modem business and consumer usage \nof photographs and other types \nof images takes place \nthrough more \ntraditional analog \nmeans. The key obstacle for many applications is the vast amount of data required to represent \na digital image directly. A digitized version of a single, color picture \nat TV resolution contains \non the order of one million bytes; 35 resolution requires \nten times that \namount. Use of digital images often is not viable due to high storage or transmission costs, even when image capture and display devices \nare quite \naffordable. Modem image compression technology \noffers a \npossible solution. State-of-the-art techniques \ncan compress typical images from 1/10 to 1/50 their uncompressed size without visibly \naffecting image quality. But compression technology \nalone is \nnot sufficient. For digital image applications involving \nstorage or transmission to become widespread in todays marketplace, \na standard image compression method is needed to \nenable interoperability \nof equipment from different manufacturers. \nThe CCITT \nrecommendation for \ntodays ubiquitous \nGroup 3 fax machines E171 is a dramatic example of how a standard compression method can enable an important image application. The Group \n3 method, however, \ndeals with bilevel images only \nand does not address photographic \nimage compression. For the past \nfew years, a standardization effort known by the acronym JPEG, for Joint Photographic Experts \nGroup, has been working toward establishing the \nfirst international digital \nimage compression \nstandard for \ncontinuous-tone (multilevel) \nstill images, both grayscale and color. The joint in JPEG \nrefers to a collaboration between CCITT and ISO. JPEG convenes officially as the IS0 committee designated JTCl/SC2/WGlO, but operates in close informal collaboration with CCIlT SGVIII. JPEG will be both an IS0 Standard and a CCITT Recommendation. The text of both will \nbe identical. Photovideotex, desktop publishing, \ngraphic arts, color facsimile, newspaper Wirephoto transmission, medical imaging, and many other continuous-tone \nimage applications require \na compression standard in order to develop significantly beyond their \npresent state. \nJPEG has undertaken the \nambitious task of developing a Presented at 3rd Annual Digital Video \nWorkshop Revised manuscript received December 6, 1991 0098 3063/92 $03.00 CJ 1992 IEEE 11 ~ ~ _____~- - I~ 'b'Wallace: The JPEG Still Picture Compression Standard xix general-purpose compression standard \nto meet \nthe needs of almost all continuous-tone still-image \napplications. If this goal proves \nattainable, not only will individual applications flourish, but exchange \nof images across \napplication boundaries \nwill be facilitated. This latter feature will become increasingly important \nas more image applications \nare implemented on general-purpose computing systems, \nwhich are themselves becoming \nincreasingly interoperable and intemetworked. For \napplications which require specialized \nVLSI to meet their compression and decompression speed \nrequirements, a common method will provide \neconomies of scale not possible \nwithin a single \napplication. This article gives an overview \nof JPEGs proposed \nimage-compression standard. Readers without prior \nknowledge of JPEG or compression based on the \nDiscrete Cosine Transform \n(DCT) are encouraged \nto study first the detailed description \nof the Baseline \nsequential codec, \nwhich is the basis for all of the DCT-based decoders. While \nthis article \nprovides many details, many more are necessarily omitted. The reader \nshould refer to \nthe IS0 draft standard [2] before attempting implementation. \nSome of the earliest industry attention to the \nJPEG proposal has been \nfocused on the Baseline sequential \ncodec as a motion image compression \nmethod - of the intraframe class, where each \nframe is encoded as a separate image. This \nclass of motion image coding, \nwhile providing \nless compression than interframe methods like MPEG, has greater flexibility for \nvideo editing. While this paper focuses only \non JPEG as a still picture standard \n(as IS0 intended), it is interesting to note that JPEG is likely to \nbecome a \nde facto intraframe motion standard \nas well. 2 Background: Requirements and \nSelec- tion Process JPEGs goal has \nbeen to develop a \nmethod for continuous-tome image compression \nwhich meets the following requirements: \n1) be at or near the \nstate of the art with regard to compression rate and accompanying image \nfidelity, over a wide \nrange of image quality \nratings, and especially \nin the range \nwhere visual \nfidelity to the original \nis characterized as very good to excellent: also, the encoder should be \nparameterizable, so that the \napplication (or user) can set the desired compression/quality \ntradeoff; be applicable \nto practically any kind of continuous-tone digital source image \n(i.e. for most \npractical purposes not be restricted to images of certain dimensions, color spaces, pixel aspect \nratios, etc.) \nand not be limited \nto classes of imagery with restrictions on scene content, such as \ncomplexity, range \nof colors, or statistical properties: 3) have tractable computational complexity, \nto make feasible software implementations \nwith viable performance on a range of CPUs, \nas well as hardware implementations \nwith viable cost \nfor applications requiring \nhigh performance; have the following modes of operation: 4) Sequential encoding: each image component \nis encoded in a single \nleft-to-right, top-to-bottom scan; Progressive encoding: \nthe image is encoded in multiple scans \nfor applications in which transmission time \nis long, and the \nviewer prefers to watch \nthe image build up in multiple coarse-to-clear passes; \nLossless encoding: the image \nis encoded to guarantee exact \nrecovery of every source \nimage sample \nvalue (even though the \nresult is \nlow compression compared \nto the lossy modes): Hierarchical encoding: the image \nis encoded at multiple resolutions \nso that lower-resolution versions may be accessed without \nfirst having to decompress the image \nat its \nfull resolution. In June 1987, JPEG conducted a selection process \nbased on \na blind assessment \nof subjective picture \nquality, and narrowed 12 proposed methods \nto three. Three informal working groups formed \nto refine them, \nand in January 1988, a second, \nmore rigorous selection \nprocess [19] revealed that the ADCT proposal [ll], based on the \n8x8 DCT, had produced the best picture \nquality. At the time \nof its selection, \nthe DCT-based method \nwas only partially defined for some \nof the modes \nof operation. From 1988 through 1990, JPEG undertook \nthe sizable task of defining, documenting, simulating, \ntesting, validating, and simply agreeing \non the plethora \nof details necessary for genuine interoperability and \nuniversality. Further history \nof the JPEG effort is \ncontained in [6,7,9, 183. 'b'xx IEEE Transactions on Consumer Electronics, Vol. 38, No. 1, FEBRUARY 1992 3 Architecture of the Proposed Standard \nThe proposed standard contains \nthe four modes of operation identified previously. \nFor each mode, \none or more distinct codecs are specified. Codecs within a mode differ according to the precision \nof source image samples they can handle or the entropy \ncoding method they use. Although the \nword codec (encoder/decoder) is used \nfrequently in this article, there is \nno requirement that implementations must include both an encoder and a decoder. Many applications will \nhave systems or devices which require only \none or the other. \nThe four modes of operation and their various \ncodecs have resulted from JPEGs goal of being generic and from the diversity of \nimage formats across applications. \nThe multiple pieces \ncan give the impression \nof undesirable complexity, \nbut they \nshould actually \nbe regarded as a comprehensive toolkit which can \nspan a wide range of continuous-tone image applications. It is unlikely that \nmany implementations will utilize \nevery tool -- indeed, most of the early implementations \nnow on the market (even \nbefore final \nIS0 approval) have implemented only the \nBaseline sequential codec. \nThe Baseline sequential \ncodec is inherently a rich and \nsophisticated compression method which will be sufficient for \nmany applications. Getting this \nminimum JPEG capability implemented properly and interoperably will provide \nthe industry with an \nimportant initial capability \nfor exchange of images across vendors and \napplications. 4 Processing Steps for DCT-Based Coding \nFigures 1 and 2 show the key processing steps \nwhich are the \nheart of the DCT-based modes \nof operation. These figures illustrate \nthe special case \nof single-component (gray scale) image compression. The reader can grasp the \nessentials of DCT-based compression by thinking of it as \nessentially compression of a stream of 8x8 blocks of grayscale image samples. Color image compression can then be approximately regarded as compression of multiple grayscale images, \nwhich are either compressed entirely one at a \ntime, or \nare compressed by alternately interleaving 8x8 sample \nblocks from each in turn. For DCT sequential-mode codecs, \nwhich include the Baseline sequential codec, \nthe simplified diagrams indicate how single-component compression \nworks in a fairly complete way. Each \n8x8 block is input, makes its way through each processing step, and yields output \nin compressed form \ninto the data stream. For DCT progressive-mode codecs, \nan image buffer \nexists prior to the entropy coding step, so that an image can be stored and then \nparceled out \nin multiple scans \nwith suc- cessively improving quality. For the hierarchical \nmode of operation, the steps \nshown are used as building blocks within a larger framework. 4.1 8x8 FDCT and IDCT At the input \nto the encoder, source \nimage samples \nare grouped into 8x8 blocks, shifted from unsigned integers with ran e [0, 2 - 11 to signed integers \nwith range [-2-, 2$-l-1], and input \nto the Forward \nDCT (FDCT). At the output \nfrom the decoder, the Inverse \nDCT (IDCT) outputs 8x8 sample \nblocks to form the \nreconstructed image. The following equations are \nthe idealized mathematical definitions of the 8x8 FDCT and 8x8 \nIDCT: 77 FO y=o C(U), C(v) = 1 otherwise. The DCT is related to the Discrete Fourier \nTransform (DFT). Some simple intuition \nfor DCT-based compression can be obtained by viewing the FDCT as a harmonic analyzer and the IDCT as a harmonic synthesizer. Each 8x8 block of source image samples is effectively \na 64-point discrete signal \nwhich is a function of the two spatial dimensions x and y. The FDCT takes such a signal as its input and decomposes it into 64 orthogonal basis signals. \nEach contains one of the 64 unique two-dimensional \n(2D) spatial frequencies which comprise the input signals \nspectrum. The ouput \nof the FDCT is the set of 64 basis-signal amplitudes or \nDCT coefficients whose values are \nuniquely determined by the particular @-point input signal. The DCT coefficient values \ncan thus be regarded as the relative amount of the 2D \nspatial frequencies contained \nin the @-point input signal. \nThe coefficient with zero frequency in both \ndimensions is called the DC \ncoefficient and the remaining 63 coefficients are called the AC coefficients. Because sample values \n'b'Wallace: The JPEG Still Picture Compression Standard 8x8 blocks DCT-Based Encoder \n/ / - IW 9 + FDCT -jr Quantizer j Entropy Encoder 1 Source Image Data \nCompressed Specifications Specifications \nImageData Figure 1. DCT-Based Encoder Processing Steps \nCompressed Image Data Specifications Figure 2. DCT-Based Decoder Processing Steps \ntypically vary slowly from point to point across \nan image, the FDCT processing \nstep lays the foundation \nfor achieving data compression \nby concentrating most of the signal \nin the lower spatial frequencies. For a \ntypical 8x8 sample block \nfrom a typical source image, \nmost of the spatial frequencies have zero or near-zero \namplitude and need not be encoded. \nAt the decoder the IDCT reverses \nthis processing step. It takes the 64 DCT coefficients (which \nat that point have been quantized) and reconstructs a @-point ouput \nimage signal \nby summing the basis \nsignals. Mathematically, the \nDCT is one-to-one mapping for \n64-point vectors between \nthe image and \nthe frequency domains. If the FDCT \nand IDCT could be \ncomputed with perfect accuracy \nand if the DCT coefficients were \nnot quantized \nas in the following description, the \noriginal @-point signal could be exactly recovered. \nIn principle, the DCT introduces no \nloss to the source \nimage samples; \nit merely transforms \nthem to a domain \nin which they can \nbe more efficiently encoded. Some properties \nof practical FDCT and IDCT \nimplementations raise the issue of what precisely should be required by the JPEG standard. \nA fundamental property \nis that the FDCT and \nIDCT equations contain transcendental functions. \nConsequently, no physical implementation can \ncompute them with perfect accuracy. Because \nof the DCTs application importance and \nits relationship to the DR, many different algorithms \nby which the Reconstructed Image Data FDCT and IDCT \nmay be approximately computed have \nbeen devised [16]. Indeed, research \nin fast DCT algorithms is ongoing and no single algorithm \nis optimal for all \nimplementations. What is optimal in software for a general-purpose \nCPU is unlikely to be optimal in firmware for a programmable DSP \nand is certain to be suboptimal for dedicated \nVLSI. Even in light of the \nfinite precision of the DCT \ninputs and outputs, independently designed implementations \nof the very \nsame FDCT or IDCT algorithm \nwhich differ even minutely in the precision \nby which they \nrepresent cosine terms or intermediate results, or in the way they sum and round \nfractional values, will eventually produce slightly different \noutputs from identical inputs. \nTo preserve freedom \nfor innovation and customization within implementations, \nJPEG has chosen \nto specify neither a unique \nFDCT algorithm or a unique IDCT \nalgorithm in its proposed standard. This makes \ncompliance somewhat more \ndifficult to confirm, because two compliant encoders (or decoders) \ngenerally will not \nproduce identical outputs given identical inputs. \nThe JPEG standard \nwill address this issue by specifying an accuracy test as part of its compliance tests for all DCT-based encoders and \ndecoders; this is to ensure against crudely inaccurate \ncosine basis functions \nwhich would \ndegrade image \nquality. 'b',. - xxii For each DCT-based mode of operation, the JPEG proposal specifies separate \ncodecs for images with 8-bit and 12-bit (per component) source image samples. The 12-bit codecs, \nneeded to accommodate certain types \nof medical and other images, require greater \ncomputational resources to achieve the required FDCT \nor IDCT accuracy. Images with \nother sample precisions can usually \nbe accommodated by either an 8-bit or 12-bit codec, but this must be \ndone outside the JPEG standard. For example, it would \nbe the responsibility of an application to decide \nhow to fit or pad a 6-bit \nsample into the 8-bit encoders input \ninterface, how to unpack it at the decoders output, \nand how to encode any necessary related information. \n4.2 Quantization After output \nfrom the FDCT, each \nof the 64 DCT coefficients is uniformly quantized in conjunction with a 64-element Quantization Table, \nwhich must be specified by the application \n(or user) as an input to \nthe encoder. Each element \ncan be any integer value from \n1 to 255, which specifies the \nstep size \nof the quantizer for \nits corresponding DCT coefficient. The purpose of quantization is \nto achieve further \ncompression by representing DCT coefficients with no greater precision \nthan is necessary to \nachieve the desired \nimage quality. Stated another \nway, the goal of this processing \nstep is to discard information \nwhich is not visually \nsignificant. Quantization is \na many-to-one mapping, and therefore is fundamentally lossy. It is the \nprincipal source \nof lossiness in DCT-based encoders. Quantization is \ndefined as division of each DCT coefficient by its corresponding quantizer step \nsize, followed by rounding to the \nnearest integer: \nF(u v) Q(u4 (3) #(U, v) = Integer Round (-) IEEE Transactions on Consumer Electronics, Vol. 38, No. 1, FEBRUARY 1992 ... This output \nvalue is \nnormalized by the quantizer step size. Dequantization is the inverse function, \nwhich in this case \nmeans simply that the normalization \nis removed by multiplying by the step size, which returns the result \nto a representation appropriate for input \nto the \nIDCT: When the aim is to compress the image \nas much as possible without visible artifacts, each step size. ideally should be chosen as the perceptual threshold or just noticeable difference \nfor the visual contribution \nof its corresponding cosine basis function. \nThese thresholds are also functions \nof the source image characteristics, display characteristics \nand viewing distance. For applications in \nwhich these variables \ncan be reasonably well defined, psychovisual experiments \ncan be \nperformed to \ndetermine the best thresholds. \nThe experiment described in [12] has led to a set \nof Quantization Tables for \nCCIR-601 [4] images and \ndisplays. These have been \nused experimentally by JPEG members and will \nappear in the IS0 standard as a matter of information, but \nnot as a requirement. 4.3 DC Coding and Zig-Zag Sequence \nAfter quantization, the \nDC coefficient is treated \nseparately from the 63 AC coefficients. The DC coefficient is a measure of the average value \nof the 64 image samples. Because there is \nusually strong correlation between the DC \ncoefficients of adjacent 8x8 blocks, the quantized \nDC coefficient is \nencoded as the difference from the DC term of the previous \nblock in the encoding order (defined \nin the following), \nas shown in Figure 3. This special treatment \nis worthwhile, \nas DC coefficients frequently contain \na significant fraction \nof the total image energy. Ac07 Differential DC encoding ACII Zig-zag sequence Figure 3. Preparation of Quantized Coefficients for \nEntropy Coding \n'b'Wallace: The JPEG Still Picture Compression Standard xxiii Finally, all \nof the quantized coefficients are ordered \ninto the zig-zag sequence, also shown \nin Figure 3. This ordering helps \nto facilitate entropy coding \nby placing low-frequency coefficients \n(which are more \nlikely to be nonzero) before high-frequency \ncoefficients. 4.4 Entropy Coding \nThe final DCT-based encoder processing step \nis entropy coding. This step achieves additional \ncompression losslessly by encoding the quantized DCT coefficients more compactly \nbased on their statistical \ncharacteristics. The JPEG proposal specifies \ntwo entropy coding methods \n- Huffman coding [8] and arithmetic coding \n1151. The Baseline sequential codec \nuses Huffman coding, but codecs with \nboth methods are specified for \nall modes of operation. It is useful to consider entropy coding \nas a 2-step \nprocess. The \nfirst step converts \nthe zig-zag sequence \nof quantized coefficients \ninto an intermediate sequence \nof symbols. The second \nstep converts the symbols \nto a data stream in which the symbols no longer \nhave externally identifiable boundaries. The \nform and \ndefinition of the intermediate symbols \nis dependent on both the \nDCT-based mode \nof operation and the entropy \ncoding method. \nHuffman coding requires \nthat one or more sets of Huffman code tables be specified \nby the application. The same \ntables used to compress an image are \nneeded to decompress it. Huffman tables may be predefined \nand used within \nan application \nas defaults, or computed specifically for \na given image \nin an initial statistics-gathering pass prior to compression. Such \nchoices are the business \nof the applications \nwhich use JPEG; the JPEG proposal \nspecifies no required \nHuffman tables. \nHuffman coding \nfor the Baseline \nsequential encoder \nis described in detail in section 7. By contrast, the particular arithmetic coding \nmethod specified in the JPEG proposal [2] requires no tables to be externally input, because it is able to adapt to the image statistics as it encodes the image. \n(If desired, statistical conditioning tables can be \nused as inputs for slightly better \nefficiency, but \nthis is not required.) Arithmetic coding \nhas produced 5-10% better compression than Huffman for many of the images \nwhich JPEG members have \ntested. However, some \nfeel it is more complex \nthan Huffman \ncoding for certain implementations, for example, the highest-speed \nhardware implementations. (Throughout JPEGs \nhistory, complexity has \nproved to \nbe most elusive as a practical memc \nfor comparing compression methods.) \nIf the only difference between \ntwo JPEG codecs is the entropy coding method, transcoding \nbetween the two \nis possible by simply entropy decoding with one \nmethod and entropy recoding \nwith the other. 4.5 Compression and Picture Quality \nFor color images \nwith moderately complex scenes, \nall DCT-based modes of operation \ntypically produce the following levels of picture quality for \nthe indicated ranges of compression. These \nlevels are only a \nguideline - quality and compression can \nvary significantly according to source image \ncharacteristics and scene content. (The \nunits bits/pixel here mean the total number of bits in the compressed image \n- including the chrominance components \n- divided by the number of samples in the luminance component.) \n0.25-0.5 bitdpixel: moderate \nto good quality, sufficient for \nsome applications; \n0.5-0.75 bitdpixel: good to very good quality, sufficient for \nmany applications: 0.75- 1/5 bits/pixel: excellent quality, sufficient \nfor most applications; \n0 1.5-2.0 bits/pixel: usually indistinguishable from the original, sufficient for \nthe most \ndemanding applications. 5 Processing Steps for Predictive \nLossless Coding After its selection of a DCT-based method \nin 1988, JPEG discovered \nthat a DCT-based lossless mode was difficult to define as a practical standard against \nwhich encoders and decoders could be independently \nimplemented, without placing severe constraints \non both encoder and decoder implementations. \nJPEG, to meet \nits requirement for \na lossless mode of operation, has chosen a simple predictive \nmethod which is wholly independent of the DCT processing described previously. Selection \nof this method was not \nthe result of rigorous competitive evaluation \nas was the DCT-based method. Nevertheless, the JPEG \nlossless method produces \nresults which, in light of its simplicity, are surpisingly close \nto the state of the art for lossless continuous-tone compression, \nas indicated by a recent technical report \n[5]. Figure 4 shows the \nmain processing steps for a \nsingle-component image. \nA predictor combines \nthe values of \nup to three neighboring samples \n(A, B, and C) to form a prediction \nof the sample indicated \nby X in Figure 5. This prediction \nis then subtracted from the \nactual value of sample \nX, and the difference \nis encoded 'b'.- CB AX xxiv IEEE Transactions on Consumer Electronics, \nVol. 38, No. 1, FEBRUARY 1992 Lossless Encoder Source Image Data \np&l Specifications Compressed Image Data \nFigure 4. Lossless Mode Encoder Processing Steps \nlosslessly by either of the entropy cdng methods - Huffman or arithmetic. Any one of the eight predictors \nlisted in Table 1 (under selection-value) \ncan be \nused. Selections 1, 2, and 3 are one-dimensional predictors \nand selections 4, 5, 6 and 7 are two-dimensional predictors. Selection-value \n0 can only be used for \ndifferential coding in the hierarchical mode of operation. The entropy coding is nearly identical to that used \nfor the \nDC coefficient as described in section 7.1 (for Huffman coding). t.. m I Figure 5. 3-Sample Prediction Neighborhood For the lossless \nmode of operation, two different codecs are specified \n- one for \neach entropy coding method. The encoders can use \nany source image precision from 2 to 16 bits/sample, and can use any \nof the predictors except selection-value \n0. The decoders \nmust handle any of the sample precisions and any \nof the predictors. \nLossless codecs typically produce around \n2: 1 compression for color images with moderately complex \nscenes. selection- value prediction 0 no prediction 1 A 2 B 3 C 4 A+B-C 5 A+(@ -C)/2) 6 B+( (A-C)/2) 7 (A+B)12 Table 1. Predictors for Lossless Coding 6 Multiple-Component Images \nThe previous sections discussed the \nkey processing steps of the DCT-based and predictive lossless \ncodecs for the case of single-component source images. \nThese steps accomplish the image \ndata compression. \nBut a good deal of the JPEG proposal is also concerned with \nthe handling and control of color (or other) \nimages with multiple components. JPEGs aim for a generic compression standard requires its proposal \nto accommodate a variety of source image formats. 6.1 Source Image Formats \nThe source image model \nused in \nthe JPEG proposal is an abstraction from a variety of image types and \napplications and consists of only what is necessary to \ncompress and reconstruct digital \nimage data. The reader should recognize that \nthe JPEG compressed data format does not encode enough information to serve as a complete image \nrepresentation. For example, JPEG does not specify \nor encode any information on pixel aspect ratio, color space, \nor image acquisition characteristics. 'b'Wallace: The JPEG Still Picture Compression Standard .I 1 Nf . Nf- 1 XXV Ci top bottom (a) Source image \nwith multiple components \n(b) Characteristics of an image component \nFigure 6. JPEG Source Image Model \nFigure 6 illustrates the JPEG source image model. A source image contains \nfrom 1 to 255 image components, sometimes called color or \nspectral bands or channels. Each component consists \nof a rectangular \narray of samples. A sample is defined to be an unsigned integer with precision P bits, with any value in the range \n[0, 2-1]. All samples of all components within the same source image \nmust have the same \nprecision P. P can \nbe 8 or 12 for DCT-based codecs, and 2 to 16 for predictive codecs. \nThe ith component has sample dimensions \nxi by yi. To accommodate formats \nin which some image \ncomponents are sampled at different rates \nthan others, components can have \ndifferent dimensions. The \ndimensions must have a mutual \nintegral relationship defined by Hi and Vi, the relative horizontal and \nvertical sampling factors, which must be \nspecified for each component. Overall image dimensions \nX and Y are defined \nas the maximum xi and yi for all \ncomponents in the image, and \ncan be \nany number \nup to 216. H and V are allowed \nonly the integer values \n1 through 4. The encoded parameters are \nX, Y, and His and Vis for each components. \nThe decoder reconstructs \nthe cfimensions xi and yi for each component, according \nto the following relationship shown \nin Equation 5: where r 1 is the ceiling function. \n6.2 Encoding Order and Interleaving \nA practical image compression standard \nmust address how systems will need \nto handle the data during the \nprocess of decompression. Many applications need \nto pipeline the process of displaying or printing \nmultiple-component images \nin parallel with the process of decompression. For \nmany systems, this is only feasible if the components are interleaved together \nwithin the compressed data stream. \nTo make the \nsame interleaving \nmachinery applicable to both DCT-based and predictive codecs, \nthe JPEG proposal has defined \nthe concept of data unit. A data unit is a sample \nin precfictive \ncodecs and an 8x8 \nblock of samples in DCT-based codecs. \nThe order \nin which compressed data units are placed in the compressed data stream \nis a generalization \nof raster-scan order. Generally, data \nunits are ordered from left-to-right and top-to-bottom according \nto the orientation shown \nin Figure 6. (It is the responsibility of applications to define which edges of a source image \nare top, bottom, left and right.) If an image component \nis noninterleaved (i.e., compressed without being \ninterleaved with other components), compressed data \nunits are ordered in a pure \nraster scan as shown in Figure 7. top left right bottom Figure 7. Noninterleaved Data Ordering When two or more components \nare interleaved, each \ncomponent Ci is partitioned into rectangular regions \nof Hi by Vi data units, as shown in the generalized \nexample of Figure 8. Regions are ordered within a component from left-to-right and top-to-bottom, and \nwithin a region, data \nunits are ordered from left-to-right and top-to-bottom. The \nJPEG proposal defines \nthe term Minimum Coded Unit (MCU) \nto be \nthe smallest \n'b",. . xxvi IEEE Transactions on Consumer Electronics, Vol. 38, No. 1, FEBRUARY 1992 CS~: H1=2, Viz2 CS~: H2=2, V2=l Cs3: H3=1, V3=2 CS4: H4=1, V4=1 \n0 3 34 - z 7 Pa e. 5 012345 2 'I 3 012 Figure 8. Generalized Interleaved \nData Ordering \nExample group of interleaved data units. For the example shown, MCU, consists of data units taken \nfirst from the \ntop-left-most region of C,, followed by data units from the same region \nof C2, and likewise for \nC3 and C,. MCU, continues the \npattem as shown. Thus, interleaved \ndata is an ordered sequence of MCUs, and the number of data units contained \nin an MCU is determined by the number of components interleaved and their relative \nsampling factors. The maximum number of components which can \nbe interleaved is 4 and the maximum number of data units in an MCU is 10. The latter restriction \nis expressed as shown in \nEquation 6, where the summation is over \nthe interleaved components: HixViI1O (6) all i in interleave Because of this restriction, \nnot every \ncombination of 4 components which can be represented in noninterleaved order within a JPEG-compressed image \nis allowed to be interleaved. Also, note that the JPEG proposal \nallows some components to be interleaved and some to be noninterleaved within the same compressed image. 1 6.3 Multiple Tables In addition to the interleaving control discussed \npreviously, JPEG codecs must control application \nof the proper table \ndata to the proper \ncomponents. The same quantization table \nand the same \nentropy coding table (or set \nof tables) must be used to encode all samples within a component. JPEG decoders can store up to 4 different quantization \ntables and up to 4 different \n(sets of) entropy coding tables simultaneously. \n(The Baseline \nsequential decoder is the \nexception; it can only store up to 2 sets of entropy coding tables.) This \nis necessary for \nswitching between different tables during \ndecompression of a scan containing multiple \n(interleaved) components, in order to apply the proper \ntable to \nthe proper \ncomponent. (Tables cannot be loaded during \ndecompression of a scan.) Figure \n9 illustrates the table-switching control \nthat must be \nmanaged in conjunction with multiple-component interleaving for the encoder side. (This simplified \nview does not distinguish between quantization and entropy \ncoding tables.) "b'Wallace: The JPEG Still Picture Compression Standard \nxxvii Compressed Image Data \nFigure 9. Component-Interleave and Table-Switching Control 7 Baseline and Other \nDCT Sequential Codecs The DCT sequential mode of operation consists \nof the FDCT and Quantization steps \nfrom section 4, and the \nmultiple-component control \nfrom section 6.3. In addition to the Baseline sequential \ncodec, other DCT sequential codecs are defined \nto accommodate the two different sample precisions \n(8 and 12 bits) and the two different types of entropy coding \nmethods (Huffman and arithmetic). Baseline sequential coding \nis for images with 8-bit samples and uses Huffman coding only. It also differs \nfrom the \nother sequential \nDCT codecs in that its \ndecoder can \nstore only two \nsets of Huffman tables (one AC table and~DC table per set). This restriction \nmeans that, for images \nwith three or four interleaved components, at least one set \nof Huffman tables must be \nshared by two components. This restriction \nposes no limitation at all for noninterleaved \ncomponents: a new set of tables can be loaded \ninto the decoder \nbefore decompression of a \nnoninterleaved component begins. \nFor many applications which do \nneed to \ninterleave three color components, \nthis restriction is hardly a limitation at all. Color spaces (YUV, CIELUV, \nCIELAB, and \nothers) which represent the chromatic (color) information in two components and the \nachromatic (grayscale) information in a third are more efficient for compression than spaces like RGB. \nOne Huffman table set can be used for the \nachromatic component and one for the \nchrominance components. \nDCT coefficient statistics are similar \nfor the \nchrominance components \nof most images, and one set of Huffman tables can encode both almost as optimally as two. The committee also \nfelt that early availability of single-chip implementations \nat commodity prices would encourage early acceptance of the JPEG proposal in a variety of applications. In 1988 when Baseline sequential was defined, the committees VLSI experts felt \nthat current technology made the \nfeasibility of crowding four \nsets of loadable Huffman tables \n- in addition to four \nsets of Quantization tables \n- onto a single commodity-priced \ncodec chip a risky proposition. The FDCT, Quantization, \nDC differencing, and zig-zag ordering processing steps for \nthe Baseline \nsequential codec proceed \njust as described in section 4. Prior to entropy coding, there \nusually are few nonzero and \nmany zero-valued coefficients. \nThe task \nof entropy coding is to encode these few coefficients efficiently. \nThe description \nof Baseline sequential \nentropy coding is given in two \nsteps: conversion \nof the quantized DCT coefficients into an intermediate sequence \nof symbols and assignment of variable-length codes \nto the \nsymbols. 7.1 Intermediate Entropy Coding Representations \nIn the intermediate symbol sequence, \neach nonzero \nAC coefficient is represented in combination with the \nrunlength (consecutive number) of zero-valued AC coefficients which precede it in the zig-zag sequence. \nEach such \nrunlength/nonzero-coefficient combination is \n(usually) represented \nby a pair of symbols: symbol-1 symbol-2 \n(RUNLENGTH, SIZE) (AMPLITUDE) Symbol-1 represents \ntwo pieces \nof information, RUNLENGTH and SIZE. Symbol-2 represents \nthe single piece \nof information designated AMPLITUDE, \nwhich is simply \nthe amplitude \nof the nonzero AC coefficient. RUNLENGTH is the number \nof consecutive zero-valued \nAC coefficients in the zig-zag sequence preceding the nonzero AC coefficient being represented. SIZE is \nthe number of bits used to \nencode AMPLITUDE - that is, to encoded symbol-2, by the signed-integer encoding used with \nJPEGs particular method of Huffman coding. \nRUNLENGTH represents zero-runs \nof length 0 to 15. Actual zero-runs in the zig-zag sequence \ncan be greater than 15, so the symbol-1 value (15, 0) is interpreted as the extension \nsymbol with runlength=16. There \ncan be \nup to three \nconsecutive (15, 0) extensions before the \nterminating symbol-1 whose RUNLENGTH value \ncompletes the \nactual runlength. The terminating \nsymbol-1 is always followed by a single symbol-2, \nexcept for the case in which the last run of zeros includes the last (63d) AC coefficient. In this frequent \ncase, the special symbol-1 \nvalue (0,O) means EOB (end of block), and can be viewed \nas an escape symbol which terminates the 8x8 sample block. \n'b'xxviii IEEE Transactions on Consumer Electronics, \nVol. 38, No. 1, FEBRUARY 1992 Thus, for each 8x8 block of samples, the zig-zag sequence of 63 quantized AC coefficients is represented as a sequence of symbol-1, symbol-2 symbol pairs, though each pair can have \nrepetitions of symbol-1 in the case of a long run-length or \nonly one symbol-1 in the case of an EOB. \nThe possible range of quantized AC coefficients determines the range \nof values which both \nthe AMPLITUDE and the SIZE information must represent. A numerical analysis \nof the 8x8 FDCT equation shows that, if the @-point (8x8 block) input \nsignal contains N-bit integers, \nthen the nonfractional part of the output \nnumbers (DCT coefficients) \ncan grow by at most 3 bits. This \nis also the largest possible \nsize of a quantized DCT coefficient when its quantizer step \nsize has integer value \n1. Baseline sequential has \n8-bit integer source \nsamples in the range \n[-27, 27-1], so quantized AC coefficient am litudes are covered by integers in the range \n[-21, 2 -13. The signed-integer encoding uses symbol-2 AMPLITUDE codes of 1 to 10 bits in length (so SIZE also represents values \nfrom 1 to lo), and RUNLENGTH represents values \nfrom 0 to 15 as discussed previously. \nFor AC coefficients, the structure \nof the symbol-1 and symbol-2 intermediate representations is illustrated \nin Tables 2 and 3, respectively. The intermediate representation \nfor an 8x8 sample \nblocks differential DC coefficient is structured \nsimilarly. Symbol- 1, however, represents only SIZE \ninformation; symbol-2 represents AMPLITUDE information as before: 18 symbol-1 symbol-2 \n(SIZE) (AMPLITUDE) Because the DC coefficient is differentially encoded it \n2ll-11 as \nthe AC coefficients, so one additional level \nmust be added to the bottom of Table 3 for DC coefficients. Symbol-1 for DC coefficients thus represents a value from \n1 to 11. is covered by twice as many integer values, \n[-2 il , SIZE I I 0 1 2 ... 9 10 RUN-SI= values 15 ZRL Table 2. Baseline Huffman Coding \nSymbol-1 Structure 7.2 Variable-Length Entropy Coding \nOnce the quantized coefficient data for \nan 8x8 block is \nrepresented in the intermediate \nsymbol sequence described above, variable-length \ncodes are assigned. For each 8x8 \nblock, the \nDC coefficients symbol-1 and symbol-2 representation is coded and output first. For both \nDC and AC coefficients, each symbol-1 is encoded with a variable-length code (VLC) \nfrom the \nHuffman table set \nassigned to the 8x8 blocks image component. Each symbol-2 is encoded \nwith a variable-length integer \n(VLI) code \nwhose length \nin bits is given in Table 3. VLCs and VLIs both are codes with variable lengths, but \nVLIs are not Huffman codes. An important distinction \nis that the length \nof a VLC (Huffman code) is not known until it \nis decoded, but the length of a VLI is stored \nin its preceding \nVLC. Huffman codes (VLCs) must \nbe specified extemally \nas an input to JPEG encoders. (Note that the form in which Huffman tables are represented in the data stream is \nan indirect specification \nwith which the decoder must construct the tables themselves prior \nto decompression.) The JPEG proposal includes an example set of Huffman tables in its information annex, \nbut because \nthey are application-specific, it specifies none for required \nuse. The VLI codes in contrast, are \nhardwired into the \nproposal. This is appropriate, because the VLI codes are far more numerous, can be computed rather than stored, and have not \nbeen shown to be appreciably more efficient when implemented as Huffman codes. 7.3 Baseline Encoding Example \nThis section gives an example of Baseline compression and encoding of a single 8x8 sample \nblock. Note that \na good deal of the operation of a complete JPEG Baseline encoder is omitted here, including creation \nof Interchange Format information (parameters, headers, \nquantization and Huffman tables), byte-stuffing, padding to \nbyte-boundaries prior to a marker code, and other key operations. Nonetheless, this \nexample should help to \nmake concrete much of the foregoing \nexplanation. Figure 10(a) \nis an 8x8 block of 8-bit samples, aribtrarily exuacted from a real image. The \nsmall variations from sample to sample indicate the predominance of low spatial frequencies. \nAfter subtracting 128 from each sample for the required \nlevel-shift, the \n8x8 block is input \nto the FDCT, equation (1). Figure \n1O(b) shows (to one decimal \nplace) the resulting \nDCT coefficients. Except for a \nfew of the lowest frequency coefficients, the amplitudes are quite \nsmall. \\--- Ill 'b'Wallace: The JPEG Still Picture Compression Standard \nmix 139 144 149 153 155 155 155 155 235.6 -1.0-12.1 -5.2 2.1 -1.7 -2.7 1.3 \n16 11 10 16 24 40 51 61 144 151 153 156 159 156 \n156 156 -22.6 -17.5 \n-6.2 -3.2 -2.9 -0.1 \n0.4 -1.2 12 12 \n14 19 26 58 60 55 150 155 160 \n163 158 \n156 156 156 -10.9 -9.3 -1.6 1.5 0.2 -0.9 \n-0.6 -0.1 14 13 16 24 40 57 69 \n56 159 161 162 160 160 \n159 159 159 -7.1 -1.9 0.2 \n1.5 0.9 -0.1 \n0.0 0.3 14 17 22 29 \n51 87 80 62 159 160 161 162 162 155 \n155 155 -0.6 -0.8 \n1.5 1.6 -0.1 -0.7 \n0.6 1.3 18 22 37 56 68 109 103 77 161 161 161 161 \n160 157 157 157 1.8 -0.2 \n1.6 -0.3 -0.8 1.5 1.0 -1.0 24 35 55 64 81 104 113 92 162 162 161 \n163 162 157 157 157 -1.3 -0.4 -0.3 -1.5 \n-0.5 1.7 \n1.1 -0.8 49 64 78 87 103 121 120 \n101 162 162 I61 161 163 \n158 158 \n158 -2.6 1.6 \n-3.8 -1.8 1.9 1.2 -0.6 -0.4 72 92 \n95 98 112 100 103 99 (a) source image samples \n(b) forward DCT coefficients (c) quantization table \n144 146 \n149 152 154 156 156 156 \n-2 -1 0 0 0 \n0 0 0 \n-24 -12 148 150 152 \n154 156 \n156 156 \n156 155 156 157 158 158 157 156 155 0 0 0 0 \n0 0 0 \n0 160 161 161 \n162 161 \n159 157 \n155 00000000 oOOooooo 163 163 \n164 163 \n162 160 158 \n156 00000000 163 164 164 164 162 \n160 158 157 \n00000000 160 161 162 \n162 162 \n161 159 \n158 00000000 158 159 161 \n161 162 161 159 \n158 15 0 -1 0 0 \n0 0 0 \n2400-100 0 0 \n0 0 \n-1 0 0 0 0 0 \n-14-13 0 0 0 0 0 0 \n00000000 00000000 00000000 (d) normalized quantized \n(e) denormalized quantized \n(0 reconstructed image samples \ncoefficients coefficients \nFigure 10. DCT and Quantization Examples \nFigure 1O(c) is the example quantization table \nfor luminance (grayscale) components included \nin the informational annex \nof the draft JPEG standard part \n1 [2j. Figure lO(d) shows the quantized \nDCT coefficients, normalized by their quantization table \nentries, as specified by equation (3). At the decoder \nthese numbers are denormalized according \nto equation (4), and input \nto the IDCT, equation \n(2). Finally, figure 10(Q shows the reconstructed sample \nvalues, remarkably similar \nto the \noriginals in 10(a). Of course, the numbers \nin figure 10(d) \nmust be \nHuffman-encoded before transmission \nto the decoder. The first \nnumber of the block \nto be encoded \nis the DC term, which must be differentially encoded. If the quantized \nDC term of the previous \nblock is, for example, 12, then the difference \nis +3. Thus, the intermediate representation \nis (2)(3), for \nSIZE=:! and AMPLITUDE=3. Next, the the quantized \nAC coefficients are encoded. \nFollowing the zig-zag \norder, the first non-zero coefficient is -2, preceded by a zero-run \nof 1. This yields an interme&ate representation \nof (1,2)(-2). Next encountered in the zig-zag order are three \nconsecutive non-zeros \nof amplitude - 1. This means \neach is preceded by a zero-run of length zero, for \nintermediate symbols \n(O,l)(-1). The last non-zero coefficient is -1 \npreceded by two zeros, for (2,1)(-1). \nBecause this is the last non-zero coefficient, the final symbol representing \nthis 8x8 block is EOB, or (0,O). Next the codes themselves \nmust be assigned. For this example, the VLCs (Huffman codes) from \nthe informational annex \nof [2j will be used. The \ndifferential-DC VLC for this example is: (2) 011 The AC luminance VLCs for this example are: (0,O) 1010 (OJ) 00 (1,2) 11011 (2,l) 11100 'b'.- IEEE Transactions \non Consumer Electronics, \nVol. 38, No. I, FEBRUARY 1992 The VLIs specified in [2] are related \nto the twos complement representation. They are: Thus, the bit-stream \nfor this 8x8 example \nblock is as follows. Note that \n31 bits are required to represent \n64 coefficients, which achieves compression of just under 0.5 bits/sample: 7.4 Other DCT Sequential Codes The structure of the 12-bit \nDCT sequential codec with Huffman \ncoding is a straightforward extension of the entropy \ncoding method described previously. \nQuantized DCT coefficients can be 4 bits larger, \nso the SIZE and AMPLITUDE information extend \naccordingly. DCT sequential with arithmetic coding is described \nin detail in [2]. 8 DCT Progressive Mode The DCT progressive mode of operation consists \nof the same FDCT and Quantization steps \n(from section 4) that are used by DCT sequential mode. The \nkey difference is \nthat each image component \nis encoded in multiple scans rather than in a single scan. \nThe first scan(s) encode a rough but \nrecognizable version of the image which can be transmitted quickly in comparison to the total \ntransmission time, and are refined by succeeding scans until \nreaching a level of picture quality that \nwas established by the quantization tables. \nTo achieve this requires the addition \nof an \nimage-sized buffer \nmemory at the output \nof the quantizer, before the input to entropy encoder. \nThe buffer memory must be of sufficient size to store the image as quantized DCT coefficients, each of which (if stored straightforwardly) is \n3 bits larger \nthan the source image samples. After each block of DCT coefficients is quantized, \nit is stored in the coefficient buffer \nmemory. The \nbuffered coefficients \nare then partially encoded in each of multiple scans. There are two complementary methods \nby which a block of quantized DCT coefficients may be partially encoded. First, only a specified band of coefficients from the zig-zag \nsequence need be \nencoded within a given scan. This procedure is called spectral selection, \nbecause each band \ntypically contains coefficients \nwhich occupy a lower or higher part of the spatial-frequency specmm for that 8x8 block. \nSecondly, the coefficients \nwithin the current band need not \nbe encoded to their full \n(quantized) accuracy in a given scan. Upon a coefficients first encoding, the \nN most significant bits can be encoded first, \nwhere N is specifiable. In subsequent scans, the less significant bits can \nthen be \nencoded. This procedure is \ncalled successive approximation. Both procedures can be used separately, or \nmixed in flexible combinations. I SIZE AMPLITUDE 1 -1,l -3,-2,2,3 -7..-4,4..7 -15..-8,8..15 -31 ..-16,16..31 -63..-32,32..63 127..-64.64.. 127 8 -255.- 128;128..255 9 -51 1..-256,256.3 1 10 -1023..-512,512..1023 Table 3. Baseline Entropy Coding Symbol-2 Structure Some intuition for spectral selection \nand successive approximation can be obtained from Figure 11. The \nquantized DCT coefficient information can be viewed as a rectangle for \nwhich the axes \nare the DCT coefficients (in zig-zag order) and their amplitudes. Spectral selection \nslices the information in one dimension and successive approximation in the other. \n9 Hierarchical Mode of Operation The hierarchical mode provides a pyramidal encoding of an image at multiple resolutions, \neach differing in resolution from its adjacent \nencoding by a factor of two in \neither the \nhorizontal or vertical \ndimension or both. The encoding \nprocedure can be summarized as follows: 1) Filter \nand down-sample the original \nimage by the desired \nnumber of multiples of 2 in each dimension. 2) Encode this reduced-size image using \none of the sequential DCT, progressive DCT, or lossless encoders described previously. \n3) Decode this \nreduced-size image and then \ninterpolate and up-sample \nit by 2 horizontally and/or vertically, \nusing the \nidentical interpolation filter \nwhich the receiver \nmust use. \n'b'Wallace: The JPEG Still Picture Compression Standard mi I DCT coefficients mage comDonent \n., 76 10 as @mtiz-ed MSB- LSB DCT coefficients (b) Sequential encodmg ~ 765 4 2nd scan grd scan grd scan . nth scan (?Se) 6th scan c) progressive encoding: spectral selection Figure 1 1. Spectral Selection and \nSuccessive Approximation Methods \nof Progressive Encoding d) progressive \nencoding: successive approximation 4) Use this up-sampled image \nas a prediction of the original at this resolution, and encode the difference image using \none of the sequential DCT, progressive \nDCT, or lossless encoders \ndescribed previously. \n5) Repeat steps \n3) and 4) until the full resolution \nof the image has been \nencoded. The encoding \nin steps 2) and 4) must be done using \nonly DCT-based \nprocesses, only lossless processes, \nor DCT-based processes with a final lossless \nprocess for each component. Hierarchical encodmg is useful in applications in which a very high resolution image \nmust be accessed by a lower-resolution display. \nAn example is an image scanned and \ncompressed at high resolution for a very high-quality printer, where the image must \nalso be displayed on a low-resolution PC video screen. 'b'mii IEEE Transactions \non Consumer Electronics, \nVol. 38, No. 1, FEBRUARY 1992 10 Other Aspects \nof the JPEG Proposal Some key aspects of the proposed standard can only \nbe mentioned briefly. Foremost among these are points concerning \nthe coded representation for compressed image data specified in addition to the encoding and decoding \nprocedures. Most importantly, an interchange format syntax is specified which ensures that a JPEG-compressed image can \nbe exchanged successfully between different application environments. \nThe format is structured in a consistent way for all \nmodes of operation. The interchange format always \nincludes all quantization \nand entropy-coding tables \nwhich were used to compress the image. Applications (and application-specific standards) \nare the users \nof the JPEG standard. The JPEG standard imposes no requirement that, within an applications environment, \nall or even any tables must be encoded with the compressed image \ndata during storage or transmission. This leaves \napplications the \nfreedom to \nspecify default \nor referenced tables \nif they are considered appropriate. \nIt also leaves them the responsibility \nto ensure that \nJPEG-compliant decoders used within \ntheir environment get loaded with the proper \ntables at the proper times, and that the proper tables are included in the interchange \nformat when a compressed image \nis exported outside the application. \nSome of the important applications \nthat are already in the process of adopting JPEG compression or have stated their interest \nin doing so are Adobes PostScript language for printing systems \n[ll, the Raster Content portion of the IS0 Office Document Architecture and Interchange Format [ 131, the future CCITT color facsimile standard, \nand the European ETSI videotext standard \n[lo]. 11 Standardization Schedule \nJPEGs IS0 standard will \nbe divided into \ntwo parts. Part 1 [2] will specify the \nfour modes \nof operation, the different codecs specified for those modes, and \nthe interchange format. \nIt will also contain \na substantial informational \nsection on implementation guidelines. Part \n2 [3] will \nspecify the \ncompliance tests which will \ndetermine whether an encoder implementation, a decoder implementation, or \na JPEG-compressed image \nin interchange format comply with \nthe Part \n1 specifications. In addition to the IS0 documents referenced, the \nJPEG standard will also be issued as CCIlT Recommendation T.8 1. There are two key balloting phases in the IS0 standardization process: a Committee Draft (CD) is balloted to determine promotion to Draft International Standard \n(DIS), and a DIS is balloted \nto determine promotion to International Standard \n(IS). A CD ballot requires four \nto six months \nof processing, and a DIS ballot requires six \nto nine \nmonths of processing. JPEGs Part 1 began DIS ballot in November 1991, and \nPart 2 began CD ballot in December 1991. Though there is no guarantee that the \nfirst ballot of \neach phase will \nresult in promotion to \nthe next, \nJPEG achieved promotion of CD Part 1 to DIS Part 1 in the first ballot. Moreover, \nJPEGs DIS Part 1 has undergone no technical changes (other than some minor corrections) since \nJPEGs final Working Draft (WD) [14]. Thus, Part \n1 has remained unchanged \nfrom the final \nWD, through CD, \nand into DIS. If all goes well, Part 1 should receive final approval \nas an IS in mid-1992, with Part 2 getting final IS approval about nine months later. 12 Conclusions The emerging \nJPEG continuous-tome image compression standard is not a panacea that will \nsolve the myriad issues which must be addressed before digital images will be fully integrated within all the \napplications that will ultimately benefit from them. For example, if two applications cannot \nexchange uncompressed images because \nthey use \nincompatible color spaces, aspect ratios, dimensions, etc. \nthen a common compression method \nwill not help. \nHowever, a great many applications are stuck be- \ncause of storage or \nmnsmission costs, because of ar- gument over which \n(nonstandard) compression method to use, or because VLSI codecs are too ex- pensive due to low volumes. For these applications, \nthe thorough technical evaluation, testing, selection, \nvalidation, and documentation work which JPEG \ncommittee members have performed is \nexpected to soon yield \nan approved international standard \nthat will withstand \nthe tests \nof quality and time. As di- verse imaging applications become increasingly im- \nplemented on open networked \ncomputing systems, the ultimate measure \nof the committees success will be when JPEG-compressed digital images come to be regarded and even taken \nfor granted \nas just an- other data type, as text and \ngraphics are today. 'b'Wallace: The JPEG Still Picture Compression Standard \nAcknowledgments The following longtime \nJPEG core members have \nspent untold hours (usually \nin addition to their real jobs ) to make this collaborative international \neffort succeed. Each \nhas made specific substantive \ncontri- butions to the JPEG proposal: Aharon Gill (Zoran, Israel), Eric Hamilton (C-Cube, USA), \nAlain Leger (CCETT, France), \nAdriaan Ligtenberg (Storm, \nUSA), Herbert Lohscheller (ANT, Germany), Joan \nMitchell (IBM, \nUSA), Michael Nier (Kodak, \nUSA), Takao Omachi (NEC, Japan), \nWilliam Pennebaker (IBM, USA), Henning Poulsen (KTAS, Denmark), \nand Jorgen \nVaaben (AutoGraph, Denmark). \nThe leadership efforts of Hiroshi Yasuda (NTT, Japan), \nthe Convenor of JTCl/SC2/WG8 from which JPEG was spawned, \nIstvan Sebestyen (Siemens, Germany), \nthe Special Rapporteur \nfrom CCITT SGVIII, and \nGraham Hudson \n(British Telecom U.K.) former JPEG chair and founder \nof the effort which became JPEG. The author regrets that space \ndoes not permit recognition of the many other individuals \nwho con- tributed to JPEGs work. \nThanks to Majid Rabbani of Eastman Kodak for pro- viding the example \nin section 7.3. The authors role within \nJPEG has been supported \nin a great number \nof ways by Digital Equipment Cor- \nporation References 1. 2. 3. 4. 5. 6. Adobe Systems \nInc. PostScript Language \nRefer- ence Manual. \nSecond Ed. Addison \nWesley, Menlo Park, \nCalif. 1990 Digital Compression and Coding \nof Continuous- tone Still Images, Part \n1, Requirements and \nGuidelines. ISO/IEC JTC \n1 Draft International \nStandard 10918-1, \nNov. 1991. Digital Compression and Coding \nof Continuous- tone Still Images, Part \n2, Compliance Testing. \nISODEC JTCl Committee Draft 10918-2, Dec. \n1991. Encoding parameters \nof digital television for studios. CCIR Recommendations, Recommen- \ndation 601,1982. Howard, P.G., and \nVitter, J.S. \nNew methods for lossless image compression \nusing arithmetic coding. Brown University Dept. \nof Computer Science Tech. Report \nNo. CS-91-47, Aug. 1991. Hudson, G.P. The development \nof photographic videotex in the UK. In Proceedings of the IEEE \nGlobal Telecommunications \nConference, IEEE Communication Society, 1983, pp. 3 19-322. \nxxxiii 7. Hudson, G.P., Yasuda, H., and \nSebestyCn, I. The international standardization \nof a still pic- ture compression technique. \nIn Proceedings of the IEEE Global Telecommunications \nConfer- ence, IEEE Communications \nSociety, Nov. 1988, pp. 1016-1021. 8. Huffman, D.A. \nA method \nfor the construction \nof minimum redundancy codes. \nIn Proceedings IRE, vol. 40, 1962, pp. 1098-1101. 9. LCger, A. Implementations of fast discrete co- \nsine transform for full color videotex services \nand terminals. \nIn Proceedings of the IEEE Global Telecommunications \nConference, IEEE Communications Society, 1984, pp. 333-337. 10. LCger, A., Omachi, T., and Wallace, G. The \nJPEG still picture compression algorithm. \nIn Optical Engineering, \nvol. 30, no. 7 (July 1991), \npp. 947-954. 11. LCger, A., Mitchell, M., and Yamazaki, \nY. Still picture compression algorithms evaluated for \nin- ternational standardization. \nIn Proceedings of the IEEE Global Telecommunications \nConfer- ence, IEEE Communications \nSociety, Nov. 1988, pp. 1028-1032. \n12. Lohscheller, H. A subjectively adapted image \ncommunication system. \nIEEE Trans. Commun. COM-32 (Dec. 1984), \npp. 1316-1322. 13. Office Document Architecture (ODA) \nand Inter- change Format, Part \n7: Raster Graphics Content \nArchitectures. ISODC JTCl International Standard 8613-7. \n14. Pennebaker, W.B., JPEG Tech. Specification, \nRevision 8. Informal Working paper JPEG-8- \nR8, Aug. 1990. \n15. Pennebaker, W.B., Mitchell, J.L., et. al. \nArith- metic coding \narticles. IBM J. Res. Dev., \nvol. 32, no. 6 (Nov. 1988), pp. 717-774. 16. Rao, K.R., \nand Yip, \nP. Discrete Cosine \nTransform--Algorithms, Advantages, Applica- \ntions. Academic Press, Inc. London, 1990. \n17. Standardization of Group 3 facsimile apparatus \nfor document transmission. CCITT Recommen- \ndations, Fascicle VII.2, Recommendation \nT.4, 1980. 18. Wallace, G.K. Overview \nof the JPEG (ISO/CCITT) still image compression standard. \nImage Processing Algorithms and Techniques. \nIn Proceedings of the SPIE, vol. 1244 (Feb. 1990), pp. 220-233. \n19. Wallace, G., Vivian, R,. and Poulsen, \nH. Sub- _- ____- 'b'-- XWxiV IEEE Transactions on Consumer Electronics, Vol. 38, No. 1, FEBRUARY 1992 jective testing results \nfor still picture compres- sion algorithms for intemational standardization. \nIn Proceedings of the IEEE Global Telecommu- \nnications Conference. \nIEEE Communications Sociefy, Nov. 1988, pp. 1022-1027. Biography Gregory K. Wallace is currently Manager of Multimedia Engineering, Advanced Development, \nat Digital Equipment Corporation. Since \n1988 he has served as Chair of the JPEG committee (ISO/IEC \nJTCl/SC2/WGlO). For the past five \nyears at DEC, he has worked \non efficient software and hardware implementations of image compression and processing algorithms \nfor incorporation in general-purpose computing systems. He received the \nBSEE and \nMSEE from \nStanford University in 1977 and 1979. His current research interests \nare the integration of robust real-time multimedia capabilities into \nnetworked computing systems. '