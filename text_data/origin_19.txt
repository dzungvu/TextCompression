b"FaceRecognitionUsingActiveAppearanceModelsG.J.Edwards,T.F.Cootes,andC.J.TaylorWolfsonImageAnalysisUnit,DepartmentofMedicalBiophysics,UniversityofManchester,ManchesterM139PT,U.K.gje@sv1.smb.man.ac.ukhttp://www.wiau.man.ac.ukAbstract.Wepresentanewframeworkforinterpretingfaceimagesandim-agesequencesusinganActiveAppearanceModel(AAM).TheAAMcontainsastatistical,photo-realisticmodeloftheshapeandgrey-levelappearanceoffaces.ThispaperdemonstratestheuseoftheAAM'sefiterativematchingschemeforimageinterpretation.WeusetheAAMasabasisforfacerecognition,ob-taingoodresultsfordifimages.WeshowhowtheAAMframeworkallowsidentityinformationtobedecoupledfromothervariation,allowingevidenceofidentitytobeintegratedoverasequence.TheAAMapproachmakesoptimaluseoftheevidencefromeitherasingleimageorimagesequence.Sincewederiveacompletedescriptionofagivenimageourmethodcanbeusedasthebasisforarangeoffaceimageinterpretationtasks.1IntroductionThereiscurrentlyagreatdealofinterestinmodel-basedapproachestotheinterpreta-tionofimages[17][9][15][14][8].Theattractionsaretwo-fold:robustinterpretationisachievedbyconstrainingsolutionstobevalidinstancesofthemodelexample;andtheabilityto`explain'animageintermsofasetofmodelparametersprovidesabasisforsceneinterpretation.Inordertorealisethesethemodelofobjectappearanceshouldbeascompleteaspossible-abletosynthesiseaverycloseapproximationtoanyimageofthetargetobject.Amodel-basedapproachisparticularlysuitedtothetaskofinterpretingfacesinimages.Facesarehighlyvariable,deformableobjects,andmanifestverydifferentap-pearancesinimagesdependingonpose,lighting,expression,andtheidentityoftheperson.Interpretationofsuchimagesrequirestheabilitytounderstandthisvariabilityinordertoextractusefulinformation.Currently,themostcommonlyrequiredinforma-tionistheidentityoftheface.Althoughmodel-basedmethodshaveprovedquitesuccessful,noneoftheexistingmethodsusesafull,photo-realisticmodelandattemptstomatchitdirectlybymin-imisingthedifferencebetweenmodel-synthesisedexampleandtheimageunderinter-pretation.Althoughsuitablephoto-realisticmodelsexist,(e.g.Edwardsetal[8]),theytypicallyinvolvealargenumberofparameters(50-100)inordertodealwiththevari-abilityduetodifferencesbetweenindividuals,andchangesinpose,expression,andlighting.Directoptimisationoversuchahighdimensionalspaceseemsdaunting."b"Weshowthatadirectoptimisationapproachisfeasibleandleadstoanalgorithmwhichisrapid,accurate,androbust.Wedonotattempttosolveageneraloptimisationeachtimewewishtothemodeltoanewimage.Instead,weexploitthefacttheoptimisationproblemissimilareachtime-wecanlearnthesesimilaritiesoff-line.Thisallowsustodirectionsofrapidconvergenceeventhoughthesearchspacehasveryhighdimensionality.Themainfeaturesoftheapproacharedescribedhere-fulldetailsandexperimentalvalidationshavebeenpresentedelsewhere[4].Weapplythisapproachtofaceimagesandshowthat,usingthemodelparame-tersforwecanobtaingoodresultsforpersonandexpressionrecognitionusingaverydiftrainingandtestsetofstillimages.Wealsoshowhowthemethodcanbeusedintheinterpretationofimagesequences.Theaimistoimproverecognitionperformancebyintegratingevidenceovermanyframes.Edwardset.al.[7]describedhowafaceappearancemodelcanbepartitionedtogivesetsofparametersthatindependentlyvaryidentity,expression,poseandlighting.Weexploitthisideatoobtainanestimateofidentitywhichisindependentofothersourcesofvariabilityandcanbestraightforwardlytoproduceanoptimalestimateofidentity.WeshowthatthisleadstoastableestimateofID,eveninthepresenceofconsiderablenoise.Wealsoshowhowtheapproachcanbeusedtoproducehigh-resolutionvisualisationofpoorqualitysequences.1.1BackgroundSeveralmodel-basedapproachestotheinterpretationoffaceimagesofhavebeende-scribed.Themotivationistoachieverobustperformancebyusingthemodeltocon-strainsolutionstobevalidexamplesoffaces.Amodelalsoprovidesthebasisforabroadrangeofapplicationsby`explaining'theappearanceofagivenimageintermsofacompactsetofmodelparameters,whichmaybeusedtocharacterisethepose,ex-pressionoridentityofaface.Inordertointerpretanewimage,anefmethodofthebestmatchbetweenimageandmodelisrequired.TurkandPentland[17]useprincipalcomponentanalysistodescribefaceimagesintermsofasetofbasisfunctions,or`eigenfaces'.Theeigenfacerepresentationisnotro-busttoshapechanges,anddoesnotdealwellwithvariabilityinposeandexpression.However,themodelcanbetoanimageeasilyusingcorrelationbasedmethods.Ez-zatandPoggio[9]synthesisenewviewsofafacefromasetofexampleviews.Theythemodeltoanunseenviewbyastochasticoptimisationprocedure.Thisisextremelyslow,butcanberobustbecauseofthequalityofthesynthesisedimages.Cootesetal[3]describea3Dmodelofthegrey-levelsurface,allowingfullsynthesisofshapeandappearance.However,theydonotsuggestaplausiblesearchalgorithmtomatchthemodeltoanewimage.Nastaratal[15]describearelatedmodelofthe3Dgrey-levelsurface,combiningphysicalandstatisticalmodesofvariation.Thoughtheydescribeasearchalgorithm,itrequiresaverygoodinitialisation.Ladesatal[12]modelshapeandsomegreylevelinformationusingGaborjets.However,theydonotimposestrongshapeconstraintsandcannoteasilysynthesiseanewinstance.Cootesetal[5]modelshapeandlocalgrey-levelappearance,usingActiveShapeModels(ASMs)tolocatexibleobjectsinnewimages.Lanitisatal[14]usethisapproachtointerpretfaceimages.HavingfoundtheshapeusinganASM,thefaceiswarpedintoanormalised"b'frame,inwhichamodeloftheintensitiesoftheshape-freefaceareusedtointerprettheimage.Edwardsatal[8]extendthisworktoproduceacombinedmodelofshapeandgrey-levelappearance,butagainrelyontheASMtolocatefacesinnewimages.Ournewapproachcanbeseenasafurtherextensionofthisidea,usingalltheinforma-tioninthecombinedappearancemodeltototheimage.Covell[6]demonstratesthattheparametersofaneigen-featuremodelcanbeusedtodriveshapemodelpointstothecorrectplace.Weuseageneralisationofthisidea.BlackandYacoob[2]uselocal,hand-craftedmodelsofimagewtotrackfacialfeatures,butdonotattempttomodelthewholeface.Ouractiveappearancemodelapproachisageneralisationofthis,inwhichtheimagedifferencepatternscorrespondingtochangesineachmodelparameterarelearntandusedtomodifyamodelestimate.2ModellingFaceAppearanceInthissectionweoutlinehowourappearancemodelsoffacesweregenerated.TheapproachfollowsthatdescribedinEdwardsetal[8]butincludesextragrey-levelnor-malisationsteps.SomefamiliaritywiththebasicapproachisrequiredtounderstandthenewActiveAppearanceModelalgorithm.Themodelsweregeneratedbycombiningamodelofshapevariationwithamodeloftheappearancevariationsinashape-normalisedframe.Werequireatrainingsetoflabelledimages,wherelandmarkpointsaremarkedoneachexamplefaceatkeypositionstooutlinethemainfeatures.Givensuchasetwecangenerateastatisticalmodelofshapevariation(see[5]fordetails).Thelabelledpointsonasinglefacedescribetheshapeofthatface.Wealignallthesetsofpointsintoacommonco-ordinateframeandrepresenteachbyavector,.Wethenapplyaprincipalcomponentanalysis(PCA)tothedata.Anyexamplecanthenbeapproximatedusing:(1)whereisthemeanshape,isasetoforthogonalmodesofshapevariationandisasetofshapeparameters.Tobuildastatisticalmodelofthegrey-levelappearancewewarpeachexampleim-agesothatitscontrolpointsmatchthemeanshape(usingatriangulationalgorithm).Wethensamplethegreylevelinformationfromtheshape-normalisedimageovertheregioncoveredbythemeanshape.Tominimisetheeffectofgloballightingvariation,wenormalisethisvector,obtaining.Fordetailsofthismethodsee[4].ByapplyingPCAtothisdataweobtainalinearmodel:(2)whereisthemeannormalisedgrey-levelvector,isasetoforthogonalmodesofgrey-levelvariationandisasetofgrey-levelmodelparameters.Theshapeandappearanceofanyexamplecanthusbesummarisedbythevectorsand.Sincetheremaybecorrelationsbetweentheshapeandgrey-levelvaria-tions,weapplyafurtherPCAtothedataasfollows.Foreachexamplewegeneratetheconcatenatedvector'b'Fig.1.Firstfourmodesofappearancevariation(+/-3sd)(3)whereisadiagonalmatrixofweightsforeachshapeparameter,allowingforthedifferenceinunitsbetweentheshapeandgreymodels.WeapplyaPCAonthesevec-tors,givingafurthermodel(4)wherearetheeigenvectorsofandisavectorofappearanceparameterscontrollingboththeshapeandgrey-levelsofthemodel.Sincetheshapeandgrey-modelparametershavezeromean,doestoo.Anexampleimagecanbesynthesisedforagivenbygeneratingtheshape-freegrey-levelimagefromthevectorandwarpingitusingthecontrolpointsdescribedby.Fulldetailsofthemodellingprocedurecanbefoundin[4].Weappliedthemethodtobuildamodeloffacialappearance.Usingatrainingsetof400imagesoffaces,eachlabelledwith122pointsaroundthemainfeatures.Fromthiswegeneratedashapemodelwith23parameters,ashape-freegreymodelwith113parametersandacombinedappearancemodelwhichrequiredonly80parametersrequiredtoexplain98%oftheobservedvariation.Themodelusedabout10,000pixelvaluestomakeupthefacepatch.Figure1showstheeffectofvaryingthefourappearancemodelparameters.3ActiveAppearanceModelSearchGiventhephoto-realisticfacemodel,weneedamethodofautomaticallymatchingthemodeltoimagedata.Givenareasonablestartingapproximation,werequireanefalgorithmforadjustingthemodelparameterstomatchtheimage.Inthissectionwegiveanoverviewofsuchanalgorithm.Fulltechnicaldetailsaregivenin[4].3.1OverviewofAAMSearchGivenanimagecontainingafaceandthephoto-realisticfacemodel,weseektheopti-mumsetofmodelparameters(andlocation)thatbestdescribestheimagedata.One'b"metricwecanusetodescribethematchbetweenmodelandimageissimply,thevectorofdifferencesbetweenthegrey-levelvaluesintheimageandacorrespondinginstanceofthemodel.Thequalityofthematchcanbedescribedby.Asageneraloptimizationproblem,wewouldseektovarythemodelparameterswhileminimizing.Thisrepresentsanenormoustask,giventhatthemodelspacehas80dimensions.TheActiveAppearanceModelmethodusesthefullvectortodrivethesearch,ratherthanasimplescore.Wenotethateachattempttomatchthemodeltoanewfaceimageisactuallyasimilaroptimisationproblem.Solvingageneralopti-mizationproblemfromscratchisunnecessary.TheAAMattemptstolearnsomethingabouthowtosolvethisclassofproblemsinadvance.Byprovidinga-prioriknowledgeofhowtoadjustthemodelparametersduringduringimagesearch,anefrun-timealgorithmresults.Inparticular,theAAMusesthespatialpatternin,toencodeinformationabouthowthemodelparametersshouldbechangedinordertoachieveabetterForexample,ifthelargestdifferencesbetweenafacemodelandafaceimageoccurredatthesidesoftheface,thatwouldimplythataparameterthatthewidthofthemodelfaceshouldbeadjusted.Cootesetal.[4]describethetrainingalgorithmindetail.Themethodworksbylearningfromanannotatedsetoftrainingexampleinwhichthe`true'modelparam-etersareknown.Foreachexampleinthetrainingset,anumberofknownmodeldis-placementsareapplied,andthecorrespondingdifferencevectorrecorded.Onceenoughtrainingdatahasbeengenerated,multivariatemultipleregressionisappliedtomodeltherelationshipbetweenthemodeldisplacementandimagedifference.Imagesearchthentakesplacebyplacingthemodelintheimageandmeasuringthedifferencevector.Thelearntregressionmodelisthenusedtopredictamovementofthefacemodellikelytogiveabettermatch.Theprocessisiteratedtoconvergence.Inourexperiments,weimplementamulti-resolutionversionofthisalgorithm,usinglowerresolutionmodelsinearlierstagesofasearchtogiveawiderlocationrange.Themodelusedcontained10,000pixelsatthehighestleveland600pixelsatthelowest.4FaceRecognitionusingAAMSearchLanitisetal.[13]describefacerecognitionusingshapeandgrey-levelparameters.IntheirapproachthefaceislocatedinanimageusingActiveShapeModelsearch,andtheshapeparametersextracted.Thefacepatchisthendeformedtotheaverageshape,andthegrey-levelparametersextracted.Theshapeandgrey-levelparametersareusedtogetherforAsdescribedabove,wecombinetheshapeandgrey-levelparametersandderiveAppearanceModelparameters,whichcanbeusedinasimilar,butprovidingamorecompactmodelthanthatobtainedbyconsideringshapeandgrey-levelseparately.Givenanewexampleofaface,andtheextractedmodelparameters,theaimistoidentifytheindividualinawaywhichisinvarianttoconfoundingfactorssuchaslighting,poseandexpression.Ifthereexistsarepresentativetrainingsetoffaceimages,itispossibletodothisusingtheMahalonobisdistancemeasure[11],whichenhancestheeffectofinter-classvariation(identity),whilstsuppressingtheeffectofwithinclassvariation(pose,lighting,expression).Thisgivesascaledmeasureofthedistanceofan"b"Fig.2.Varyingthemostidentityparameter(top),andmanipulatingresidualvariationwithoutaffectingidentity(bottom)examplefromaparticularclass.TheMahalanobisdistanceoftheexamplefromclass,isgivenby(5)whereisthevectorofextractedappearanceparameters,isthecentroidofthemul-tivariatedistributionforclassi,andisthecommonwithin-classcovariancematrixforallthetrainingexamples.Givensuftrainingexamplesforeachindividual,theindividualwithin-classcovariancematricescouldbeused-itis,however,restrictivetoassumethatsuchcomprehensivetrainingdataisavailable.4.1IsolatingSourcesofVariationThedescribedearlierassumesthatthewithin-classvariationisverysimilarforeachindividual,andthatthepooledcovariancematrixprovidesagoodoveralles-timateofthisvariation.Edwardsetal.[7]usethisassumptiontolinearlyseparatetheinter-classvariabilityfromtheintra-classvariabilityusingLinearDiscriminantAnal-ysis(LDA).Theapproachseekstoalineartransformationoftheappearancepa-rameterswhichmaximisesinter-classvariation,basedonthepooledwithin-classandbetween-classcovariancematrices.Theidentityofafaceisgivenbyavectorofdis-criminantparameters,,whichideallyonlycodeinformationimportanttoidentity.Thetransformationbetweenappearanceparameters,,anddiscriminantparameters,isgivenby(6)whereisamatrixoforthogonalvectorsdescribingtheprincipaltypesofinter-classvariation.Havingcalculatedtheseinter-classmodesofvariation,Edwardsetal.[7]showedthatasubspaceorthogonaltocouldbeconstructedwhichmodelledonlyintra-classvariationsduetochangeinpose,expressionandlighting.TheeffectofthisdecompositionistocreateacombinedmodelwhichisstillintheformofEquation1,butwheretheparameters,,arepartitionedintothosethataffectidentityandthosethatdescribewithin-classvariation.Figure2showstheeffectofvaryingthemostcantidentityparameterforsuchamodel;alsoshownistheeffectofapplyingthemodeoftheresidual(identity-removed)modeltoanexampleface.Itcanbeseenthatthelinearseparationisreasonablysuccessfulandthattheidentityremainsunchanged.The'identity'subspaceconstructedgivesasuitableframeofreferencefor"b'Fig.3.Originalimage(right)andbest(left)givenlandmarkpointsInitial2its8its14its20itsconvergedFig.4.Multi-Resolutionsearchfromdisplacedpositiontion.Theeuclideandistancebetweenimageswhenprojectedontothisspaceisamea-sureofthesimilarityofIDbetweentheimages,sincediscriminantanalysisensuresthattheeffectofconfoundingfactorssuchasexpressionisminimised.4.2SearchResultsAfullanalysisoftherobustnessandaccuracyofAAMsearchisbeyondthescopeofthispaper,butisdescribedelsewhere[4].Inourexperiments,weusedthefaceAAMtosearchforfacesinpreviouslyunseenimages.Figure3showsthebestofthemodelgiventheimagepointsmarkedbyhandforthreefaces.Figure4showsframesfromaAAMsearchforeachface,eachstartingwiththemeanmodeldisplacedfromthetruefacecentre.4.3RecognitionResultsThemodelwasusedtoperformtworecognitionexperiments;recognitionofidentity,andrecognitionofexpression.Inbothtests400faceswereused-200fortrainingand'b'Fig.5.Typicalexamplesfromtheexperimentalset200fortesting.Thesetcontainedimagesof20differentindividualscapturedunderarangeofconditions.Thisparticularsetoffaceswaschosenforitslargerangeofex-pressionchangesaswellaslimitedposeandlightingvariation.Thesefactors,thewithinclassvariability,servetomaketherecognitiontasksmuchharderthanwithcontrolledexpressionandpose.Figure5showssometypicalexamplesfromtheset.Theactiveappearancemodelwasusedtolocateandinterpretboththetrainingandtestimages.Inbothcasesthemodelwasgiventheinitialeyepositions,andwasthenrequiredtotothefaceimageusingthestrategydescribedinsection3.Thus,foreachface,asetofmodelparameterswasextracted,andtheresultsusedforexperiments.4.4RecognisingIdentityTheidentityrecognitionwasperformedintheidentitysubspaceasdescribedinsection4.1.EachexamplevectorofextractedmodelparameterswasprojectedontotheID-subspace.Thetrainingsetwasusedtothecentroid,intheID-subspaceforeachofthetrainingfaces.Atestfacewasthenaccordingtothenearestcentroidofthetrainingset.InordertoquantifytheperformanceoftheActiveAppearanceModelforlocationandinterpretation,wecomparedtheresultswiththebestthatcouldbeachievedusingthiswithhandannotation.Foreachexample(trainingandtest)the122key-landmarkpointswereplacedbyhand,andthemodelparametersextractedfromtheimageasdescribedinsection2.Usingtheabove,thismethodachieved88%correctrecognition.Whentheactiveappearancemodelwasappliedtothesameimages,therecognitionrateremainedat88%.Althoughthisrepresentsequalperformancewithhand-annotation,afewofthefailureswereondifferentfacesfromthehand-annotatedresults.ThuswecanconcludethattheActiveAppearanceModelcompeteswithhandannotation;anyfurtherimprovementinraterequiresaddressingtheclas-itself.4.5RecognisingExpressionInordertotesttheperformanceoftheActiveAppearanceModelforexpressionrecog-nition,wetestedthesystemagainst25humanobservers.Eachobserverwasshownthesetof400faceimages,andaskedtoclassifytheexpressionofeachasoneof:happy,sad,afraid,angry,surprised,disgusted,neutral.Wethendividedtheresultsintotwoseparateblocksof200imageseach,oneusedfortrainingtheexpression,andtheotherusedfortesting.Sincetherewasconsiderabledisagreementamongstthe'b'humanobserversastothecorrectexpression,itwasnecessarytodeviseanobjectivemeasureofperformanceforboththehumansandthemodel.Aleave-one-outbasedschemewasdevisedthus:Takingthe200testimages,eachhumanobserverattachedalabeltoeach.Thislabelwasthencomparedwiththelabelattachedtothatimagebythe24otherobservers.Onepointwasscoredforeveryagreement.Inprinciplethiscouldmeanamaximumscoreof24x200=4800points,however,therewereveryfewcasesinwhichallthehumanobserversagreed,sotheactualmaximumismuchless.Inordertogiveaperformancebaselineforthisdata,thescorewascalculatedseveraltimesbymakingrandomchoicesalone.Theother200imageswereusedtotrainanexpressionbasedonthemodelparameters.Thiswasthentestedonthesame200imagesasthehumanobservers.Theresultswereasfollows:Randomchoicesscore660+/-150Humanobserverscore2621+/-300Machinescore1950Althoughthemachinedoesnotperformaswellasanyofthehumanobservers,theresultsencouragefurtherexploration.TheAAMsearchresultsareextremelyaccurate,andtheIDrecognitionperformancehigh.Thissuggeststhatexpressionrecognitionislimitedbythesimplelinearwehaveused.Furtherworkwilladdressamoresophisticatedmodelofhumanexpressioncharacterisation.5TrackingandfromSequencesInmanyrecognitionsystems,theinputdataisactuallyasequenceofimagesofthesameperson.Inprincipal,agreateramountofavailableisinformationthanfromasingleim-age,eventhoughanysingleframeofvideomaycontainmuchlessinformationthanagoodqualitystillimage.Weseekaprincipledwayofinterpretingtheextrainformationavailablefromasequence.Sincefacesaredeformableobjectswithhighlyvariableap-pearance,thisisadifproblem.Thetaskistocombinetheimageevidencewhilstnoise,thedifisknowingthedifferencebetweenrealtemporalchangestothedata(eg.thepersonsmiles)andchangessimplyduetosystematicand/orrandomnoise.Themodel-basedapproachoffersapotentialsolution-byprojectingtheimagedataintothemodelframe,wehaveameansofregisteringthedatafromframetoframe.Intu-itively,wecanimaginedifferentdynamicmodelsforeachseparatesourceofvariability.Inparticular,givenasequenceofimagesofthesamepersonweexpecttheidentitytoremainconstant,whilstlighting,poseandexpressionvaryeachwithitsowndynamics.Infact,mostofthevariationinthemodelisduetochangesbetweenindividuals,vari-ationwhichdoesnotoccurinasequence.Ifthisvariationcouldbeheldconstantwewouldexpectmorerobusttracking,sincethemodelwouldmorerepresenttheinputdata.Edwardset.al.[7]showthatLDAcanbeusedtopartitionthemodelintoIDandnon-IDsubspacesasdescribedinsection4.1.Thisprovidesthebasisforaprincipledmethodofintegratingevidenceofidentityoverasequence.Ifthemodelparameterforeachframeareprojectedintotheidentitysubspace,theexpectedvariationoverthe'b'sequenceiszeroandwecanapplyanappropriatetoachieverobusttrackingandanoptimalestimateofidentityoverthesequence.Althoughuseful,theseparationbetweenthedifferenttypesofvariationwhichcanbeachievedusingLDAisnotperfect.Themethodprovidesagoodapprox-imation,but,inreality,thewithin-classspreadtakesadifferentshapeforeachperson.Whenviewedforeachindividualatatime,thereistypicallycorrelationbetweentheidentityparametersandtheresidualparameters,eventhoughforthedataasawhole,thecorrelationisminimised.EzzatandPoggio[10]describenormalisationofposeusingmultipleviewsofthesameperson,demonstratingthefeasibilityofalinearapproach.Theyas-sumethatdifferentviewsofeachindividualareavailableinadvance-here,wemakenosuchassumption.Weshowthattheestimationofvariationcanbeintegratedwithtrackingtomakeoptimaluseofbothpriorandnewinformationinesti-matingIDandachievingrobusttracking.5.1ofRecognitionfromSequencesInourapproach,wereasonthattheimperfectionsofLDAwhenappliedtoaindividualcanbemodelledbyobservingthebehaviourofthemodelduringasequence.WedescribealinearcorrectiontotheresultoftheglobalLDA,givenasequenceofaface.Toillustratetheproblem,weconsiderasyntheticsitua-tioninwhichappearanceisdescribedinsome2-dimensionalspaceasshownin6.Weimaginealargenumberofrepresentativetrainingexamplesfortwoindividuals,personXandpersonYprojectedintothisspace.Theoptimumdirectionofgroupsep-aration,,andthedirectionofresidualvariation,areshown.AperfectdiscriminantSub-optimal spread+person Yperson XABCtest. ZIntra-class variation, rIdentity,dFig.6.LimitationofLinearDiscriminantAnalysis:Bestpossibleforsingleexam-ple,Z,istheprojection,A.ButifZisanindividualwhobehaveslikeXorY,theoptimumprojectionsshouldbeCorBrespectively.analysisofidentitywouldallowtwofacesofdifferentpose,lightingandexpressiontobenormalisedtoareferenceview,andthustheidentitycompared.ItisclearfromthediagramthatanorthogonalprojectionontotheidentitysubspaceisnotidealforeitherpersonXorpersonY.GivenafullyrepresentativesetoftrainingimagesforX'b'andY,wecouldworkoutinadvancetheidealprojection.Wedonothowever,wish(orneed)torestrictourselvestoacquiringtrainingdatainadvance.IfwewishtoidentifyanexampleofpersonZ,forwhomwehaveonlyoneexampleimage,thebestestimatepossibleistheorthogonalprojection,A,sincewecannotknowfromasingleexamplewhetherZbehaveslikeX(inwhichcaseCwouldbethecorrectidentity)orlikeY(whenBwouldbecorrect)orindeed,neither.Thediscriminantanalysisproducesonlyaorderapproximationtovariation.Inourapproachweseektocalculatecorrectionsfromimagesequences.TheframeworkusedistheAppearanceModel,inwhichfacesarerepresentedbyapa-rametervector,asinEquation1.LDAisappliedtoobtainaorderglobalapproximationofthelinearsubspacede-scribingidentity,givenbyanidentityvector,,andtheresiduallinearvariation,givenbyavector.Avectorofappearanceparameters,canthusbedescribedby(7)whereandarematricesoforthogonaleigenvectorsdescribingidentityandresid-ualvariationrespectively.andareorthogonalwithrespecttoeachotherandthedimensionsofandsumtothedimensionof.Theprojectionfromavector,ontoandisgivenby(8)and(9)Equation8givestheorthogonalprojectionontotheidentitysubspace,,thebestclas-availablegivenasingleexample.Weassumethatthisprojectionisnotideal,sinceitisnotGivenfurtherexamples,inparticular,fromasequence,weseektoapplyacorrectiontothisprojection.Itisassumedthatthecorrec-tionofidentityrequiredhasalinearrelationshipwiththeresidualparameters,butthatthisrelationshipisdifferentforeachindividual.Formally,ifisthetrueprojectionontotheidentitysubspace,istheorthogonalpro-jection,istheprojectionontotheresidualsubspace,andisthemeanoftheresidualsubspace(averagelighting,pose,expression)then,(10)whereisamatrixgivingthecorrectionoftheidentity,giventheresidualparame-ters.Duringasequence,manyexamplesofthesamefaceareseen.WecanusetheseexamplestosolveEquation10inaleast-squaressenseforthematrix,byapplyinglinearregression,thusgivingthecorrectionrequiredfortheparticularindividual.5.2TrackingFaceSequencesIneachframeofanimagesequence,anActiveAppearanceModelcanbeusedtolo-catetheface.Theiterativesearchprocedurereturnsasetofparametersdescribingthe'b'bestmatchfoundofthemodeltothedata.Baumberg[1]andRoweet.al.[16]hasde-scribedaKalmanframeworkusedasaoptimalrecursiveestimatorofshapefromsequencesusinganActiveShapeModel.Inordertoimprovetrackingrobustness,weproposeasimilarscheme,butusingthefullAppearanceModel,andbasedonthede-couplingofidentityvariationfromresidualvariation.Thecombinedmodelparametersareprojectedintothetheidentityandresidualsub-spacesbyEquations8and9.Ateachframe,t,theidentityvector,,andresidualvectorarerecorded.Untilenoughframeshavebeenrecordedtoallowlinearre-gressiontobeapplied,thecorrectionmatrix,issettocontainallzeros,sothatthecorrectedestimateofidentity,isthesameastheorthogonallyprojectedestimate,.Onceregressioncanbeapplied,theidentityestimatestartstobecorrected.ThreesetsofKalmanareusedtotracktheface.Eachtrack2D-pose,,IDvariation,,andnon-ID,,variationrespectively.The2D-poseandnon-IDvariationaremodelledasrandom-walkprocesses,theIDvariationismodelledasarandomconstant,theexpecteddynamicsofthesystem.Theoptimumparameterscontrollingtheopera-tionofKalmancanbeestimatedfromthevariationseenoverthetrainingset.Forexample,theIDisinitialisedonthemeanface,withaestimateduncertaintycoveringtherangeofIDseenduringtraining.6TrackingResultsInordertotestthisapproachwetookashortsequenceofanindividualrecitingthealphabetwhilstmoving.WethensuccessivelydegradedthesequencebyaddingGaus-siannoiseat2.5,5,7.5,10,12.5and30%averagedisplacementperpixel.Figure7showsframesselectedfromtheuncorruptedsequence,togetherwiththeresultoftheActiveAppearanceModelsearchoverlaidontheimage.Thesubjecttalksandmoveswhilevaryingexpression.Theamountofmovementincreasestowardstheendofthese-quence.After40framestheadaptivecorrectionandKalmanwasswitchedon.Weshowtheresultsfortheuncorruptedsequence.Figure8showsthevalueoftherawpro-jectionontotheandsecondIDparameters.Considerablevariationisobservedoverthesequence.Thecorrected,andtheestimatesoftheIDparametersareshownin9and10respectively.Figures9showsthat,oncetheIDcorrectionisswitchedon(atframe40),amorestableestimateofIDresults.Figure10showsthatthecombinationofIDcorrectionandtemporalresultsinanextremelystableestimateofID.Figure11illustratesthestabilityoftheIDestimatewithimagedegra-dation.ThevalueoftheIDparameterisshownonthey-axis.ThisisnormalisedoverthetotalvariationinID-valueoverthetrainingset.Itisseenthattheestimatere-mainsreasonablyconsistent(within+/-0.03%oftheoverallvariation)atlowlevelsofdegradation,becomingunstableatahigherlevel.7EnhancedVisualisationAftertrackingmanyframesofasequencetheestimateofthecorrectedidentityvectorstabilises.Acorrespondingreconstructionofthepersoncanbesynthesised.Thesyn-'b'Fig.7.Trackingandidentifyingaface.Originalframesareshownonthetoprow,reconstructiononthebottom.0102030405060708090100-1500-1000-50005001000Frame NumberParameter ValueFirst ID param Second ID paramFig.8.RawIDparameters0102030405060708090100-1500-1000-50005001000Frame NumberParameter ValueFirst ID param Second ID paramFig.9.CorrectedIDparameters0102030405060708090100-1500-1000-50005001000Frame NumberParameter ValueFirst ID param Second ID paramFig.10.Filtered,corrected,IDthesisedimageisbasedontheevidenceintegratedoverthesequence.Thisprovidesameansofgeneratinghighresolutionreconstructionsfromlowerresolutionsequences.Figure12illustratesanexample:Thelefthandimageisaframefromasequenceof95images.InthecentreimageweshowanexamplefromthesequenceafterdeliberateGaussiansubsamplingtosynthesisalow-resolutionsourceimage.Thereconstructionontherightshowstheestimateofthepersonbasedonevidenceintegratedoverthelow-resolutionsequence.8ConclusionsWehavedescribedtheuseofanActiveAppearanceModelinfacerecognition.Themodelusesalltheinformationavailablefromthetrainingdataandfacilitatesthede-couplingofmodelintoIDandnon-IDparts.WhenusedforstaticfacetheAAMprovedasreliableaslabellingtheimagesbyhand.Arateof88%wasachieved.Whenusedforexpressionrecognitionthesystemsshowslessagreementthanhumanobserversbutneverthelessencouragesfurtherworkinthisarea.AobservationofthequalityofmodelandtheexcellentidentityrecognitionperformancesuggeststhattheitselfratherthantheAAMsearchlimitstheexpressionrecognitionperformance.'b'0102030405060708090100-0.5-0.4-0.3-0.2-0.100.10.2Frame NumberNormalized ID Value2.5% Noise 5% Noise   7.5% Noise 10% Noise  12.5% Noise30% Noise  Fig.11.TrackingNoisyData.IDestimateremainsconsistentatincreasingnoiselevels,becomingunstableat30%noiselevel.Fig.12.Synthesisingahigh-resfacefromalow-ressequence.Lefthandimage:anoriginalframefromsequence.Centreimage:framefromdeliberatelyblurredsequence.Righthandimage:reconstructionfromlow-ressequenceWehaveoutlinedatechniqueforimprovingthestabilityoffaceandtrack-ingwhensubjecttovariationinpose,expressionandlightingconditions.Thetrackingtechniquemakesuseoftheobservedeffectofthesetypesofvariationinordertoprovideabetterestimateofidentity,andthusprovidesamethodofusingtheextrainformationavailableinasequencetoimproveBycorrectlydecouplingtheindividualsourcesofvariation,itispossibletodevelopde-coupleddynamicmodelsforeach.Thetechniquewehavedescribedallowstheinitialapproximatedecouplingtobeupdatedduringasequence,thusavoidingtheneedforlargenumbersoftrainingexamplesforeachindividual.References1.A.M.Baumberg.LearningDeformableModelsforTrackingHumanMotion.PhDthesis,UniversityofLeeds,1995.2.M.J.BlackandY.Yacoob.RecognizingFacialExpressionsunderRigidandNon-RigidFacialMotions.InInternationalWorkshoponAutomaticFaceandGestureRecognition1995,pages1217,Zurich,1995.'b'3.T.CootesandC.Taylor.Modellingobjectappearanceusingthegrey-levelsurface.InE.Hancock,editor,BritishMachineVisonConference,pages479488,York,England,September1994.BMVAPress.4.T.F.Cootes,G.J.Edwards,andC.J.Taylor.Activeappearancemodels.InECCV98(toappear),Freiberg,Germany,1998.5.T.F.Cootes,C.J.Taylor,D.H.Cooper,andJ.Graham.ActiveShapeModels-TheirTrainingandApplication.ComputerVision,GraphicsandImageUnderstanding,61(1):3859,1995.6.M.Covell.Eigen-points:Control-pointLocationusingPrincipalComponentAnalysis.InInternationalWorkshoponAutomaticFaceandGestureRecognition1996,pages122127,Killington,USA,1996.7.G.J.Edwards,A.Lanitis,C.J.Taylor,andT.Cootes.StatisticalModelsofFaceImages:ImprovingInBritishMachineVisionConference1996,Edinburgh,UK,1996.8.G.J.Edwards,C.J.Taylor,andT.Cootes.LearningtoIdentifyandTrackFacesinImageSequences.InBritishMachineVisionConference1997,Colchester,UK,1997.9.T.EzzatandT.Poggio.FacialAnalysisandSynthesisUsingImage-BasedModels.InInternationalWorkshoponAutomaticFaceandGestureRecognition1996,pages116121,Killington,Vermont,1996.10.T.EzzatandT.Poggio.FacialAnalysisandSynthesisUsingImage-BasedModels.InInternationalWorkshoponAutomaticFaceandGestureRecognition1996,pages116121,Killington,Vermont,1996.11.D.J.Hand.Discriminationand.JohnWileyandSons,1981.12.M.Lades,J.Vorbruggen,J.Buhmann,J.Lange,C.vonderMalsburt,R.Wurtz,andW.Ko-nen.Distortioninvariantobjectrecognitioninthedynamiclinkarchitecture.IEEETransac-tionsonComputers,42:300311,1993.13.A.Lanitis,C.Taylor,andT.Cootes.AApproachtoCodingandInterpretingFaceImages.InInternationalConferenceonComputerVision,pages368373,Cambridge,USA,1995.14.A.Lanitis,C.Taylor,andT.Cootes.AutomaticInterpretationandCodingofFaceImagesUsingFlexibleModels.IEEETransactionsonPatternAnalysisandMachineIntelligence,19(7):743756,1997.15.C.Nastar,B.Moghaddam,andA.Pentland.GeneralizedImageMatching:StatisticalLearn-ingofPhysically-BasedDeformations.InEuropeanConferenceonComputerVision,volume1,pages589598,Cambridge,UK,1996.16.S.RoweandA.Blake.StatisticalFeatureModellingforActiveContours.InEuropeanConferenceonComputerVision,volume2,pages560569,Cambridge,UK,1996.17.M.TurkandA.Pentland.EigenfacesforRecognition.JournalofCognitiveNeuroscience,3(1):7186,1991.'