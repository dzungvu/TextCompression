b'InternationalJournalofComputerVision38(1),1533,2000\nc2000KluwerAcademicPublishers.ManufacturedinTheNetherlands.\nATrainableSystemforObjectDetection\nCONSTANTINEPAPAGEORGIOUANDTOMASOPOGGIO\nCenterforBiologicalandComputationalLearning,ArticialIntelligenceLaboratory,MIT,\nCambridge,MA,USA\ncpapa@ai.mit.edutp@ai.mit.eduAbstract.Thispaperpresentsageneral,trainablesystemforobjectdetectioninunconstrained,clutteredscenes.\nThesystemderivesmuchofitspowerfromarepresentationthatdescribesanobjectclassintermsofanovercomplete\n\ndictionaryoflocal,oriented,multiscaleintensitydifferencesbetweenadjacentregions,efcientlycomputableas\n\naHaarwavelettransform.Thisexample-basedlearningapproachimplicitlyderivesamodelofanobjectclass\n\nbytrainingasupportvectormachineclassierusingalargesetofpositiveandnegativeexamples.Wepresent\n\nresultsonface,people,andcardetectiontasksusingthesamearchitecture.Inaddition,wequantifyhowthe\n\nrepresentationaffectsdetectionperformancebyconsideringseveralalternaterepresentationsincludingpixelsand\n\nprincipalcomponents.Wealsodescribeareal-timeapplicationofourpersondetectionsystemaspartofadriver\n\nassistancesystem.\nKeywords:\ncomputervision,machinelearning,patternrecognition,peopledetection,facedetection,eardetection\n1.Introduction\nAstheamountofimageandvideoinformationavail-\nableincreases,robust,congurableobjectdetection\n\nsystemsformanagingthisdatawillbecomeindispens-\n\nable.Therehasbeenanexplosionintheamountof\n\ninformationpresentedontheInternetasitisquickly\n\ntransitionsfromatext-basedmediumtooneofim-\n\nageandvideocontent;objectdetectionsystemswillbe\n\nusedtosearchthroughthegrowingnumberofimage\n\nandvideodatabases.Thistechnologywillalsobeused\n\ninsurveillanceapplications,driverassistancesystems,\n\nandasfrontendstorecognitionsystems.\nThispaperaddressestheproblemofobjectandpat-\nterndetectioninstaticimagesofunconstrained,clut-\n\nteredscenes.Wecontrastdetectionwiththeproblem\n\nofrecognition,wherethegoalistoidentifyspecicin-\n\nstancesofaclass.Aface\ndetectionsystemknowshow\ntodifferentiatefacesfromeverythingelse,whilea\n\nface\nrecognition\nsystemknowsthedifferencebetween\nmyfaceandotherfaces.Thedetectionofreal-world\n\nobjectsofinterest,suchasfaces,people,andcars,\n\nposeschallengingproblems:theseobjectsaredifcult\ntomodelwithsignicantvarietyincolorandtexture,\nthebackgroundsagainstwhichtheobjectslieareoften\n\ncomplexandcluttered,andcharacteristicslikelighting,\n\nsize,andnumberofobjectscannotbeaccountedforin\n\nanybutthemostcontrivedsituations.\nOurtechniqueusesadescriptivemodelofanobject\nclassthatisrichenoughtoeffectivelymodelanyofthe\n\npossibleshapes,poses,colors,andtexturesofanobject.\n\nAtthesametime,thetechniqueisgeneralenoughthat\n\nitcaneasilybetransferedtoanewclassofobjects.\nThesystemderivesmuchofitspowerfromanew\nrepresentationthatdescribesanobjectclassinterms\n\nofalargesetoflocalorientedintensitydifferencesbe-\n\ntweenadjacentregions;thisrepresentationisefciently\n\ncomputableasaHaarwavelettransform.Imagesare\n\nmappedfromthespaceofpixelstothatofanovercom-\n\npletedictionaryofHaarwaveletfeaturesthatprovides\n\narichdescriptionofthepattern.Thisrepresentation\n\nisabletocapturethestructureoftheclassofobjects\n\nwewouldliketodetectwhileignoringthenoiseinher-\n\nentintheimages.Theuseofanovercompletedictio-\n\nnaryisinspiredbyimagereconstructiontechniques;\n\nourgoalistodoclassicationand,tothisend,the\n'b'16PapageorgiouandPoggio\novercompletedictionaryprovidesuswitharicherex-\npressivelanguageinwhichwecancomparecomplex\n\npatterns.Wewillbeusinganexample-basedlearningap-\nproachwhereamodelofanobjectclassisderived\n\nimplicitlyfromatrainingsetofexamples.Inthisway,\n\nspecializingthisgeneralsystemtoaspecicdomain\n\ninvolvesplugginginanewsetoftrainingdatawith-\n\noutmodifyingthecoresystemorhandcraftinganew\n\nmodel.Thespeciclearningengineweuseisasup-\n\nportvectormachine(SVM)classier.Thisclassica-\n\ntiontechniquehasanumberofpropertiesthatmakeit\n\nparticularlyattractiveandhasrecentlyreceivedmuch\n\nattentioninthemachinelearningcommunity.\nThereisalargebodyofpreviousworkinobjectde-\ntection;ofparticularrelevancetothispaperisthework\n\nonfacedetectioninstaticimages.Recently,example-\n\nbaseapproacheshaveachievedahighdegreeofsuccess\n\ninthiseld(SungandPoggio,1994;Moghaddamand\n\nPentland,1995;Rowleyetal.,1998;Vaillantetal.,\n\n1994;Osunaetal.,1997b).Theseview-basedap-\n\nproachescanhandledetectingfacesinclutteredscenes,\n\nandhaveshownareasonabledegreeofsuccesswhen\n\nextendedtohandlenon-frontalviews.Incontrastto\n\nfacedetection,detectingpeopleinstaticimageshas,\n\nuntilnow,notbeensuccessfullytackled.Currentpeo-\n\npledetectionsystems(Wrenetal.,1995;Haritaoglu\n\netal.,1998;HeiseleandWohler,1998;McKennaand\n\nGong,1997;ShioandSklansky,1991;Rohr,1993;\n\nHogg,1983)typicallyassumeanyofseveralrestric-\n\ntiveassumptions,thatthepeoplearemoving,there\n\nisastaticbackgroundwithaxedcamera,imple-\n\nmenttrackingandnottruedetection,usehand-crafted\n\nmodels,ortheymakeassumptionsonthenumberof\n\npeopleinthescene.InForsythandFleck(1997,1998),\n\ntheydescribeasystemthatusescolor,texture,andge-\n\nometrytolocalizehorsesandnakedpeopleinstatic\n\nimages.Thesystemismainlytargetedtowardsretriev-\n\ningimageswithasingleobjectofinterest.Methods\n\noflearningthesebodyplansofhandcodedhierar-\n\nchiesofpartsfromexamplesaredescribedinForsyth\n\nandFleck(1997).Oursystemmakesnoneofthese\n\nassumptionsandresultsinahighlyrobustpeoplede-\n\ntectiontechniqueforstaticimages.Cardetectionis\n\nalsoadomainreceivingincreasedattention;(Bregler\n\nandMalik,1996)describeasystemusingmixturesof\n\nexpertsonsecondorderGaussianfeaturestoidentify\n\ndifferentclassesofcars(detectionhasbeensubsumed)\n\nand(Lipson,1996;Lipsonetal.,1997)describesasys-\n\ntemthatusesadeformabletemplateforsideviewcar\ndetection.InBeymeretal.(1997),theypresentatraf-\ncmonitoringsystemthathasacardetectionmodule\n\nthatlocatescornerfeaturesinhighwaysequencesand\n\ngroupsfeaturesforsinglecarstogetherbyintegrating\n\ninformationovertime.ThesystemofBetkeetal.(1997)\n\nandBetkeandNguyen(1998)usescornerfeaturesand\n\nedgemapscombinedwithtemplatematchingtodetect\n\ncarsinhighwayvideoscenes.\nThispaperdescribesourgeneralframeworkforob-\njectdetectioninthecontextofface,people,andcar\n\ndetection.Weprovideanin-depthdescriptionofour\n\ncoresysteminSection2,alongwithdetailsonwavelets\n\n(Section2.1),ourparticulardictionaryofwaveletfea-\n\ntures(Section2.2),andthesupportvectormachine\n\nclassicationtechnique(Section2.3).InSection3,\n\nwecompareandcontrastwaveletswithotherpossible\n\nrepresentations,includingpixelsandprincipalcompo-\n\nnents.Areal-timeimplementationofourpeoplede-\n\ntectionsystemaspartofadriverassistancesystemis\n\ndescribedinSection4.Weconcludewithrelatedareas\n\nthatwearecurrentlypursuinganddirectionsforfuture\n\nwork.\n2.ArchitectureandRepresentation\nThearchitecturaloverviewofoursystemisprovided\ninFig.1asappliedtothetaskofpeopledetectionand\n\nshowsthetrainingandtestingphases.Inthetraining\n\nstep,thesystemtakesasinput1)asetofimagesof\n\ntheobjectclassthathavebeenalignedandscaledso\n\nthattheyareallinapproximatelythesameposition\n\nandthesamesizeand2)asetofpatternsthatarenot\n\ninourobjectclass.Anintermediaterepresentationthat\n\nencapsulatestheimportantinformationofourobject\n\nclassiscomputedforeachofthesepatterns,yielding\n\nasetofpositiveandnegativefeaturevectors.These\n\nfeaturevectorsareusedtotrainapatternclassierto\n\ndifferentiatebetweenin-classandout-of-classpatterns.\nInthetestingphase,weareinterestedindetecting\nobjectsinout-of-sampleimages.Thesystemslidesa\n\nxedsizewindowoveranimageandusesthetrained\n\nclassiertodecidewhichpatternsshowtheobjectsof\n\ninterest.Ateachwindowposition,weextractthesame\n\nsetoffeaturesasinthetrainingstepandfeedtheminto\n\nourclassier;theclassieroutputdetermineswhether\n\nornotwehighlightthatpatternasanin-classobject.\n\nToachievemultiscaledetection,weiterativelyresize\n\ntheimageandprocesseachimagesizeusingthesame\n\nxedsizewindow.\n'b'ATrainableSystemforObjectDetection17\nFigure1\n.Thetrainingandtestingphasesofoursystem.\nThissectionaddressesthekeyissuesinthedevelop-\nmentofourtrainedpatternclassier:therepresentation\n\nandthelearningengine.\n2.1.Wavelets\nTheultimategoalinchoosingarepresentationforan\nobjectdetectionsystemisndingonethatyieldshigh\n\ninter-classvariability,whileatthesametimeachiev-\n\ninglowintra-classvariability.Sinceobjectclasseslike\n\npeoplecanbequitecomplex,thisisanontrivialtask.To\n\nencodethevisualstructureofanobjectclass,ourrep-\n\nresentationmustidentifyfeaturesataresolutionwhere\n\ntherewillbesomeconsistencythroughouttheobject\n\nclass,whileatthesametimeignoringnoise.Therep-\n\nresentationweuse,Haarwavelets,identieslocal,ori-\n\nentedintensitydifferencefeaturesatdifferentscales\nandisefcientlycomputable.TheHaarwaveletisper-\nhapsthesimplestsuchfeaturewithnitesupport.We\n\ntransformourimagesfrompixelspacetothespaceof\n\nwaveletcoefcients,resultinginanovercompletedic-\n\ntionaryoffeaturesthatarethenusedastrainingfora\n\nclassier.\nThissectiondescribestheunderlyingrepresentation\nthatweuseforextractingobjectfeatures,theHaar\n\nwavelet.Wealsodescribeadenser(redundant)trans-\n\nformthatweusetoprovidearicherfeaturesetandto\n\nachievethespatialresolutionweneedtoaccomplish\n\ndetection.2.1.1.TheHaarWavelet.\nWaveletsprovideanatural\nmathematicalstructurefordescribingourpatterns;\n\namoredetailedtreatmentcanbefoundinMallat\n\n(1989).Thesevectorspacesformthefoundationsof\n'b'18PapageorgiouandPoggio\ntheconceptofamultiresolutionanalysis.Weformal-\nizethenotionofamultiresolutionanalysisasthe\n\nsequenceofapproximatingsubspaces\nV0V1V2:::VjVjC1:::;thevectorspace\nVjC1candescribenerdetailsthanthespace\nVj,buteveryel-\nementof\nVjisalsoanelementof\nVjC1.Amultireso-\nlutionanalysisalsopostulatesthatafunctionapproxi-\n\nmatedin\nVjischaracterizedasitsorthogonalprojec-\ntiononthevectorspace\nVj.Asabasisforthevectorspace\nVj,weusethe\nscalingfunctions,jiDp2j.2jxi/;iD0;:::;2j1;(1)where,forourcaseoftheHaarwavelet,\n.x/D(1for0\nx<10otherwise\n(2)Nextwedenethevectorspace\nWjthatistheor-\nthogonalcomplementoftwoconsecutiveapproxima-\nFigure2\n.TheHaarwaveletframework;(a)theHaarscalingfunctionandwavelet,(b)thethreetypesof2-dimensionalnon-standardHaar\nwavelets:vertical,horizontal,anddiagonal,and(c)theshiftinthestandardtransformascomparedtoourquadruplydenseshiftresultinginan\n\novercompletedictionaryofwavelets.\ntingsubspaces,\nVjC1DVjWj.The\nWjareknown\naswaveletsubspaces\nandcanbeinterpretedasthe\nsubspaceofdetailsinincreasingrenements.The\n\nwaveletspace\nWjisspannedbyabasisoffunctions,\njiDp2j.2jxi/;iD0;:::;2j;(3)whereforHaarwavelets,\n.x/D8><>:1for0\nx<121for\n12x<10otherwise\n(4)Thesumofthewaveletfunctionsformanorthonor-\nmalbasisfor\nL2.R/.Itcanbeshown(underthestan-\ndardconditionsofmultiresolutionanalysis)thatallthe\n\nscalingfunctionscanbegeneratedfromdilationsand\n\ntranslationsofonescalingfunction.Similarly,allthe\n\nwaveletfunctionsaredilationsandtranslationsofthe\n\nmotherwaveletfunction.Figure2(a)showsthescaling\n'b'ATrainableSystemforObjectDetection19\nandwaveletfunctions.Theapproximationofsome\nfunctionf.x/inthespace\nVjisfoundtobe:\nAj.f/DXk2Zj;kz}|{hf.u/;\njk.u/ijk.x/(5)wherewelettheinnerproductbedenotedby\nj;kforfutureuse.Similarly,theprojectionof\nf.x/onWjis:Dj.f/DXk2Zj;kz}|{hf.u/;\njk.u/ijk.x/(6)where,inthiscase,theinnerproductisdenotedby\nj;k.Thestructureoftheapproximatingandwaveletsub-\nspacesleadstoanefcientcascadealgorithmforthe\n\ncomputationofthescalingcoefcients,\nj;k,andthe\nwaveletcoefcients,\nj;k:j;kDXn2Zhn2kjC1;n(7)j;kDXn2Zgn2kjC1;n(8)wherefhigandfgigaretheltercoefcientscorre-\nspondingtothescalingandwaveletfunctions.Using\n\nthisconstruction,theapproximationofafunction\nf.x/inthespace\nVjis:Aj.f/DXn2Zj;kp2j.2jxk/(9)Similarly,theapproximationof\nf.x/inthespace\nWjis:Dj.f/DXn2Zj;kp2j.2jxk/(10)SinceweusetheHaarwavelet,thecorresponding\nltersare:\nhDf:::;0;12;12;0;0;:::gandgDf:::;0;12;12;0;0;:::g.Thescalingcoefcientsaresim-\nplytheaveragesofpairsofadjacentcoefcientsin\n\nthecoarserlevelwhilethewaveletcoefcientsarethe\n\ndifferences.\nItisimportanttoobservethatthediscretewavelet\ntransform(DWT)performs\ndownsamplingordecima-tionofthecoefcientsatthenerscalessincethelters\nhandgaremovedinastepsizeof2foreachincrement\nofk.2.1.2.2-DimensionalWaveletTransform.\nThenat-\nuralextensionofwaveletsto2Dsignalsisobtained\n\nbytakingthetensorproductoftwo1Dwavelettrans-\n\nforms.Theresultisthethreetypesofwaveletbasis\n\nfunctionsshowninFig.2.Thersttypeofwaveletis\n\nthetensorproductofawaveletbyascalingfunction,\n\n.x;y/D.x/.y/;thiswaveletencodesadiffer-\nenceintheaverageintensityalongaverticalborderand\n\nwewillrefertoitsvalueasa\nverticalcoefcient.Simi-\nlarly,atensorproductofascalingfunctionbyawavelet,\n\n.x;y/D.x/.y/,isa\nhorizontalcoefcient,\nandawaveletbyawavelet,\n.x;y/D.x/.y/,isa\ndiagonal\ncoefcientsincethiswaveletresponds\nstronglytodiagonalboundaries.\nSincethewaveletsthatthestandardtransformgen-\nerateshaveirregularsupport,weusethenon-standard\n\n2DDWTwhere,atagivenscale,thetransformisap-\n\npliedtoeachdimensionsequentiallybeforeproceeding\n\ntothenextscale(Stollnitzetal.,1994).Theresultsare\n\nHaarwaveletswithsquaresupportatalllevels,shown\n\ninFig.2(b).\n2.1.3.QuadrupleDensityTransform.\nForthe1D\nHaartransform,thedistancebetweentwoneighboring\n\nwaveletsatlevel\nn(withsupportofsize2\nn)is2\nn.Toob-\ntainadensersetofbasisfunctionsthatprovidearicher\n\nmodelandnerspatialresolution,weneedasetofre-\n\ndundantbasisfunctions,oranovercomplete\ndictionary,wherethedistancebetweenthewaveletsatlevel\nnis142n(Fig.2c).Thestraightforwardapproachofshifting\nthesignalandrecomputingtheDWTwillnotgener-\n\natethedesireddensesampling.Instead,thiscanbe\n\nachievedbymodifyingtheDWT.Togeneratewavelets\n\nwithdoubledensity\n,wherewaveletsoflevel\nnarelo-\ncatedevery\n122npixels,wesimplydonotdownsample\ninEq.(8).Togeneratethe\nquadrupledensity\ndictionary,\nrst,wedonotdownsampleinEq.(7),givingusdouble\n\ndensityscalingcoefcients.Next,wecalculatedouble\n\ndensitywaveletcoefcientsonthetwosetsofscaling\n\ncoefcientsevenandoddseparately.Byinterleav-\n\ningtheresultsofthetwotransformswegetquadruple\n\ndensitywaveletcoefcients.Forthenextlevel(\nnC1),wekeeponlytheevenscalingcoefcientsofthepre-\n\nviouslevelandrepeatthequadrupletransformonthis\n\nsetonly;theoddscalingcoefcientsaredroppedoff.\n\nSinceonlytheevencoefcientsarecarriedalongat\n\nallthelevels,weavoidanexplosioninthenumber\n\nofcoefcients,yetobtainadenseanduniformsam-\n\nplingofthewaveletcoefcientsatallthelevels.As\n\nwiththeregularDWT,thetimecomplexityis\nO.n/in'b'20PapageorgiouandPoggio\nthenumberofpixels\nn.Theextensionofthequadruple\ndensitytransformto2Disstraightforward.\n2.2.TheWaveletRepresentation\nTheHaartransformprovidesamultiresolutionrepre-\nsentationofanimagewithwaveletfeaturesatdifferent\n\nscalescapturingdifferentlevelsofdetail;thecoarse\n\nscalewaveletsencodelargeregionswhilethenescale\n\nwaveletsdescribesmaller,localregions.Thewavelet\n\ncoefcientspreservealltheinformationintheoriginal\n\nimage,butthecodingofthevisualinformationdiffers\n\nfromthepixel-basedrepresentationintwosignicant\n\nways.\nFirst,thewaveletsencodethedifferenceinaverage\nintensitybetweenlocalregionsalongdifferentorien-\n\ntations,inamultiscaleframework.Constraintsonthe\n\nvaluesofthewaveletscanexpressvisualfeaturesofthe\n\nobjectclass;strongresponsefromaparticularwavelet\n\nindicatesthepresenceofanintensitydifference,or\n\nboundary,atthatlocationintheimagewhileweakre-\n\nsponsefromawaveletindicatesauniformarea.\nSecond,theuseofanovercompleteHaarbasisal-\nlowsustopropagateconstraintsbetweenneighboring\n\nregionsanddescribecomplexpatterns.Thequadruple\n\ndensitywavelettransformprovideshighspatialreso-\n\nlutionandresultsinarich,overcompletedictionaryof\n\nfeatures.Insteadofquadrupledensitywavelets,itis\n\npossibletousejustthedoubledensitywaveletsthat\n\noverlapby50%;weexpectthatthequadrupledensity\n\nversionshouldgiveusbetterperformance,thoughthis\n\nisanuntestedassumption.\nOurmainmotivationforusingwaveletsisthatthey\ncapturevisuallyplausiblefeaturesoftheshapeandin-\n\nteriorstructureofobjectsthatareinvarianttocertain\n\ntransformations.Theresultisacompactrepresentation\n\nwheredissimilarexampleimagesfromthesameobject\n\nclassmaptosimilarfeaturevectors.\nWithapixelrepresentation,whatwewouldbeen-\ncodingaretheactualintensitiesofdifferentpartsof\n\nthepatternsasimpleexamplemakesitclearthatthis\n\nencodingdoesnotcapturetheimportantfeaturesfor\n\ndetection.Take,forinstance,ourexampleoftwodata\n\npointsofthesameclasswhereoneisadarkbodyon\n\nawhitebackgroundandtheotherisawhitebodyona\n\ndarkbackground.Withanintensitybasedrepresenta-\n\ntion(likepixels),eachoftheseexamplesmapstocom-\n\npletelydifferentfeaturevectors.Arepresentationthat\n\nencodeslocal,oriented,intensitydifferences(likeHaar\n\nwavelets)wouldyieldsimilarfeaturevectorswherethe\nfeaturescorrespondingtouniformregionsarezeroand\nthosecorrespondingtoboundariesarenon-zero.Infact,\n\nsinceinourrepresentationweencodeonlythemagni-\n\ntudeoftheintensitydifference,thefeaturevectorsfor\n\nthissimpletwoexamplecasewouldbeidentical.\nWedonotusealltheverynescalesofwaveletsas\nfeaturesforlearningsincethesescalescapturehighfre-\n\nquencydetailsthatdonotcharacterizetheclasswell;\n\nforinstance,inthecaseofpeople,thenestscale\n\nwaveletsmayrespondtochecks,stripes,andother\n\ndetailpatterns,allofwhicharenotfeaturesthatare\n\ncharacteristictotheentireclass.Similarly,thevery\n\ncoarsescalewaveletsarenotusedasfeaturesforlearn-\n\ningsincetheirsupportwillbeaslargeastheobject\n\nandwillthereforenotencodeusefulinformation.So,\n\nfortheobjectdetectionsystemwehavedeveloped,we\n\nthrowouttheveryneandverycoarsewaveletsand\n\nonlyuse2mediumscalesofwaveletsasfeaturesfor\n\nlearning.Thesescalesdependontheobjectclassand\n\nthesizeofthetrainingimagesandarechosenapriori.\nInthefollowingsections,weshowhowourwavelet\nrepresentationappliestofaces,people,andcars;this\n\ncodingoflocalintensitydifferencesatseveralscales\n\nprovidesaexibleandexpressiverepresentationthat\n\ncancharacterizeeachofthesecomplexobjectclasses.\n\nFurthermore,thewaveletrepresentationiscomputa-\n\ntionallyefcientforthetaskofobjectdetectionsince\n\nwedonotneedtocomputethetransformforeachimage\n\nregionthatisexaminedbutonlyonceforthewholeim-\n\nageandthenprocesstheimageinthespaceofwavelets.\n2.2.1.AnalyzingtheFaceClass.\nForthefaceclass,\nwehaveatrainingsetof2,429gray-scaleimagesof\n\nfacesthissetconsistsofacoresetoffaces,withsome\n\nsmallangularrotationstoimprovegeneralizationand\n\n24,730non-facepatterns.Theseimagesareallscaled\n\ntothedimensions19\n19andshowthefacefrom\nabovetheeyebrowstobelowthelips;typicalimages\n\nfromthedatabaseareshowninFig.3.Databasesof\n\nthissizeandcompositionhavebeenusedextensively\n\ninfacedetection(Sung,1995;Rowleyetal.,1998;\n\nOsunaetal.,1997a).Forthesizeofpatternsourface\n\nsystemuses,wehaveatourdisposalwaveletsofthe\n\nsize2\n2;44;88,and16\n16.Insteadofusing\ntheentiresetofwavelets,weapriorilimitthedictio-\n\nnarytocontainthewaveletsofscales2\n2and4\n4,sincecoarserfeaturesdonotcontainsignicantinfor-\n\nmationfordetectionpurposes.Atthescale4\n4pixels,\nthereare17\n17featuresinquadrupledensityforeach\nwaveletclassandat2\n2pixelsthereare17\n17'b'ATrainableSystemforObjectDetection21\nFigure3\n.Exampleimagesfromthedatabaseoffacesusedfortrainingandthecorrespondingensembleaveragefeatures.Thetrainingimages\naregraylevelofsize19\n19pixels.Theaveragefeaturevaluesarecodedingraylevelandaredisplayedintheirproperspatialconguration.\nFeatureswhosevaluesareclosetotheaveragevalueofonearecodedasgray,coefcientsthatareabovetheaveragearedarkerandthosebelow\n\ntheaveragearelighter.Wecanobservestrongfeaturesintheeyeareasandthenose.Thecheekareaisanareaofalmostuniformintensity,that\n\nis,thecoefcientsinthecheekregionshavebelowaveragevalues.\nfeaturesindoubledensityforeachclass,foratotalof\n1,734coefcients.\nTherawvalueofacoefcientmaynotnecessarilybe\nindicativeofaboundaryaweakcoefcientinarela-\n\ntivelydarkimagemaystillindicatethepresenceofan\n\nintensitydifferencethatissignicantforthepurposes\n\nofclassication.Toreducetheseeffectsonthefeatures\n\nusedforclassication,wenormalizeacoefcients\n\nvalueagainsttheothercoefcientsinthesamearea.\n\nForthenormalizationstep,wecomputetheaverageof\n\neachwaveletsclass(\nfvertical;horizontal;diagonal\ngf2;4g)overthecurrentpatternanddividethewavelet\nresponseatacertainspatiallocationbyitscorrespond-\n\ningclassaverage.Wecalculatetheaveragesseparately\n\nforeachclasssincethepowerdistributionbetweenthe\n\ndifferentclassesmayvary.\nAfterthenormalization,theaveragevalueofacoef-\ncientforrandompatternsshouldbe1.Threeclasses\n\noffeaturemagnitudeswillemerge:ensembleaverage\n\nvaluesmuchlargerthan1indicatestrongintensitydif-\n\nferencefeaturesthatareconsistentalongalltheexam-\n\nples,valuesthataremuchlessthan1indicateconsistent\n\nuniformregions,andvaluesthatarecloseto1areasso-\n\nciatedwithinconsistentfeatures,orrandompatterns.\nTovisualizethedetectedfacefeatureswecodethe\nensembleaverageofthewaveletcoefcientsusinggray\n\nlevelanddrawthemintheirproperspatiallayoutin\n\nFig.3.Coefcientswithvaluescloseto1areplotted\ningray,thosewithvalueslargerthan1aredarker,and\nthosewithvalueslessthan1arelighter.Itisinteresting\n\ntoobservetheemergingpatternsinthefacialfeatures.\n\nTheverticalwaveletscapturethesidesofthenose,\n\nwhilethehorizontalwaveletscapturetheeyesockets,\n\neyebrows,andtipofthenose.Interestingly,themouth\n\nisarelativelyweakfeaturecomparedtotheothers.The\n\ndiagonalwaveletsrespondstronglytotheendpointof\n\nfacialfeatures.\n2.2.2.AnalyzingthePeopleClass.\nForlearningthe\npeopleclass,wehavecollectedasetof1,800color\n\nimagesofpeopleindifferentposes(Fig.4)anduse\n\nthe1,800mirrorimagesaswelland16,726non-\n\npeoplepatterns.Alloftheimagesarenormalizedto\n\nthedimensions128\n64andthepeopleimagesare\nalignedsuchthatthebodiesarecenteredandapproxi-\n\nmatelythesamesize(thedistancefromtheshoulders\n\ntofeetisabout80pixels).\nAsinthecaseoffaces,tocodefeaturesatappro-\npriatescalesforpeopledetectionscalesatwhich\n\nweexpectrelevantfeaturesofpeopletoemerge\n\nwerestrictthesystemtothewaveletsatscalesof\n\n3232pixels(15\n5featuresforeachorientation)\nand16\n16pixels(29\n13foreachorientation).\nInourpeopledetectionsystem,ourtrainingdatabase\nisofcolorimages.Foragivenpattern,wecomputethe\n\nquadrupledensityHaartransformineachcolorchannel\n'b'22PapageorgiouandPoggio\nFigure4\n.Exampleimagesfromthedatabaseofpeopleusedfortrainingandthecorrespondingensembleaveragefeatures.Thetrainingimages\nare128\n64colorimages.Asinthecaseoffaces,theaveragefeaturevaluesarecodedingraylevelandaredisplayedintheirproperspatial\nconguration.Thewaveletsidentifythesignicantvisualboundaryinformationpresentinthepeopleimages:theverticalwaveletsrespondto\n\nthesidesofthebody,thehorizontalwaveletsrespondtothetopoftheheadandtheshoulders,andthediagonalwaveletsrespondtothehead,\n\nshoulders,hands,andfeet.\n(RGB)separatelyandtakeasthecoefcientvalueata\nspeciclocationandorientationtheonelargestinabso-\n\nlutevalueamongthethreechannels,providingthesys-\n\ntemwiththemostvisuallysignicantinformation.This\n\ntechniquemapstheoriginalcolorimagetoapseudo-\n\ncolorchannelthatgivesus1,326waveletcoefcients,\n\nthesamenumberasifwehadbeenusinggraylevel\n\nimages.Tovisualizethepatternsthatemergeusingthis\nwaveletrepresentationforpeople,wecancodetheav-\n\neragevaluesofthecoefcientsingraylevelanddisplay\n\nthemintheproperspatiallayoutaswedidforthefaces.\n\nFigure4showseachaveragewaveletdisplayedasa\n\nsmallsquarewherefeaturescloseto1aregray,stronger\n\nfeaturesaredarker,andweakerfeaturesarelighter.As\n\nwithfaces,weobservethateachclassofwaveletcoef-\n\ncientsistunedtoadifferenttypeofstructuralinfor-\n\nmation.Theverticalwaveletscapturethesidesofthe\npeople.Thehorizontalwaveletsrespondtotheshoul-\ndersandtoaweakerbeltline.Thediagonalwavelets\n\naretunedtocornerfeatures,i.e.theshoulders,hands,\n\nandfeet.The16\n16scalewaveletsprovidenespatial\nresolutionofthebodysoverallshapeandsmallerscale\n\ndetails,suchastheheadandextremities,areclearly\n\nevident.\n2.2.3.AnalyzingtheCarClass.\nThecardetection\nsystemusesadatabaseof516frontalandrearcolor\n\nimagesofcars,normalizedto128\n128andaligned\nsuchthatthefrontorrearbumperis64pixelsacross.\n\nFortraining,weusethemirrorimagesaswellforatotal\n\nof1,032positivepatternsand5,166negativepatterns.\n\nThetwoscalesofwaveletsweusefordetectionare\n\n1616and32\n32.Liketheprocessingforpeople,\nwecollapsethethreecolorchannelfeaturesintoasin-\n\nglechannelbyusingthemaximumwaveletresponse\n'b'ATrainableSystemforObjectDetection23\nFigure5\n.Exampleimagesfromthedatabaseofcarsusedfortrainingandthecorrespondingensembleaveragefeatures.Thetrainingimagesare\n128128colorimages.Thegraylevelcodingoftheaveragefeaturevaluesshowthatthewaveletsrespondtothesignicantvisualcharacteristics\nofcars:theverticalwaveletsrespondtothesidesofthecar,thehorizontalwaveletsrespondtotheroof,underside,topofthegrilleandbumper\n\narea,andthediagonalwaveletsrespondtothecornersofthecarsbody.Atthescale16\n16,wecanevenseeevidenceofwhatseemstobe\nlicenseplateandheadlightstructuresintheaverageresponses.\nofeachchannelataspeciclocation,orientation,and\nscale.Thisgivesusatotalof3,030waveletfeatures\n\nthatareusedtotraintheSVM.\nTheaveragewaveletfeaturevaluesarecodedingray\nlevelinFig.5.Aswithbothfacesandcars,muchof\n\nthecharacteristicstructureofcarsisevidentinthese\n\naverages.\n2.2.4.Discussion.\nComparingthedatabaseofpeople\n(Fig.4)tothedatabaseoffaces(Fig.3)illustratesan\n\nimportantfundamentaldifferenceinthetwoclasses.\n\nInthecaseoffaces,thereareclearpatternswithinthe\n\nface,consistingoftheeyes,noseandmouth;thesepat-\n\nternsarecommontoalltheexamples.Thisisnotthe\n\ncasewithfullbodyimagesofpeople.Thepeopledo\n\nnotshareanycommoncolorortexture.Furthermore,\nthepeopleimageshavealotofspuriousdetailssuchas\n\njackets,ties,andbags.Ontheotherhand,wewouldex-\n\npectthatpeoplecanbecharacterizedquitewellbytheir\n\nfairlysimilaroverallbodyshape,orsilhouette.Our\n\napproachtreatsthesetwocaseswherethereisdifferent\n\nunderlyinginformationcontentintheobjectclasses\n\ninauniformmanner.Frontalandrearviewsofcars\n\nhavebothacertainamountofcommoninteriorstruc-\n\nture(topofgrille,licenseplates,headlights)aswellas\nfairlyuniformouterboundaries;wewillalsoseethat\ncarsarehandledequallywellinthisframework.\nThereiscertainaprioriknowledgeembeddedinour\nchoiceofthewavelets.Theuseoftheabsolutevalue\n\nofthecoefcientmaybeessentialinthecaseofpeople\n\nsincethedirectionoftheintensitydifferenceofacer-\n\ntainfeaturesorientationisnotimportant;adarkbody\n\nagainstalightbackgroundandalightbodyagainsta\n\ndarkbackgroundshouldberepresentedashavingthe\n\nsameinformationcontent.Furthermore,wecompute\n\nthewavelettransformforagivenpatternineachofthe\n\nthreecolorchannelsandthen,forawaveletataspecic\n\nlocationandorientation,weusetheonethatislargestin\n\nmagnitudeamongstthethreechannels.Thisisbasedon\n\ntheobservationthatthereislittleconsistencyincolor\n\nbetweendifferentpeopleandallowsthesystemtokey\n\noffofthemostvisuallysignicantfeatures.Thissame\n\npriorassumptionisusedforourcardetectionsystem\n\naswell.\nOncewehavegeneratedthefeaturevectorsforan\nobjectclassandhavedonethesameforasetofimages\n\nnotinourobjectclass,weusealearningalgorithm\n\nthatlearnstodifferentiatebetweenthetwoclasses.The\n\nparticularlearningengineweuseisasupportvector\n\nmachine,describedbelow.\n'b'24PapageorgiouandPoggio\n2.3.SupportVectorMachineClassication\nThesecondkeycomponentofoursystemistheuse\nofatrainablepatternclassierthatlearnstodifferen-\n\ntiatebetweenpatternsinourobjectclassandallother\n\npatterns.Ingeneralterms,thesesupervisedlearning\n\ntechniquesrelyonhavingasetoflabeledexamplepat-\n\nternsfromwhichtheyderiveanimplicitmodelofthe\n\ndomainofinterest.Theparticularlearningenginewe\n\nuseisasupportvectormachine(SVM)classier.\nSupportvectormachines(SVM)isatechniqueto\ntrainclassiersthatiswell-foundedinstatisticallearn-\n\ningtheory;fordetails,seeVapnik(1995),Burges\n\n(1998)andVapnik(1998).Oneofthemainattractions\n\nofusingSVMsisthattheyarecapableoflearningin\n\nhigh-dimensionalspaces\nwithveryfewtrainingexam-\nples.Theyaccomplishthisbyminimizingaboundon\n\ntheempiricalerrorandthecomplexityoftheclassier,\n\natthesametime.\nThisconceptisformalizedinthetheoryofuniform\nconvergenceinprobability:\nR./\nRemp./\nC8h`;log./\n`(11)withprobability1\n.Here,\nR./\nistheexpectedrisk,\nRemp./\nistheempiricalrisk,\n`isthenumberoftrain-\ningexamples,\nhistheVCdimensionoftheclassier\nthatisbeingused,and\n8./istheVCcondenceof\ntheclassier.Intuitively,whatthismeansisthatthe\n\nuniformdeviationbetweentheexpectedriskandem-\n\npiricalriskdecreaseswithlargeramountsoftraining\n\ndata`andincreaseswiththeVCdimension\nh.This\nleadsusdirectlytotheprincipleofstructuralriskmin-\n\nimization,wherebywecanattempttominimizeatthe\n\nsametimeboththeactualerroroverthetrainingset\n\nandthecomplexityoftheclassier;thiswillbound\n\nthegeneralizationerrorasinEq.(11).Itisexactlythis\n\ntechniquethatsupportvectormachinesapproximate.\nThiscontrolingofboththetrainingseterror\nandtheclassierscomplexityhasallowedsupportvectorma-\n\nchinestobesuccessfullyappliedtoveryhighdimen-\n\nsionallearningtasks;(Joachims,1997)presentsresults\n\nonSVMsappliedtoa10,000dimensionaltextcatego-\n\nrizationproblemand(Osunaetal.,1997b)showa283\n\ndimensionalfacedetectionsystem.\nThesupportvectormachinealgorithmformulates\nthetrainingproblemasonethatnds,amongallpossi-\n\nbleseparatingsurfaces,theonethatmaximizesthedis-\n\ntancebetweentheclosestelementsofthetwoclasses.In\n\npractice,thisisdeterminedthroughsolvingaquadratic\n\nprogrammingproblem.\nUsingtheSVMformulation,thegeneralformofthe\ndecisionfunctionforapoint\nxis:f.x/D`XiD1iyiK.x;xi/Cb!(12)where`isthenumberoftrainingdatapoints,\niareLagrangeparametersobtainedintheoptimizationstep,\n\nand./isathresholdfunction.Thekernel\nK.;/denesadotproductbetweenprojectionsofthear-\n\ngumentsinsomefeaturespace;itisinthis(typically\n\nhighdimensional)featurespacethataseparatinghy-\n\nperplaneisfound.Differentkernelsinducedifferent\n\ntypesofclassiers.Forexample,with\nK.x;y/Dxytheseparatingsurfaceisahyperplaneinthespaceof\nx,K.x;y/D.xyC1/nleadstoan\nnthdegreepolyno-\nmialclassier,and\nK.x;y/Dexp\n.kxyk2/givesa\nGaussianradialbasisfunction.\nOncetheoptimizationproblemhasbeensolved,it\nisusuallythecasethatmostoftheparameters\niarezero.Thedecisionsurfacethereforeonlydependsona\n\nsmallernumberofdatapointswithnon-zero\ni;these\ndatapointsarecalled\nsupportvectors\n.Forourdetectionproblem,whereweuseaquadratic\nclassier,thedecisionsurfaceis:\nf.x/DNsXiD1iyi.xxiC1/2Cb!(13)whereiisnowanindexintojustthe\nNssupportvectors.\n3.Experiments\nInFigs.68wepresentexamplesofourtrainableobject\ndetectionsystemasappliedtothedomainsofface,\n\npeople,andcardetection,respectively.Wereiteratethat\n\nthesystemmakesnoaprioriassumptiononthescene\n\nstructureorthenumberofobjectspresentanddoesnot\n\nuseanymotionorotherdynamicalinformation.The\n\nperformanceofeachoftheseparticularinstantiations\n\nofdetectionsystemscouldeasilybeimprovedbyusing\n\nmoretrainingdata.Wehavenotsoughttopushthe\n\nlimitsofperformanceinparticulardomains;rather,our\n\ngoalhasbeentoshowthatthisuniformarchitecturefor\n\nobjectdetectionleadstohighperformanceinseveral\n\ndomains.ThedenseHaartransformcapturesarichsetoffea-\nturesthatallowstheSVMclassiertoobtainapowerful\n\nclassmodel;thewaveletsrespondtosignicantvisual\n'b'ATrainableSystemforObjectDetection25\nFigure6\n.Resultsofourfacedetectionsystemonasetofout-of-sampleimages.A,C,E,F,G,H,I,J,K,L,M,Narefromthetestdatabase\nofSung&Poggio;B,Darefromwww.starwars.com;Oisfromwww.corbis.com.Missedfaces(B,F,I,J,K,M)areduetosignicanthead\n\nrotationsthatwerenotpresentinthetrainingdata.Falsepositives(D,E,F,N)areduetoinsufcienttrainingdataandcanbeeliminatedby\n\nusingmorenegativetrainingdata.\n'b'26PapageorgiouandPoggio\nFigure7\n.Resultsofpeopledetectiononout-of-sampleimages.A,I,Karefromwww.starwars.com;B,D,E,F,H,J,Narefromwww.corbis.com;\nC,Garefromwww.cnn.com;L,O,PweretakeninBostonandCambridge;MwasprovidedbyDaimlerChrysler.Misseddetectionsaredue\n\ntothepersonbeingtooclosetotheedgeoftheimage(B)orwhenthepersonhasabodyshapenotrepresentedinthetrainingdata(I).False\n\npositivesoftenlookverysimilartopeople(A)orareduetothepresenceofstrongintensitydifferences(D,E,K,L,M,O).\n'b'ATrainableSystemforObjectDetection27\nFigure8\n.Resultsofcardetectiononout-of-sampleimages.Aisfromwww.lewistonpd.com;B,C,D,E,F,G,H,J,K,L,M,Oarefrom\nwww.corbis.com;Iisfromwww.enn.com;Nisfromwww.foxglove.com.Missedpositiveexamplesareduetoocclusions(A,F,O)orwherea\n\ncaristooclosetotheedgeoftheimage(A).Falsepositives(C,J,I,N)areduetoinsufcienttrainingandcanbeeliminatedwithmorenegative\n\ntrainingpatterns.\n'b'28PapageorgiouandPoggio\nfeatureswhilesmoothingawaynoise.Thischoiceof\nfeaturesisapriori,however;thissectionpresentsthere-\n\nsultsofmanytestscomparingdifferentfeaturesforob-\n\njectdetection.Therearemanypossiblealternaterepre-\n\nsentationsthathavebeenusedintheliterature,includ-\n\ningpixelsandPCA,andthesedifferentrepresentations\n\narecomparedinourdetectionframework.Anotherde-\n\ncisionwemadewastoignorethesignofthewavelets\n\nandusetheirabsolutevalue;thisistestedagainstthe\n\nsignedvalues.Inaddition,forpeopledetection,our\n\ntrainingsetisincolor;weempiricallyquantifytheim-\n\nprovementinperformanceusingcolordataasopposed\n\ntograyleveldata.\nIntheresultspresentedinthissection,ourpeople\ndetectionsystemistrainedon1,848positivepatterns\n\n(924frontalandrearpeopleimagesandtheirmirror\n\nimages)and11,361non-peoplepatternsandtestedon\n\n123imagescontainingpeopleand794,906non-people\n\npatterns.Thefacedetectionsystemistrainedon2,429\n\nfaceimagesand13,229non-facepatternsandtestedon\n\n105imagescontainingfacesand3,909,200non-face\n\npatterns.Thecardetectionsystemistrainedon1,032\n\nfrontalandrearcolorimagesofcars(516examples\n\nandtheirmirrors)and5,166non-carpatternsandtested\n\non90imagescontainingcarsand600,272non-car\n\npatterns.3.1.Pixels,Wavelets,PCA\nOurmainpremiseforchoosingawaveletbasedrep-\nresentationisthatintensitydifferencesbetweenlo-\n\ncaladjacentregionscontainhigherqualityinforma-\n\ntionforthepurposeofobjectdetectionthanother\n\ntraditionalrepresentations.Pixelrepresentationscap-\n\nturethemostlocalfeatures.Thesehavebeenused\n\nextensivelyforfacedetectionbutduetothevariability\n\ninthepeoplepatterns,wewouldexpectpixelrepre-\n\nsentationstofailforpeopledetection.Attheotherend\n\nofthelocalityspectrumareglobalrepresentationslike\n\nPCAwhichencodesaclassintermsofbasisfunc-\n\ntionsthataccountforthevarianceinthedataset.We\n\ncanchangetheclassoffeaturestoseewhichyields\n\nthebestperformance.Forthepeopleandcardetec-\n\ntionsystems,weusethe1,769overlapping8\n8av-\neragesinsteadofpixelsforamorefaircomparison\n\nthatusessimilarnumbersoffeatures;furthermore,\n\ntheseaveragesarehistogramequalizedinthesame\n\nmannerasthepixelrepresentation.Forfaces,weuse\n\npixels.\n3.2.Signedvs.UnsignedWavelets\nThefeaturesoursystemusesdonotcontaininforma-\ntiononthesignoftheintensitygradient,butarethe\n\nabsolutevaluesofthewaveletresponses.Withthese\n\nfeatures,wearesolelydescribingthestrengthofthe\n\nintensitydifferences.Foranobjectclasslikepeople,\n\nwhereadarkbodyonalightbackgroundhasthesame\n\ninformationasalightbodyonadarkbackgroundand\n\nthereislittleconsistencyintheintensities,thesignof\n\nthegradientshouldnotmatter.Ontheotherhand,ifwe\n\nconsiderfacepatterns,thereisconsistentinformation\n\ninthesignofthegradientoftheintensitydifferences.\n\nForinstance,theeyesaredarkerthanthecheeksand\n\ntheforeheadandthemouthisdarkerthanthecheeks\n\nandthechin;thesetypesofrelationshipshavebeen\n\nexploredinSinha(1994).Wemightexpectthatusing\n\nthesigninformation(\nCor)wouldenhanceresults\ninthiscase.\n3.3.Completevs.Overcomplete\nThemotivationforusingtheovercompleteHaar\nwaveletrepresentationistoprovidearichersetoffea-\n\nturesoverwhichthesystemwilllearnand,ultimately,\n\namoreaccuratedescriptionofaperson.Wetestthis\n\nagainstthestandardcompleteHaarrepresentation.\n3.4.Colorvs.GrayLevel\nForcolorimagesinthecaseofpeopledetection,wecol-\nlapseinformationfromthethreecolorchannelsintoa\n\nsinglepseudo-channelthatmaintainsthestrongestlo-\n\ncalintensitydifferences.Itisintuitivelyobviousthat\n\ncolorimagescontainmuchricherinformationthanthe\n\ncorrespondinggray-scaleversions.Wepresentexperi-\n\nmentsthatquantifytheinherentinformationcontentin\n\nusingcolorimagesasopposedtograylevelforobject\n\ndetection.3.5.Faces,People,andCars\nOurROCcurveshighlighttheperformanceofthede-\ntectionsystemasaccuracyoverout-of-sampledata\n\nagainsttherateoffalsepositives,measuredasthenum-\n\nberoffalsepositivesperpatternexamined.TheROC\n\ncurvesthatcomparedifferentrepresentationsforthe\n\nfacedetectionsystemareshowninFig.9.Therepre-\n\nsentationsusedforfacedetectionarerawpixels(361\n'b'ATrainableSystemforObjectDetection29\nFigure9\n.ROCcurvesforfacedetectioncomparingdifferentfea-\nturesusingpixelfeaturesasabenchmark.\nfeatures),histogramequalizedpixels(361features),\nprincipalcomponentsofhistogramequalizedpixels\n\n(361features),graysignedwavelets(1,740features),\n\nandgrayunsignedwavelets(1,740features).Grayun-\n\nsignedwaveletsyieldthebestperformance,whilegray\n\nsignedwaveletsandhistogramequalizedgraypixels\n\nleadtothesamelevelofperformance,slightlyworse\n\nthanthegrayunsignedwavelets;theversionusingprin-\n\ncipalcomponentsislessaccuratethanthehistogram\n\nequalizedpixels.Thattheunsignedwaveletsperform\n\nbetterthanthesignedwaveletsissomewhatcounterin-\n\ntuitive;wehadpostulatedthatthesignofthewavelets\n\ncontainimportantinformationforfacedetectionsince\n\nhumanfaceshaveconsistentpatterns.Usingtheabso-\n\nlutemagnitudeofthewaveletsmayresultinarepre-\n\nsentationwithlessvariabilitythanthesignedversion,\n\nwhilestillencodingtheimportantinformationforde-\n\ntection,allowingtheclassiertondabetterdecision\n\nsurface.Togaugetheperformanceofthesystem,we\n\ncantakeapointontheROCcurveandtranslatethe\n\nperformanceintorealimageterms.Forinstance,fora\n\n90%detectionrate,wemusttolerate1falsepositivefor\n\nevery100,000patternsprocessed,orapproximately1\n\nfalsepositiveperimage.\nTheROCcurvesforthepeopledetectionsystemare\nshowninFig.10.Here,usingallthecolorfeatures\n\nperformsthebest,whereforinstancea90%detection\n\nrateleadsto1falsepositiveforevery10,000patterns\n\nthatareprocessed(about3falsepositivesperimage).\n\nGraylevelwaveletsperformsignicantlybetterthan\n\nthecorrespondinggraylevelaverages;here,unlikethe\nFigure10\n.ROCcurvesforpeopledetectioncomparingdifferent\nfeaturesusingpixeltypefeaturesasabenchmark.\ncaseoffacedetection,therawpixelvaluesdonotchar-\nacterizetheobjectclasswell.Whenweusethe1,769\n\nPCAsofthe8\n8averagestheperformanceissignif-\nicantlyworse.Figure10alsosupportsourhypothesis\n\nonthenecessityofanovercompleteversusacomplete\n\nrepresentation;thesystemstartingfromacompleterep-\n\nresentation(120colorwavelets)underperformsallof\n\nthesystemsbasedontheovercompleterepresentation.\n\nThesignedversionsofboththecolorandgraylevel\n\nwaveletsperformworsethantheirunsignedversions.\n\nWehypothesizethatthereasonisthesameasthecase\n\nforfaces,thattheunsignedversionsresultinmorecom-\n\npactrepresentationsoverwhichitiseasiertolearn(see\n\ntheintuitiongiveninSection2.2).\nThepreliminaryROCcurveforourcardetectionsys-\ntemusingunsignedwaveletfeaturesoncolorimages\n\nisshowninFig.11.\n4.AReal-TimeApplication\nTherearemanypossibleapplicationsofthistechnol-\nogy,rangingfromautomotiveassistancesystemsto\n\nsurveillance.Theonlyfactorthatisinhibitingoursys-\n\ntemfrombeingusedrightnowinsuchsystemsisthe\n\nrelativelyslowprocessingspeed.Itisimportanttonote\n\nthatourfullsystemis,forthemostpart,anunoptimized\n\nresearchtool;wehavenotinvestedsignicantamounts\n\nofeffortinimprovingthecorespeed.\nWehavedevelopedamodiedversionofour\nstaticpeopledetectionsystemthatachievesreal-time\n'b'30PapageorgiouandPoggio\nFigure11\n.PreliminaryROCcurveforcardetectionusingwavelet\nfeaturesovercolorimages.\nperformance.Thissectiondescribesareal-timeappli-\ncationofourtechnologyaspartofalargersystemfor\n\ndriverassistance;thecombinedsystem,includingour\n\npeopledetectionmodule,iscurrentlydeployedlive\n\ninaDaimlerChryslerSClassdemonstrationvehicle.\n\nTheremainderofthissectiondescribestheintegrated\n\nsystem.4.1.SpeedOptimizations\nOuroriginalunoptimizedstaticpeopledetectionsys-\ntemusingcolorimagesprocessessequencesatarate\n\nof1frameper20minutes;thisisclearlyinadequatefor\n\nanyreal-timeautomotiveapplication.Wehaveimple-\n\nmentedoptimizationsthathaveyieldedseveralorders\n\nofmagnitudeworthofspeedups.\n4.1.1.GrayLevelImages.\nOuruseofcolorimages\nforpeopledetectionispredicatedonthefactthat,\n\nforpeople,thethreedifferentcolorchannels(RGB)\n\ncontainasignicantamountofinformationthatgets\n\nwashedoutingraylevelimagesofthesamescene.This\n\nuseofcolorinformationresultsinsignicantcomputa-\n\ntionalcost;theresizingandHaartransformoperations\n\nareperformedoneachcolorchannelseparately.Inor-\n\ndertoimprovesystemspeed,wemodifythesystemto\n\nprocessintensityimages.\n4.1.2.UsingaSubsetoftheFeatures.\nInsteadofus-\ningtheentiresetof1,326waveletfeatures,thesystem\nundergoesafeatureselectionstepwherewepickjust\n29ofthemoreimportantfeaturesacrossourtraining\n\nsetthatencodethestructureofthebody.Thischanges\n\nthe1,326dimensionalinnerproductinEq.(13)intoa\n\n29dimensionalinnerproduct.Thesewaveletsarecur-\n\nrentlymanuallychosenasthestrongestandweakest\n\nwaveletsthatareconsistentacrosstheensembleeither\n\nasindicatorsofanintensityboundaryorauniformre-\n\ngion.Thereare6verticaland1horizontalcoefcients\n\natthescaleof32\n32and14verticaland8horizontal\natthescaleof16\n16.Figure12showsthecoefcients\nFigure12\n.Thereducedsetof29waveletfeaturesforfastpeople\ndetectionoverlayedonanexampleimageofaperson.\n'b'ATrainableSystemforObjectDetection31\nFigure13\n.ROCcurvesforpeopledetectioncomparingdifferent\nwaveletfeaturesanddifferentfeaturesetsizes;intheversionrunning\n\nintheexperimentalDaimlerChryslercar,weusethe29grayunsigned\n\nversion.\nintheirproperspatiallocations,overlayedonanimage\nfromthetrainingdatabase.Thissparserrepresentation\n\ndoesnot,ofcourse,yieldthesameperformance;Fig.13\n\nshowshowour29grayunsignedwaveletversioncom-\n\npareswithotherwaveletfeaturesandfeaturesetsizes.\n4.1.3.ReducedSetVectors.\nFromEq.(13),wecan\nseethatthecomputationtimeisalsodependentonthe\n\nnumberofsupportvectors,\nNs;inoursystem,thisis\ntypicallyontheorderof1,000.Weuseresultsfrom\n\n(Burges,1996)toobtainanequivalentdecisionsurface\n\nintermsofasmallnumberofsyntheticvectors.This\n\nmethodyieldsanewdecisionsurfacethatisequivalent\n\ntotheoriginalonebutusesjust29vectors.\n4.1.4.FocusofAttention.\nTofurtherenhancethepro-\ncessingspeedofthesystem,wecanuseafocusof\n\nattentionmodulethatconcentratesprocessingonlyon\n\nareasofanimagethatarelikelytocontainpeople.This\n\nfocusofattentioncankeyoffofdifferentcharacteris-\n\ntics,includingmotion,distance,localimagecomplex-\n\nity,shape,andcolor(Ittietal.,1998;IttiandKoch,\n\n1999).4.2.IntegrationwiththeDaimlerChryslerUrban\nTrafcAssistant\nTothisend,wehaveintegratedourpeopledetection\nsystemwithastereo-basedobstacledetectionsystem\nincollaborationwithDaimlerChryslerAG.Daimler-\nChryslerhasobviouslymotivatedinterestsinobstacle\n\ndetectionalgorithmsforautomotiveapplicationsasa\n\nmeanstoaiddrivingand,ultimately,toallowforau-\n\ntonomousdriving.Oneoftheimportantrequirements\n\nofthesystemisthatitisabletodealwithbothhighway\n\nandurbanscenes,thelatterbeingmuchmorecomplex\n\nthantheformer.\nTheDaimlerChryslerUrbanTrafcAssistant(UTA)\nisareal-timevisionsystemforobstacledetection,\n\nrecognition,andtracking(Frankeetal.,1998).UTA\n\nrelieson3Dpositionanddepthinformation,obtained\n\nusingabinocularstereovisionsystem.Toovercome\n\ntheexpensivecorrespondenceproblem,theyhavede-\n\nvelopedafeaturebasedapproachtostereoanalysisthat\n\nrunsat25Hzona200MHzPowerPC604.Thesys-\n\ntemclustersfeaturepointsthatcorrespondtothesame\n\nobject,providingarectangularboundingboxaround\n\neachobstacleinthescene.\nUsingthisboundingboxwhichcloselyoutlinesthe\nshapeoftheobstacle,weexpandthisareatoprovide\n\nalargerregionofinterestinwhichwewillrunour\n\npeopledetectionsystem;thisisdonetoalleviatepossi-\n\nblemisalignmentsintheboundingboxprovidedbythe\n\nstereosystem.Furthermore,thestereosystemprovides\n\nanaccurateestimateofthedistancetoeachobject;us-\n\ningthisinformationwecanconstrainthenumberof\n\nsizesatwhichwelookforpeopletoasmallnumber,\n\ntypicallyunderthreescales.\nWithintheseregionsofinterest,weuseour29gray\nlevelfeaturesystemwiththereducedsetmethodthat\n\nlowersthenumberofsupportvectorsto29.Inreal-\n\nworldtestsequencesprocessedwhiledrivingthrough\n\nEsslingen/Stuttgart,Germany,weareabletoachieve\n\nratesofmorethan10Hzwithunder15msperobstacle\n\nbeingspentinthepeopledetectionmodule.\n5.Conclusion\nWehavedescribedageneral,trainableobjectdetec-\ntionsystemforstaticimages;inthispaper,resultsare\n\nshownforface,people,andcardetectionwithexcel-\n\nlentresults.Thesystemusesarepresentationbasedon\n\nanovercompletedictionaryofHaarwaveletsthatcap-\n\nturesthesignicantinformationaboutelementsofthe\n\nobjectclass.Whencombinedwithapowerfulclassi-\n\ncationengine,thesupportvectormachine,weobtaina\n\ndetectionsystemthatachievesourgoalsofhighaccu-\n\nracywithlowratesoffalsepositives.Forfacedetec-\n\ntion,typicalout-of-sampleperformanceisadetection\n'b'32PapageorgiouandPoggio\nrateof90%with1falsepositiveforevery100,000pat-\nternsthatareprocessedandforpeopledetectionwecan\n\nachieve90%accuracywith1falsepositiveforevery\n\n10,000patternsprocessed.Toourknowledge,thisis\n\ntherstpeopledetectionsystemdescribedintheliter-\n\naturethatispurelyapatternclassicationsystemand\n\nthatdoesnotrelyonmotion,tracking,backgroundsub-\n\ntraction,oranyassumptionsonthescenestructure.\nOurresultsincardetectioninstaticimagesusing\nthistrainablearchitecturearealsonovel.Duetothe\n\nsignicantchangeinthe2Dimageinformationofcars\n\nundervaryingviewpoint,developingaposeinvariant\n\ncardetectionsystemislikelytobesignicantlymore\n\ndifcultthanaposeinvariant(upright)peopledetection\n\nsystem,sincethecharacteristicpatternofapersondoes\n\nnotchangesignicantlyfromdifferentviewpoints.In-\n\nsteadofafullpatternapproach,acomponentbased\n\napproachtocardetectionthatidentiesdifferentparts\n\nofacarheadlights,wheels,windshield,etc.inthe\n\nappropriatecongurationmaybemoresuccessful.Pre-\n\nliminaryworkonsuchacomponentbasedsystemfor\n\npeopledetectionisdescribedinMohan(1999).\nWhilethecoresystemwedescribeimplementsa\nbruteforcesearchintheentireimage,thedetector\n\nwouldbemoreappropriateaspartofalargersys-\n\ntem.Forinstance,ifweincorporatea\nfocusofattention\nmoduleasinthecaseoftheDaimlerChryslerintegra-\n\ntion,thesystemwillbeabletotargetspecicareasin\n\nthescene.Thisresultsinbothfasterprocessingtime\n\nandmorerobustperformance.\nTheperformancethatthissystemachievescanbeen-\nhancedbyincorporatingdynamicalinformationwhen\n\nweareprocessingvideosequences.Severaltechniques\n\nthatweareworkingonhavealreadyimprovedtheper-\n\nformancetothepointwhereourfalsepositiverateis\n\nnearzero.\nAcknowledgments\nThispaperdescribesresearchdonewithintheCenter\nforBiologicalandComputationalLearninginthe\n\nDepartmentofBrainandCognitiveSciencesandatthe\n\nArticialIntelligenceLaboratoryattheMassachusetts\n\nInstituteofTechnology.Thisresearchissponsoredby\n\ngrantsfromtheNationalScienceFoundation,ONR,\n\nandDarpa.AdditionalsupportisprovidedbyEastman\n\nKodakCompany,DaimlerChrysler,Siemens,ATR,\n\nAT&T,Compaq,HondaR&DCo.,Ltd.,MerrillLynch,\n\nNTTandCentralResearchInstituteofElectricPower\n\nIndustry.\nReferences\nBetke,M.,Haritaoglu,E.,andDavis,L.1997.Highwaysceneanaly-\nsisinhardreal-time.In\nProceedingsofIntelligentTransportation\nSystems.Betke,M.andNguyen,H.1998.Highwaysceneanalysisforma\nmovingvehicleunderreducedvisibilityconditions.In\nProceed-\ningsofIntelligentVehicles\n,pp.131136.\nBeymer,D.,McLauchlan,P.,Coifman,B.,andMalik,J.1997.A\nreal-timecomputervisionsystemformeasuringtrafcparameters.\n\nInProceedingsofComputerVisionandPatternRecognition\n,pp.\n495501.Bregler,C.andMalik,J.1996.Learningappearancebasedmodels:\nMixturesofsecondmomentexperts.In\nAdvancesinNeural\nInformationProcessingSystems\n.Burges,C.1996.Simpliedsupportvectordecisionrules.In\nPro-\nceedingsof13thInternationalConferenceonMachineLearning\n.Burges,C.1998.Atutorialonsupportvectormachinesforpat-\nternrecognition.In\nProceedingsofDataMiningandKnowledge\nDiscovery\n,U.Fayyad(Ed.),pp.143.\nForsyth,D.andFleck,M.1997.Bodyplans.In\nProceedingsof\nComputerVisionandPatternRecognition\n,pp.678683.\nForsyth,D.andFleck,M.1999.Automaticdetectionofhumannudes,\nInternationalJournalofComputerVision\n,32(1):6377.\nFranke,U.,Gavrila,D.,Goerzig,S.,Lindner,F.,Paetzold,F.,and\nWoehler,C.1998.Autonomousdrivinggoesdowntown.\nIEEEIntelligentSystems\n,pp.3240.\nHaritaoglu,I.,Harwood,D.,andDavis,L.1998.W4:Who?When?\nWhere?What?Arealtimesystemfordetectingandtracking\n\npeople.In\nFaceandGestureRecognition\n,pp.222227.\nHeisele,B.andWohler,C.1998.Motion-basedrecognitionofpedes-\ntrians.In\nProceedingsofInternationalConferenceonPattern\nRecognition\n,pp.13251330.\nHogg,D.1983.Model-basedvision:Aprogramtoseeawalking\nperson.ImageandVisionComputing\n,1(1):520.\nItti,L.andKoch,C.1999.Acomparisonoffeaturecombination\nstrategiesforsaliency-basedvisualattentionsystems.In\nHumanVisionandElectronicImaging\n,vol.3644,pp.473482.\nItti,L.,Koch,C.,andNiebur,E.1998.Amodelofsaliency-\nbasedvisualattentionforrapidsceneanalysis.\nIEEETransac-\ntionsonPatternAnalysisandMachineIntelligence\n,20(11):1254\n1259.Joachims,T.1997.Textcategorizationwithsupportvectormachines.\nTechnicalReportLS-8Report23,UniversityofDortmund.\nLipson,P.1996.Contextandcongurationbasedsceneclassication.\nPh.D.thesis,MassachusettsInstituteofTechnology.\nLipson,P.,Grimson,W.,andSinha,P.1997.Congurationbased\nsceneclassicationandimageindexing.In\nProceedingsofCom-\nputerVisionandPatternRecognition\n,pp.10071013.\nMallat,S.1989.Atheoryformultiresolutionsignaldecomposition:\nThewaveletrepresentation.\nIEEETransactionsonPatternAnal-\nysisandMachineIntelligence\n,11(7):674693.\nMcKenna,S.andGong,S.1997.Non-intrusivepersonauthenti-\ncationforaccesscontrolbyvisualtrackingandfacerecogni-\n\ntion.In\nAudio-andVideo-basedBiometricPersonAuthentication\n,J.Bigun,G.Chollet,andG.Borgefors(Eds.),pp.177\n\n183.Moghaddam,B.andPentland,A.1995.Probabilisticvisuallearning\nforobjectdetection.In\nProceedingsof6thInternationalConfer-\nenceonComputerVision\n.'b'ATrainableSystemforObjectDetection33\nMohan,A.1999.Robustobjectdetectioninimagesbycomponents.\nMastersThesis,MassachusettsInstituteofTechnology.\nOsuna,E.,Freund,R.,andGirosi,F.1997a.Supportvectormachines:\nTrainingandapplications.A.I.Memo1602,MITArticialIntel-\n\nligenceLaboratory.\nOsuna,E.,Freund,R.,andGirosi,F.1997b.Trainingsupportvec-\ntormachines:Anapplicationtofacedetection.In\nProceedingsof\nComputerVisionandPatternRecognition\n,pp.130136.\nRohr,K.1993.Incrementalrecognitionofpedestriansfromimage\nsequences.In\nProceedingsofComputerVisionandPatternRecog-\nnition,pp.813.\nRowley,H.,Baluja,S.,andKanade,T.1998.Neuralnetwork-based\nfacedetection.\nIEEETransactionsonPatternAnalysisandMa-\nchineIntelligence\n,20(1):2338.\nShio,A.andSklansky,J.1991.Segmentationofpeopleinmotion.\nInIEEEWorkshoponVisualMotion\n,pp.325332.\nSinha,P.1994.Qualitativeimage-basedrepresentationsforobject\nrecognition.A.I.Memo1505,MITArticialIntelligenceLabo-\n\nratory.\nStollnitz,E.,DeRose,T.,andSalesin,D.1994.Waveletsforcomputer\ngraphics:Aprimer.TechnicalReport94-09-11,Departmentof\n\nComputerScienceandEngineering,UniversityofWashington.\nSung,K.-K.1995.Learningandexampleselectionforobjectand\npatterndetection.Ph.D.Thesis,MITArticialIntelligenceLab-\n\noratory.\nSung,K.-K.andPoggio,T.1994.Example-basedlearningforview-\nbasedhumanfacedetection.A.I.Memo1521,MITArticial\n\nIntelligenceLaboratory.\nVaillant,R.,Monrocq,C.,andCun,Y.L.1994.Originalapproach\nforthelocalisationofobjectsinimages.\nIEEProceedingsVision\nImageSignalProcessing\n,141(4):245250.\nVapnik,V.1995.\nTheNatureofStatisticalLearningTheory\n.Springer\nVerlag.\nVapnik,V.1998.\nStatisticalLearningTheory\n.JohnWileyandSons:\nNewYork.\nWren,C.,Azarbayejani,A.,Darrell,T.,andPentland,A.1995.\nPnder:Real-timetrackingofthehumanbody.TechnicalRe-\n\nport353,MITMediaLaboratory.\n'