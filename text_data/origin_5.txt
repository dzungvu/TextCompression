b"PersonbyProbabilisticRelativeDistanceComparison\n\nWei-ShiZheng\n1\n;\n2\n,ShaogangGong\n2\n,andTaoXiang\n2\n1\nSchoolofInformationScienceandTechnology,SunYat-senUniversity,China\n2\nSchoolofElectronicEngineeringandComputerScience,QueenMaryUniversityofLondon,UK\nwszheng@ieee.org,sgg@eecs.qmul.ac.uk,txiang@eecs.qmul.ac.uk\nAbstract\nMatchingpeopleacrossnon-overlappingcameraviews,\nknownaspersonrischallengingduetothe\nlackofspatialandtemporalconstraintsandlargevisualap-\npearancechangescausedbyvariationsinviewangle,light-\ning,backgroundclutterandocclusion.Toaddressthese\nchallenges,mostpreviousapproachesaimtoextractvisual\nfeaturesthatarebothdistinctiveandstableunderappear-\nancechanges.However,mostvisualfeaturesandtheircom-\nbinationsunderrealisticconditionsareneitherstablenor\ndistinctivethusshouldnotbeusedindiscriminately.Inthis\npaper,weproposetoformulatepersonras\nadistancelearningproblem,whichaimstolearntheop-\ntimaldistancethatcanmaximisesmatchingaccuracyre-\ngardlessthechoiceofrepresentation.Tothatend,weintro-\nduceanovelProbabilisticRelativeDistanceComparison\n(PRDC)model,whichdiffersfrommostexistingdistance\nlearningmethodsinthat,ratherthanminimisingintra-class\nvariationwhilstmaximisingintra-classvariation,itaims\ntomaximisetheprobabilityofapairoftruematchhav-\ningasmallerdistancethanthatofawrongmatchpair.\nThismakesourmodelmoretoleranttoappearancechanges\nandlesssusceptibletomodelover.Extensiveexperi-\nmentsarecarriedouttodemonstratethat1)byformulating\nthepersonronproblemasadistancelearning\nproblem,notableimprovementonmatchingaccuracycan\nbeobtainedagainstconventionalpersonr\ntechniques,whichisparticularlytwhenthetrain-\ningsamplesizeissmall;and2)ourPRDCoutperformsnot\nonlyexistingdistancelearningmethodsbutalsoalternative\nlearningmethodsbasedonboostingandlearningtorank.\n1.Introduction\nTherehasbeenanincreasinginterestinmatchingpeo-\npleacrossdisjointcameraviewsinamulti-camerasystem,\nknownasthepersonproblem[10,7,14,8,\n\nMostofthisworkwasdonewhentheauthorwasatQMUL.\nFigure1.Typicalexamplesofappearancechangescausedby\ncross-viewvariationsinviewangle,lighting,backgroundclutter\nandocclusion.Eachcolumnshowstwoimagesofthesameper-\nsonfromtwodifferentcameraviews.\n3].Forunderstandingbehaviourofpeopleinalargeareaof\npublicspacecoveredbymultipleno-overlappingcameras,\nitiscriticalthatwhenatargetdisappearsfromoneview,\nhe/shecanbeinanotherviewamongacrowdof\npeople.Despitethebesteffortsfromcomputervisionre-\nsearchersinthepast5years,theperson\nproblemremainslargelyunsolved.,inabusy\nuncontrolledenvironmentmonitoredbycamerasfroma\ndistance,personvrelyinguponbiometricssuch\nasfaceandgaitisinfeasibleorunreliable.Withoutac-\ncuratetemporalandspatialconstraintsgiventhetypically\nlargegapsbetweencameraviews,visualappearancefea-\nturesalone,extractedmainlyfromclothing,areintrinsically\nweakformatchingpeople(e.g.mostpeopleinwinterwear\ndarkclothes).Inaddition,aperson'sappearanceoftenun-\ndergoeslargevariationsacrossdifferentcameraviewsdue\ntochangesinviewangle,lighting,background\nclutterandocclusion(seeFig.1),resultingindifferentpeo-\npleappearingmorealikethanthatofthesamepersonacross\ndifferentcameraviews(seeFigs.4and5).\nMostexistingstudieshavetriedtoaddresstheabove\nproblemsbyseekingamoredistinctiveandstablefea-\nturerepresentationofpeople'sappearance,rangingwidely\nfromcolorhistogram[10,7],graphmodel[4],spatialco-\noccurrencerepresentationmodel[14],principalaxishis-\ntogram[8],rectangleregionhistogram[2],tocombina-\ntionsofmultiplefeatures[7,3].Afterfeatureextraction,\nexistingmethodssimplychooseastandarddistancemea-\n649\n"b'suresuchas\nl\n1\n-norm[14],\nl\n2\n-normbaseddistance[8],or\nBahattacharyyadistance[7].Howeverundersevereview-\ningconditionchangesthatcancausetintra-object\nappearancevariation(e.g.viewangle,lighting,occlusion),\ncomputingasetoffeaturesthatarebothdistinctiveandsta-\nbleunderallconditionchangesisextremelyhardifnotim-\npossibleunderrealisticconditions.Moreover,giventhat\ncertainfeaturescouldbemorereliablethanothersundera\ncertaincondition,applyingastandarddistancemeasureis\nundesirableasitessentiallytreatsallfeaturesequallywith-\noutdiscardingbadfeaturesselectivelyineachindividual\nmatchingcircumstance.\nInthispaper,weproposetoformulatepersonre-\nasadistancelearningproblemwhichaimsto\nlearntheoptimaldistancemetricthatcanmaximisematch-\ningaccuracyregardlessthechoiceofrepresentation.To\nthatend,anovelProbabilisticRelativeDistanceCompar-\nison(PRDC)modelisproposed.Theobjectivefunction\nusedbyPRDCaimstomaximisetheprobabilityofapair\noftruematch(i.e.twotrueimagesofpersonA)havinga\nsmallerdistancethanthatofapairofrelatedwrongmatch\n(i.e.twoimagesofpersonAandBrespectively).Thisis\nincontrastwiththatofaconventionaldistancelearningap-\nproach,whichaimstominimiseintra-classvariationinan\nabsolutesense(i.e.makingallimagesofpersonAmore\nsimilar)whilstmaximisinginter-classvariation(i.e.mak-\ningallimagesofpersonAandBmoredissimilar).Our\napproachismotivatedbythenatureofourproblem.Specif-\nically,thepersonproblemhasthreecharac-\nteristics:1)theintra-classvariationcanbelargeandimpor-\ntantlycanbevariedfordifferentclassesasit\niscausedbydifferentconditionchanges(seeFig.1);2)the\ninter-classvariationalsovariesdrasticallyacrossdifferent\npairsofclasses;and3)annotatingmatchedpeopleacross\ncameraviewsistediousandtypicallyonlylimitednum-\nberofclasses(people)areavailablefortrainingwitheach\nclasscontainingonlyahandfulofimagesofapersonfrom\ndifferentcameraviews(i.e.under-samplingforbuildinga\nrepresentativeclassdistribution).Byexploringarelative\ndistancecomparisonmodelprobabilistically,ourmodelis\nmoretoleranttothelargeintra/inter-classvariationandse-\nvereoverlappingofdifferentclassesinamulti-dimensional\nfeaturespace.Furthermore,duetothethirdcharacteristics\nofunder-sampling,amodelcouldbeeasilyoverifit\nislearnedbyminimisingintra-classdistanceandmaximis-\ninginter-classdistancesimultaneouslybybrutalforce.In\ncontrast,ourapproachisabletolearnadistancewithmuch\nreducedcomplexitythusalleviatingtheoverprob-\nlem,asvalidatedbyourextensiveexperiments.\nRelatedwork\nAlthoughithasnotbeenexploitedforper-\nsondistancelearningisawell-studied\nproblemwithalargenumberofmethodsreportedinthe\nliterature[16,5,17,7,17,12,15,9,1].However,most\nofthemsufferfromtheoverproblemasexplained\nabove.Recently,afewapproachesattempttoalleviatethe\nproblembyincorporatingtheideaofrelativedistancecom-\nparisonasourPRDCmodel[12,15,9].However,inthese\nworks,therelativedistancecomparisonisnot\nprobabilistically,andimportantlyisusedasanoptimisation\nconstraintratherthanobjectivefunction.Thereforethese\napproaches,eitherimplicitly[12,9]orexplicitly[15]still\naimtolearnadistancebywhicheachclassbecomesmore\ncompactwhilstbeingmoreseparablefromeachotherin\nanabsolutesense.Wedemonstratethroughexperiments\nthattheyremainsusceptibletooverforpersonre-\n\nTherehavebeenacoupleoffeatureselectionbased\nmethodsproposedforperson\n[7,11].Grayetal.[7]proposedtouseboostingtoselect\nasubsetofoptimalfeaturesformatchingpeople.How-\never,inaboostingframework,goodfeaturesareonlyse-\nlectedsequentiallyandindependentlyintheoriginalfea-\nturespacewheredifferentclassescanbeheavilyover-\nlapped.Suchselectionmaynotbegloballyoptimal.Rather\nthanselectingfeaturesindividuallyandindependently(lo-\ncalselection),weaimtolearnanoptimaldistancemeasure\nforallfeaturesjointlyviadistancelearning(globalselec-\ntion).Analternativeglobalselectionapproachwasdevel-\nopedbasedonRankSVM[11].Byformulatingtheperson\nasarankingproblem,theRankSVMap-\nproachsharesthespiritofrelativecomparisoninourmodel.\nNevertheless,ourapproachismoreprincipledandtractable\nthantheRankSVMinthat1)PRDCisasecond-orderfea-\ntureselectionapproachwhereasRankSVMisa\nonewhichisnotabletoexploitcorrelationsofdifferent\nfeatures;2)althoughRankSVMalleviatestheover\nproblembyfusingarankingerrorfunctionwithalarge\nmarginfunctioninitsobjectivefunction,theprobabilistic\nformulationofourobjectivefunctionmakesPRDCmore\ntoleranttolargeintra-andinter-classvariationsanddata\nsparsity;3)tuningthecriticalfreeparameterofRankSVM\nthatdeterminestheweightbetweenthemarginfunctionand\ntherankingerrorfunctioniscomputationallycostlyandcan\nbesub-optimalgivenlimiteddata.Incontrast,ourPRDC\nmodeldoesnotsuchaproblem.Wedemonstratethead-\nvantageofourapproachoverboththeBoosting[7]and\nRankSVM[11]basedmethodsthroughexperiments.\nThemaincontributionsofthisworkaretwo-fold.1)We\nformulatethepersonproblemasadistance\nlearningproblem,whichleadstonoteworthyimprovement\nonaccuracy.Tothebestofourknowl-\nedge,ithasnotbeeninvestigatedbefore.2)Wepropose\naprobabilisticrelativedistancecomparisonbasedmethod\nthatovercomesthelimitationsofexistingdistancelearning\nmethodswhenappliedtoperson\n650\n'b'2.ProbabilisticRelativeDistanceComparison\nforPerson\nLetusformallycastthepersononproblem\nintothefollowingdistancelearningproblem.Foranimage\nz\nofpersonA,wewishtolearnare-identmodel\ntosuccessfullyidentifyanotherimage\nz\n0\nofthesameper-\nsoncapturedelsewhereinspaceandtime.Thisisachieved\nbylearningadistancefunction\nf\n(\n\n;\n\n)\nsothat\nf\n(\nz\n;\nz\n0\n)\n<\nf\n(\nz\n;\nz\n00\n)\n,where\nz\n00\nisanimageofanyotherpersonex-\nceptA.Tothatend,givenatrainingset\n\n(\nz\ni\n;y\ni\n)\n\n,where\nz\ni\n2Z\nisamulti-dimensionalfeaturevectorrepresenting\ntheappearanceofapersoninoneviewand\ny\ni\nisitsclass\nlabel(personID),weapairwiseset\nO\n=\nf\nO\ni\n=\n(\nx\np\ni\n;\nx\nn\ni\n)\ng\n,whereeachelementofapair-wisedata\nO\ni\nitself\niscomputedusingapairofsamplefeaturevectors.More\n,\nx\np\ni\nisadifferencevectorcomputedbetweena\npairofrelevantsamples(ofthesameclass/person)and\nx\nn\ni\nisadifferencevectorfromapairofrelatedirrelevantsam-\nples,i.e.onlyonesampleforcomputing\nx\nn\ni\nisoneofthe\ntworelevantsamplesforcomputing\nx\np\ni\nandtheotherisa\nmis-matchfromanotherclass.Thedifferencevector\nx\nbe-\ntweenanytwosamples\nz\nand\nz\n0\niscomputedby\nx\n=\nd\n(\nz\n;\nz\n0\n)\n;\nz\n;\nz\n0\n2Z\n(1)\nwhere\nd\nisanentry-wisedifferencefunctionthatoutputsa\ndifferencevectorbetween\nz\nand\nz\n0\n.Thespeformof\nfunction\nd\nwillbedescribedinSec.2.3.\nGiventhepairwiseset\nO\n,adistancefunction\nf\ncanbe\nlearnedbasedonrelativedistancecomparisonsothatadis-\ntancebetweenarelevantsamplepair(\nf\n(\nx\np\ni\n)\n)issmaller\nthanthatbetweenarelatedirrelevantpair(\nf\n(\nx\nn\ni\n)\n).That\nis\nf\n(\nx\np\ni\n)\n<f\n(\nx\nn\ni\n)\nforeachpair-wisedata\nO\ni\n.Tothisend,\nwemeasuretheprobabilityofthedistancebetweenarele-\nvantpairbeingsmallerthanthatofarelatedirrelevantpair\nas:\nP\n(\nf\n(\nx\np\ni\n)\n<f\n(\nx\nn\ni\n))=\n\n1+exp\n\nf\n(\nx\np\ni\n)\n\nf\n(\nx\nn\ni\n)\n\n\n1\n:\n(2)\nWeassumetheeventsofdistancecomparisonbetweena\nrelevantpairandanirrelevantpair,i.e.\nf\n(\nx\np\ni\n)\n<f\n(\nx\nn\ni\n)\n,\nareindependent\n1\n.Then,basedonthemaximumlikelihood\nprinciple,theoptimalfunction\nf\ncanbelearnedasfollows:\nf\n=argmin\nf\nr\n(\nf;\nO\n)\n;\nr\n(\nf;\nO\n)=\n\nlog(\nY\nO\ni\nP\n(\nf\n(\nx\np\ni\n)\n<f\n(\nx\nn\ni\n)))\n:\n(3)\nThedistancefunction\nf\nisparameterisedasaMahanalobis\n(quadratic)baseddistancefunction:\nf\n(\nx\n)=\nx\nT\nMx\n;\nM\n\n0\n(4)\nwhere\nM\nisaematrix.Thedistancelearning\nproblemthusbecomeslearning\nM\nusingEqn.(3).Directly\nlearning\nM\nusingsemidprogramtechniquesiscom-\nputationallyexpensiveforhighdimensionaldata[15].In\nparticular,wefoundoutinourexperimentsthatgivenadi-\n1\nNotethatwedonotassumethedataareindependent.\nmensionalityofthousands,typicalforvisualobjectrepre-\nsentation,adistancelearningmethodbasedonlearning\nM\nbecomesintractable.Toovercomethisproblem,weper-\nformeigenvaluedecompositionon\nM\n:\nM\n=\n\nT\n=\nWW\nT\n;\nW\n=\n\n1\n2\n;\n(5)\nwherethecolumnsof\nA\nareorthonormaleigenvectorsof\nM\nandthediagonalsof\n\narethecorrespondingeigen-\nvalues.Notethat\nW\nisorthogonal.Therefore,learninga\nfunction\nf\nisequivalenttolearninganorthogonalmatrix\nW\n=(\nw\n1\n;\n\n;\nw\nl\n;\n\n;\nw\nL\n)\nsuchthat\nW\n=argmin\nW\nr\n(\nW\n;\nO\n)\n;s:t:\nw\nT\ni\nw\nj\n=0\n;\n8\ni\n6\n=\nj\nr\n(\nW\n;\nO\n)=\nX\nO\ni\nlog(1+exp\n\njj\nW\nT\nx\np\ni\njj\n2\njj\nW\nT\nx\nn\ni\njj\n2\n\n)\n:\n(6)\n2.1.AnIterativeOptimisationAlgorithm\nItisimportanttopointoutthatouroptimisationcriterion\n(6)maynotbeaconvexoptimisationproblemagainstthe\northogonalconstraintduetotherelativecomparisonmod-\nelling.Itmeansthatderivinganglobalsolutionbydirectly\noptimising\nW\nisnotstraightforward.Inthisworkwefor-\nmulateaniterativeoptimisationalgorithmtolearnanopti-\nmal\nW\n,whichalsoaimstoseekalowrank(non-trivial)so-\nlutionautomatically.Thisiscriticalforreducingthemodel\ncomplexitythusovercomingtheovproblemgiven\nsparsedata.\nStartingfromanemptymatrix,afteriteration\n`\n,anew\nestimatedcolumn\nw\n`\nisaddedto\nW\n.Thealgorithmter-\nminatesafter\nL\niterationswhenastoppingcriterionismet.\nEachiterationconsistsoftwostepsasfollows:\nStep1.\nAssumethatafter\n`\niterations,atotalof\n`\northog-\nonalvectors\nw\n1\n;\n\n;\nw\n`\nhavebeenlearned.Tolearnthe\nnextorthogonalvector\nw\n`\n+1\n,let\na\n`\n+1\ni\n=exp\nf\nX\n`\nj\n=0\njj\nw\nT\nj\nx\np;j\ni\njj\n2\njj\nw\nT\nj\nx\nn;j\ni\njj\n2\ng\n;\n(7)\nwherewe\nw\n0\n=\n0\n,and\nx\np;`\ni\nand\nx\nn;`\ni\narethediffer-\nencevectorsatthe\n`\n-thiterationasfollows:\nx\ns;`\ni\n=\nx\ns;`\n\n1\ni\n\n~w\n`\n\n1\n~w\nT\n`\n\n1\nx\ns;`\n\n1\ni\n;\ns\n2f\np;n\ng\n;i\n=1\n;\n\n;\n\n\nO\n\n\n;`\n\n1\n;\nwhere\n~w\n`\n\n1\n=\nw\n`\n\n1\n=\njj\nw\n`\n\n1\njj\n:\n(8)\nNotethatwe\nx\ns;\n0\ni\n=\nx\ns\ni\n,\ns\n2f\np;n\ng\n,and\n~w\n0\n=\n0\n.\nStep2.\nObtain\nx\np;`\n+1\ni\n,\nx\nn;`\n+1\ni\nbyEqn.(8).Let\nO\n`\n+1\n=\nf\nO\n`\n+1\ni\n=(\nx\np;`\n+1\ni\n;\nx\nn;`\n+1\ni\n)\ng\n.Then,learnanewoptimalpro-\njection\nw\n`\n+1\non\nO\n`\n+1\nasfollows:\nw\n`\n+1\n=argmin\nw\nr\n`\n+1\n(\nw\n;\nO\n`\n+1\n)\n;\nwhere(9)\nr\n`\n+1\n(\nw\n;\nO\n`\n+1\n)\n=\nX\nO\n`\n+1\ni\nlog(1+\na\n`\n+1\ni\nexp\n\njj\nw\nT\nx\np;`\n+1\ni\njj\n2\njj\nw\nT\nx\nn;`\n+1\ni\njj\n2\n\n)\n:\nWeseekanoptimalsolutionbyagradientdescentmethod:\nw\n`\n+1\n \nw\n`\n+1\n\n\n\n@r\n`\n+1\n@\nw\n`\n+1\n;\n\n0\n;\n(10)\n651\n'b'@r\n`\n+1\n@\nw\n`\n+\n1\n=\nX\nO\n`\n+1\ni\n2\n\na\n`\n+1\ni\n\nexp\n\njj\nw\nT\n`\n+1\nx\np;`\n+1\ni\njj\n2\njj\nw\nT\n`\n+1\nx\nn;`\n+1\ni\njj\n2\n\n1+\na\n`\n+1\ni\n\nexp\n\njj\nw\nT\n`\n+1\nx\np;`\n+1\ni\njj\n2\njj\nw\nT\n`\n+1\nx\nn;`\n+1\ni\njj\n2\n\n\n\nx\np;`\n+1\ni\nx\np;`\n+1\ni\nT\n\nx\nn;`\n+1\ni\nx\nn;`\n+1\ni\nT\n\nw\n`\n+1\n:\nwhere\n\nisasteplengthautomaticallydeterminedateach\ngradientupdatestep.Accordingtothedescentdirectionin\nEqn.(10)theinitialvalueof\nw\n`\n+1\nforthegradientdescent\nmethodissetto\nw\n`\n+1\n=\nj\nO\n`\n+1\nj\n\n1\nX\nO\n`\n+1\ni\n(\nx\nn;`\n+1\ni\n\nx\np;`\n+1\ni\n)\n:\n(11)\nNotethattheupdateinEqn.(8)deductsinformation\nfromeachsample\nx\ns;`\n\n1\ni\naffectedby\nw\n`\n\n1\nas\nw\nT\n`\n\n1\nx\ns;`\ni\n=\n0\n,sothatthenextlearnedvector\nw\n`\nwillonlyquantifythe\npartofthedataleftfromthelaststep,i.e.\nx\ns;`\ni\n.Inaddition,\na\n`\n+1\ni\nindicatesthetrendsinthechangeofdistancemeasures\nfor\nx\np\ni\nand\nx\nn\ni\noverpreviousiterationsandserveas\napriori\nweightforlearning\nw\n`\n.\nTheiterationofthealgorithm(for\n`>\n1\n)isterminated\nwhenthefollowingcriterionismet:\nr\n`\n(\nw\n`\n;\nO\n`\n)\n\nr\n`\n+1\n(\nw\n`\n+1\n;\nO\n`\n+1\n)\n<":\n(12)\nwhere\n"\nisasmalltolerancevaluesetto\n10\n\n6\ninthiswork.\nThealgorithmissummarisedinAlgorithm1.\nAlgorithm1:\nLearningthePRDCmodel\nData\n:\nO\n=\nf\nO\ni\n=(\nx\np\ni\n;\nx\nn\ni\n)\ng\n;">\n0\nbegin\nw\n0\n \n0\n;\n~w\n0\n \n0\n;\nx\ns;\n0\ni\n \nx\ns\ni\n;s\n2f\np;n\ng\n,\nO\n0\n \nO\n;\n`\n \n0\n;\nwhile\n1\ndo\nCompute\na\n`\n+1\ni\nbyEqn.(7);\nCompute\nx\ns;`\n+1\ni\n;s\n2f\np;n\ng\nbyEqn.(8);\nO\n`\n+1\n f\nO\n`\n+1\ni\n=(\nx\np;`\n+1\ni\n;\nx\nn;`\n+1\ni\n)\ng\n;\nEstimate\nw\n`\n+1\nusingEqn.(9);\n~w\n`\n+1\n=\nw\n`\n+1\njj\nw\n`\n+1\njj\n;\nif\n(\n`>\n1)&(\nr\n`\n(\nw\n`\n;\nO\n`\n)\n\nr\n`\n+1\n(\nw\n`\n+1\n;\nO\n`\n+1\n)\n<"\n)\nthen\nbreak;\nend\n`\n \n`\n+1\n;\nend\nend\nOutput\n:\nW\n=\n\nw\n1\n;\n\n;\nw\n`\n\n2.2.TheoreticalValidation\nThefollowingtwotheoremsvalidatethattheproposed\niterativeoptimisationalgorithmlearnsasetoforthogo-\nnalprojections\nf\nw\n`\ng\nthatiterativelydecreasetheobjective\nfunctioninCriterion(6).\nTheorem1.\nThelearnedvectors\nw\n`\n;`\n=1\n;\n\n;L\n,are\northogonaltoeachother.\nProof.\nAssumethat\n`\n\n1\northogonalvectors\nf\nw\nj\ng\n`\n\n1\nj\n=1\nhave\nbeenlearned.Let\nw\n`\nbetheoptimalsolutionofCriterion\n(9)atthe\n`\niteration.First,weknowthat\nw\n`\nisintherange\nspace\n2\nof\nf\nx\np;`\ni\ng[f\nx\nn;`\ni\ng\naccordingtoEqns.(10)and(11),\ni.e.\nw\n`\n2\nspan\nf\nx\ns;`\ni\n;i\n=1\n;\n\n;\nj\nO\nj\n;s\n2f\np;n\ngg\n.Second,\naccordingtoEqn.(8),wehave\nw\nT\nj\nx\ns;j\n+1\ni\n=0\n;s\n2f\np;n\ng\n;j\n=1\n;\n\n;`\n\n1\nspan\nf\nx\ns;`\ni\n;i\n=1\n;\n\n;\nj\nO\nj\n;s\n2f\np;n\ngg\n\nspan\nf\nx\ns;`\n\n1\ni\n;i\n=1\n;\n\n;\nj\nO\nj\n;s\n2f\np;n\ngg\n\nspan\nf\nx\ns;\n0\ni\n;i\n=1\n;\n\n;\nj\nO\nj\n;s\n2f\np;n\ngg\n(13)\nHence,\nw\n`\nisorthogonalto\nw\nj\n;j\n=1\n;\n\n;`\n\n1\n:\nTheorem2.\nr\n(\nW\n`\n+1\n;\nO\n`\n+1\n)\n\nr\n(\nW\n`\n;\nO\n`\n)\n,where\nW\n`\n=\n(\nw\n1\n;\n\n;\nw\n`\n)\n;`\n\n1\n.Thatis,thealgorithmiterativelydecreases\ntheobjectivefunctionvalue.\nProof.\nLet\nw\n`\n+1\nbetheoptimalsolutionofEqn.(9).By\nTheorem1,itiseasytoprovethatforany\nj\n\n1\n,\nw\nT\nj\nx\ns;j\ni\n=\nw\nT\nj\nx\ns;\n0\ni\n=\nw\nT\nj\nx\ns\ni\n,\ns\n2f\np;n\ng\n.Hencewehave\nr\n`\n+1\n(\nw\n`\n+1\n;\nO\n`\n+1\n)\n=\nX\nO\n`\n+1\ni\nlog(1+\na\n`\n+1\ni\nexp\n\njj\nw\nT\n`\n+1\nx\np;`\n+1\ni\njj\n2\njj\nw\nT\n`\n+1\nx\nn;`\n+1\ni\njj\n2\n\n)\n=\nr\n(\nW\n`\n+1\n;\nO\n)\nAlso\nr\n`\n+1\n(\n0\n;\nO\n`\n+1\n)=\nr\n(\nW\n`\n;\nO\n)\n.Since\nw\n`\n+1\nisthemini-\nmalsolution,wehave\nr\n`\n+1\n(\nw\n`\n+1\n;\nO\n`\n+1\n)\n\nr\n`\n+1\n(\n0\n;\nO\n`\n+1\n)\n,\nandtherefore\nr\n(\nW\n`\n+1\n;\nO\n)\n\nr\n(\nW\n`\n;\nO\n)\n.\nSinceCriterion(9)maynotbeconvex,alocaloptimum\ncouldbeobtainedineachiterationofouralgorithm.How-\never,evenifthecomputationwastrappedinalocalmini-\nmumofEqn.(9)atthe\n`\n+1\niteration,Theorem2isstill\nvalidif\nr\n`\n+1\n(\nw\n`\n+1\n;\nO\n`\n+1\n)\n\nr\n`\n(\nw\n`\n;\nO\n`\n)\n,otherwisethealgo-\nrithmwillbeterminatedbythestoppingcriterion(12).To\nalleviatethelocaloptimumproblemateachiteration,mul-\ntipleinitialisationscouldalsobedeployedinpractice.\n2.3.LearninginanAbsoluteDataDifferenceSpace\nTocomputethedatadifferencevector\nx\nin\nEqn.(1),mostexistingdistancelearningmethodsusethe\nfollowingentry-wisedifferencefunction\nx\n=\nd\n(\nz\n;\nz\n0\n)=\nz\n\nz\n0\n(14)\ntolearn\nM\n=\nWW\nT\ninthenormaldatadifferencespace\ndenotedby\nDZ\n=\n\nx\nij\n=\nz\ni\n\nz\nj\n\n\nz\ni\n;\nz\nj\n2Z\n\n.Thelearned\ndistancefunctionisthuswrittenas:\nf\n(\nx\nij\n)=(\nz\ni\n\nz\nj\n)\nT\nM\n(\nz\ni\n\nz\nj\n)=\njj\nW\nT\nx\nij\njj\n2\n:\n(15)\nInthiswork,wecomputethedifferencevectorbythe\nfollowingentry-wiseabsolutedifferencefunction:\nx\n=\nd\n(\nz\n;\nz\n0\n)=\n\n\nz\n\nz\n0\n\n\n;\nx\n(\nk\n)=\n\n\nz\n(\nk\n)\n\nz\n0\n(\nk\n)\n\n\n:\n(16)\n2\nItcanbeexploredbyLagrangianequationforEqn.(9)foranon-zero\nw\n`\n.\n652\n'b"where\nz\n(\nk\n)\nisthe\nk\n-thelementofthesamplefeaturevector.\nM\nisthuslearnedinanabsolutedatadifferencespace,de-\nnotedby\n\n\nDZ\n\n\n=\n\nj\nx\nij\nj\n=\nj\nz\ni\n\nz\nj\nj\n\n\nz\ni\n;\nz\nj\n2Z\n\n,andour\ndistancefunctionbecomes:\nf\n(\nj\nx\nij\nj\n)=\nj\nz\ni\n\nz\nj\nj\nT\nM\nj\nz\ni\n\nz\nj\nj\n=\njj\nW\nT\nj\nx\nij\njjj\n2\n:\n(17)\nWenowexplainwhylearninginanabsolutedatadif-\nferencespaceismoresuitabletoourrelativecomparison\nmodel.First,wenotethat:\nj\nz\ni\n(\nk\n)\n\nz\nj\n(\nk\n)\njj\n(\nz\ni\n(\nk\n)\n\nz\nj\n0\n(\nk\n)\nj\nj\n(\nz\ni\n(\nk\n)\n\nz\nj\n(\nk\n))\n\n(\nz\ni\n(\nk\n)\n\nz\nj\n0\n(\nk\n))\nj\n;\n(18)\nhencewehave\nj\nx\nij\njj\nx\nij\n0\nj\n:\nj\nx\nij\n\nx\nij\n0\nj\n,where`\n:\n\n'is\nanentry-wise`\n\n'.As\nj\nx\nij\nj\n;\nj\nx\nij\n0\nj\n0\n,wethuscanprove\n\n\n\n\nj\nx\nij\njj\nx\nij\n0\nj\n\n\n\n\n\n\n\n\n\nx\nij\n\nx\nij\n0\n\n\n\n\n:\n(19)\nThissuggeststhatthevariationof\nj\nx\nij\nj\ngiventhesamesam-\nplespace\nZ\nisalwayslessthanthatof\nx\nij\n.S,if\nz\ni\n;\nz\nj\n;\nz\nj\n0\narefromthesameclass,theintra-classvariation\nissmallerin\njDZj\nthanin\nDZ\n.Ontheotherhand,if\nz\nj\nand\nz\nj\n0\nbelongtoadifferentclassas\nz\ni\n,thevariationof\ninter-classdifferencesisalsomorecompactintheabsolute\ndatadifferencespace.Sincethevariationsofbothrelevant\nandirrelevantsampledifferences\nx\np\nand\nx\nn\naresmaller,the\nlearneddistancefunctionusingEqn.(6)wouldyieldmore\nconsistentdistancecomparisonresultstherefore\nourPRDCmodel.Specially,forthesamema-\ntrix\nM\n,theCauchyinequalitysuggests\nupper\n(\n\n\n\n\nW\nT\n(\nj\nx\nij\n\nx\nij\n0\nj\n)\n\n\n\n\n)\n\nupper\n(\n\n\n\n\nW\nT\n(\nx\nij\n\nx\nij\n0\n)\n\n\n\n\n)\n;\nwhere\nupper\n(\n\n)\nistheupperboundoperation.Thisindicates\nthatinthelatentsubspaceinducedby\nW\n,themaximum\nvariationof\nj\nx\nij\nj\nT\nM\nj\nx\nij\nj\nislowerthanthatof\nx\nT\nij\nMx\nij\n.\nWeshownotableoflearningPRDCinanabsolute\ndatadifferencespaceinourexperiments.\n2.4.FeatureRepresentation\nOurPRDCmodelcanbeappliedregardlessofthechoice\nofappearancefeaturerepresentationofpeople.However,\ninordertofromdifferentandcomplementaryinfor-\nmationcapturedbydifferentfeatures,westartwithamix-\ntureofcolourandtexturehistogramfeaturessimilartothose\nusedin[7]andletourmodelautomaticallydiscoveranop-\ntimalfeaturedistance.,wedividedaperson\nimageintosixhorizontalstripes.Foreachstripe,theRGB,\nYCbCr,HSVcolorfeaturesandtwotypesoftexturefea-\nturesextractedbySchmidandGaborwerecomputed\nandrepresentedashistograms.Intotal29featurechan-\nnelswereconstructedforeachstripeandeachfeaturechan-\nnelwasrepresentedbya16dimensionalhistogramvector.\nEachpersonimagewasthusrepresentedbyafeaturevector\nina2784dimensionalfeaturespace\nZ\n.Sincethefeatures\ncomputedforthisrepresentationincludelow-levelfeatures\nwidelyusedbyexistingpersonre-identitechniques,\nthisrepresentationisconsideredasgenericandrepresenta-\ntive.\n3.Experiments\nDatasetsandsettings.\nTwopublicallyavailableperson\ndatasets,i-LIDSMultiple-CameraTrack-\ningScenario(MCTS)[18,13]andVIPeR[6],wereused\nforevaluation.Inthei-LIDSMCTSdataset,whichwas\ncapturedindooratabusyairportarrivalhall,thereare119\npeoplewithatotal476personimagescapturedbymultiple\nnon-overlappingcameraswithanaverageof4imagesfor\neachperson.Manyoftheseimagesundergolargeillumina-\ntionchangeandaresubjecttoocclusions(seeFig.4).The\nVIPeRdatasetisthelargestpersondataset\navailableconsistingof632peoplecapturedoutdoorwith\ntwoimagesforeachperson.Viewpointchangeisthemost\ncauseofappearancechangewithmostofthe\nmatchedimagepairscontainingonefront/backviewand\noneside-view(seeFig.5).\nInourexperiments,foreachdataset,werandomlyse-\nlectedallimagesof\np\npeople(classes)tosetupthetest\nset,andtherestwereusedfortraining.Eachtestsetwas\ncomposedofagallerysetandaprobeset.Thegalleryset\nconsistedofoneimageforeachperson,andtheremaining\nimageswereusedastheprobeset.Thisprocedurewasre-\npeated10times.Duringtraining,apairofimagesofeach\npersonformedarelevantpair,andoneimageofhim/her\nandoneofanotherpersoninthetrainingsetformedare-\nlatedirrelevantpair,andtogethertheyformthepairwiseset\nO\ninSec.2.\nForevaluation,weusetheaveragecumulativematch\ncharacteristic(CMC)curves[6]over10trialstoshowthe\nrankedmatchingrates.Arank\nr\nmatchingrateindicatesthe\npercentageoftheprobeimageswithcorrectmatchesfound\ninthetop\nr\nranksagainstthe\np\ngalleryimages.Rank1\nmatchingrateisthusthecorrectmatching/recognitionrate.\nNotethatinpractice,althoughahighrank\n1\nmatchingrateis\ncritical,thetop\nr\nrankedmatchingratewithasmall\nr\nvalue\nisalsoimportantbecausethetopmatchedimageswillnor-\nmallybevbyahumanoperator[6].\nPRDCvs.Non-LearningbasedDistances.\nWecom-\nparedourPRDCwithnon-learningbased\nl\n1\n-normdistance\nandBhattacharyyadistancewhichwereusedbymostexist-\ningpersonwork.Ourresults(Figs.2and3,\nTables1and2)showclearlythatwiththeproposedPRDC,\nthematchingperformanceforbothdatasetsisimprovedno-\ntably,moresowhenthenumberofpeopleinthetestpoolin-\ncreases(i.e.trainingsetsizedecreases).Theimprovement\nisparticularlydramaticontheVIPeRdataset.Inparticu-\nlar,Table2showsthata4-foldincreaseincorrectmatching\nrate(\nr\n=1\n)isobtainedagainstboth\nl\n1\n-normandBhat-\ntacharyyadistanceswhen\np\n=316\n.Theresultsvalidatethe\nimportanceofperformingdistancelearning.Examplesof\nmatchingpeopleusingPRDCforbothdatasetsareshown\ninFigs.4and5respectively.\n653\n"b"(a)\np\n=50\n(b)\np\n=80\nFigure2.PerformancecomparisonusingCMCcurvesoni-LIDSMCTSdataset.\nMethods\np\n=30\np\n=50\np\n=80\nr\n=1\nr\n=5\nr\n=10\nr\n=20\nr\n=1\nr\n=5\nr\n=10\nr\n=20\nr\n=1\nr\n=5\nr\n=10\nr\n=20\nPRDC\n44.05\n72.74\n84.69\n96.29\n37.83\n63.70\n75.09\n88.35\n32.60\n54.55\n65.89\n78.30\nAdaboost\n35.58\n66.43\n79.88\n93.22\n29.62\n55.15\n68.14\n82.35\n22.79\n44.41\n57.16\n70.55\nLMNN\n33.68\n63.88\n78.17\n92.64\n27.97\n53.75\n66.14\n82.33\n23.70\n45.42\n57.32\n70.92\nITM\n36.37\n67.99\n83.11\n95.55\n28.96\n53.99\n70.50\n86.67\n21.67\n41.80\n55.12\n71.31\nMCC\n40.24\n73.64\n85.87\n96.65\n31.28\n59.30\n75.62\n88.34\n12.00\n33.66\n47.96\n67.00\nXing's\n31.80\n62.62\n77.29\n90.63\n27.04\n52.28\n65.35\n80.70\n23.18\n45.24\n56.90\n70.46\nL1-norm\n35.31\n64.62\n77.37\n91.35\n30.72\n54.95\n67.99\n82.98\n26.73\n49.04\n60.32\n72.07\nBhat.\n31.77\n61.43\n74.19\n89.53\n28.42\n51.06\n64.32\n78.77\n24.76\n45.35\n56.12\n69.31\nTable1.Toprankedmatchingrate(%)oni-LIDSMCTS.\np\nissizeofthegalleryset(larger\np\nmeanssmallertrainingset)and\nr\nistherank.\nPRDCvs.AlternativeLearningMethods.\nWealsocom-\nparedPRDCwith5alternativediscriminantlearningbased\napproaches.Theseinclude4populardistancelearning\nmethods,namelyXing'smethod[16],LMNN[15],ITM\n[1]andMCC[5],andamethoddesignedfor\npersonre-idebasedonAdaboost[7].Among\nthe4distancelearningmethods,onlyLMNNexploitsrel-\nativedistancecomparison.ButasmentionedinSec.1,it\nisusedasanoptimisationconstraintratherthanthemain\nobjectivefunctionwhichisalsonotformulatedprobabilis-\ntically.MCCissimilartoPRDCinthataprobabilistic\nmodelisusedbutitisnotarelativedistancecomparison\nbasedmethod.NotethatsinceMCCneedstoselectthebest\ndimensionformatching,weperformedcross-validationby\nselectingitsvaluein\nf\n[1:1:10]\n;d\ng\n,where\nd\nisthemaxi-\nmumrankMCCcanlearn.Amongthe5,theonlymethod\nthatlearnsinanabsolutedatadifferentspaceisAdaboost.\nOurresults(Figs.2and3,Tables1and2)showclearly\nthatourmodelyieldsthebestrank1matchingrateandover-\nallmuchsuperiorperformancecomparedtothecompared\nmodels.TheadvantageofPRDCisparticularlyapparent\nwhenatrainingsetissmall(learningbecomesmoredif-\nandatestsetislargeindicatedbythevalueof\np\n(matchingbecomesharder).Table2showsthatonVIPeR\nwhen100peopleareusedforlearningand532peoplefor\ntesting(\np\n=532\n),thecorrectmatchingrateforPRDC(and\nMCC)isalmostmorethandoubledagainstanyalternative\ndistancelearningmethods.Particularly,tingfrombe-\ningaprobabilisticmodel,MCCgivesthemostcomparable\nresultstoPRDCwhenthetrainingsetislarge.However,its\nperformancedegradesdramaticallywhenthesizeoftrain-\ningdatadecreases(seecolumnsunder\np\n=80\ninTable1\nand\np\n=532\ninTable2).Thissuggeststhatoverto\nlimitedtrainingdataisthemainreasonfortheinferiorper-\nformanceofthecomparedalternativelearningapproaches.\nPRDCvs.RankSVM.\nDifferentfromPRDC,RankSVM\nhasafreeparameterwhichdeterminestherelativeweights\nbetweenthemarginfunctionandtherankingerrorfunction\n[11].Inourexperiment,wecross-validatedtheparameter\nin\nf\n0.0001,0.005,0.001,0.05,0.1,0.5,1,10,100,1000\ng\n.\nAsshowninTables3and4,thetwomethodsallperform\nverywellagainstothercomparedalgorithmsandourPRDC\nyieldsoverallbetterperformanceespeciallyatlowerrank\nmatchingrateandgivenlesstrainingdata.Thebetterper-\nformanceofPRDCisduetotheprobabilisticmodellingand\nasecond-orderratherthanfeatureselection.Itis\nalsonotedthattuningthefreeparameterforRankSVMis\nnotatrivialtaskandtheperformancecanbesensitivetothe\ntuningespeciallygivensparsedata,whilePRDCdoesnot\nhavethisproblem.InadditionRankSVMiscomputation-\nallymoreexpensive(seedetailslater).\nEffectoflearninginanAbsoluteDataDifferenceSpace.\nWehaveshowninSec.2.3thatintheoryourrelativedis-\ntancecomparisonlearningmethodcanfromlearn-\ninginanabsolutedatadifferencespace.Tovalidate\nthisexperimentally,wecomparePRDCwithPRDC\nraw\nwhichlearnsinthenormaldatadifferencespace\nDZ\n(see\nSec.2.3).TheresultinTable5indicatesthatlearningin\nanabsolutedatadifferencespacedoesimprovethematch-\ningperformance.Notethatmostexistingdistancelearning\nmodelsarebasedonlearninginthenormaldatadifference\nspace\nDZ\n.Itispossibletoreformulatesomeofthemin\n654\n"b"(a)\np\n=316\n(b)\np\n=532\nFigure3.PerformancecomparisonusingCMCcurvesonVIPeRdataset.\nMethods\np\n=316\np\n=432\np\n=532\nr\n=1\nr\n=5\nr\n=10\nr\n=20\nr\n=1\nr\n=5\nr\n=10\nr\n=20\nr\n=1\nr\n=5\nr\n=10\nr\n=20\nPRDC\n15.66\n38.42\n53.86\n70.09\n12.64\n31.97\n44.28\n59.95\n9.12\n24.19\n34.40\n48.55\nAdaboost\n8.16\n24.15\n36.58\n52.12\n6.83\n19.81\n29.75\n43.06\n4.19\n12.95\n20.21\n30.73\nLMNN\n6.23\n19.65\n32.63\n52.25\n5.14\n13.13\n20.30\n33.91\n4.04\n9.68\n14.19\n21.18\nITM\n11.61\n31.39\n45.76\n63.86\n8.38\n24.54\n36.81\n52.29\n4.19\n11.11\n17.22\n24.59\nMCC\n15.19\n41.77\n57.59\n73.39\n11.30\n32.43\n47.29\n62.85\n5.00\n16.32\n25.92\n39.64\nXing's\n4.65\n11.96\n16.61\n24.37\n4.12\n10.02\n14.70\n20.65\n3.63\n8.76\n12.14\n18.16\nL1-norm\n4.18\n11.65\n16.52\n22.37\n3.80\n9.81\n13.94\n19.44\n3.55\n8.29\n12.27\n17.59\nBhat.\n4.65\n11.49\n16.55\n23.83\n4.19\n10.35\n14.19\n20.19\n3.82\n9.08\n12.42\n17.88\nTable2.Toprankedmatchingrate(%)onVIPeR.\np\nisthenumberofclassesinthetestingset;\nr\nistherank.\nRank\nPRDC\nRankSVM\nr\n=1\nr\n=5\nr\n=10\nr\n=20\nr\n=1\nr\n=5\nr\n=10\nr\n=20\np\n=30\n44.05\n72.74\n84.69\n96.29\n42.96\n71.30\n85.15\n96.99\np\n=50\n37.83\n63.70\n75.09\n88.35\n37.41\n63.02\n73.50\n88.30\np\n=80\n32.60\n54.55\n65.89\n78.30\n31.73\n55.69\n67.02\n77.78\nTable3.PRDCvs.RankSVM(%)oni-LIDS.\nRank\nPRDC\nRankSVM\nr\n=1\nr\n=5\nr\n=10\nr\n=20\nr\n=1\nr\n=5\nr\n=10\nr\n=20\np\n=316\n15.66\n38.42\n53.86\n70.09\n16.27\n38.23\n53.73\n69.87\np\n=432\n12.64\n31.97\n44.28\n59.95\n10.63\n29.70\n42.31\n58.26\np\n=532\n9.12\n24.19\n34.40\n48.55\n8.87\n22.88\n32.69\n45.98\nTable4.PRDCvs.RankSVM(%)onVIPeR.\nMethods\ni-LIDS,(\np\n=50\n)\nVIPeR(\np\n=316\n)\nr\n=1\nr\n=5\nr\n=10\nr\n=20\nr\n=1\nr\n=5\nr\n=10\nr\n=20\nPRDC\n37.83\n63.70\n75.09\n88.35\n15.66\n38.42\n53.86\n70.09\nPRDC\nraw\n19.92\n50.19\n68.29\n86.40\n12.28\n37.28\n53.83\n71.77\nITM\nabs\n29.16\n53.01\n66.75\n82.53\n5.44\n14.43\n22.53\n33.35\nMCC\nabs\n5.59\n23.01\n43.59\n70.47\n1.20\n3.51\n5.6\n9.68\nTable5.Effectoflearninginanabsolutedatadifferencespace.\nMethods\ni-LIDSMCTS\nVIPeR\np\n=30\np\n=50\np\n=80\np\n=316\np\n=432\np\n=532\nrank\n(\nW\n)\n3.2\n2.4\n2.3\n2.9\n3.2\n3.7\nTable6.AverageRankof\nW\nLearnedbyPRDC.\nordertolearninanabsolutedatadifferencespace.InTa-\nble5weshowthatwhenITMandMCCarelearnedinthe\nabsolutedatadifferencespace\njDZj\n,termedasITM\nabs\nand\nMCC\nabs\nrespectively,theirperformancesbecomeworseas\ncomparedtotheirresultsinTables1and2.Thisindicates\nthattheabsolutedifferentspaceismoresuitableforourrel-\nativecomparisondistancelearning.\nComputationalcost.\nThoughPRDCisiterative,ithasrel-\nativelylowcostinpractice.Inourexperiments,forVIPeR\nwith\np\n=316\n,ittookaround15minutesforanInteldual-\ncore2.93GHzCPUand48GBRAMtolearnPRDCforeach\ntrial.WeobservedthatthelowcostofPRDCispartially\nduetoitsabilitytoseekasuitablelowrankof\nW\n(i.e.con-\nvergewithinveryfewiterations)asshowninTable6.For\ncomparison,amongtheothercomparedmethods,Adaboost\nisthemostcostlyandtookover7hoursforeachtrial.For\nthe4compareddistancelearningmethods,PCAdimension-\nalityreductionmustbeperformedotherwisetheybecomes\nintractablegiventhehighdimensionalfeaturespace.For\ntheRankSVMmethod,eachtrialtookaround2.5hoursdue\ntoparametertuning.\n4.Conclusion\nWehaveproposedanewapproachforpersonre-\nbasedonprobabilisticrelativedistancecom-\nparisonwhichaimstolearnansuitableoptimaldistance\nmeasuregivenlargeintraandinter-classappearancevaria-\ntionsandsparsedata.Ourexperimentsdemonstratethat1)\nbyformulatingpersonasadistancelearn-\ningproblem,clearimprovementinmatchingperformance\ncanbeobtainedandtheimprovementismore\nwhentrainingsamplesizeissmall,and(2)ourPRDCout-\nperformsnotonlyexistingdistancelearningmethodsbut\nalsoalternativelearningmethodsbasedonboostingand\nlearningtorank.\nAcknowledgements\nThisresearchwaspartiallyfundedbytheEUFP7project\nSAMURAIwithgrantno.217899.Dr.Wei-ShiZhengwas\nalsoadditionallysupportedbythe985projectinSunYat-\nsenUniversitywithgrantno.35000-3181305.\nReferences\n[1]\nJ.Davis,B.Kulis,P.Jain,S.Sra,andI.Dhillon.Information-\ntheoreticmetriclearning.In\nICML\n,2007.\n655\n"b'Figure4.ExamplesofPersononi-LIDSMCTSusingPRDC.Ineachrow,theleft-mostimageistheprobe,imagesinthe\nmiddlearethetop20matchedgalleryimageswithahighlightedredboxforthecorrectlymatched,andtheright-mostshowsatruematch\nFigure5.ExamplesofPersonnonVIPeRusingPRDC\n[2]\nP.Dollar,Z.Tu,H.Tao,andS.Belongie.Featureminingfor\nimageIn\nCVPR\n,2007.\n[3]\nM.Farenzena,L.Bazzani,A.Perina,M.Cristani,and\nV.Murino.Personbysymmetry-drivenac-\ncumulationoflocalfeatures.In\nCVPR\n,2010.\n[4]\nN.Gheissari,T.Sebastian,andR.Hartley.Person\ncationusingspatiotemporalappearance.In\nCVPR\n,2006.\n[5]\nA.GlobersonandS.Roweis.Metriclearningbycollapsing\nclasses.In\nNIPS\n,2005.\n[6]\nD.Gray,S.Brennan,andH.Tao.Evaluatingappearance\nmodelsforrecognition,reacquisition,andtracking.In\nIEEE\nInternationalworkshoponperformanceevaluationoftrack-\ningandsurveillance\n,2007.\n[7]\nD.GrayandH.Tao.Viewpointinvariantpedestrianrecogni-\ntionwithanensembleoflocalizedfeatures.In\nECCV\n,2008.\n[8]\nW.Hu,M.Hu,X.Zhou,J.Lou,T.Tan,andS.Maybank.\nPrincipalaxis-basedcorrespondencebetweenmultiplecam-\nerasforpeopletracking.\nPAMI\n,28(4):663671,2006.\n[9]\nJ.Lee,R.Jin,andA.Jain.Rank-baseddistancemetriclearn-\ning:Anapplicationtoimageretrieval.In\nCVPR\n,2008.\n[10]\nU.Park,A.Jain,I.Kitahara,K.Kogure,andN.Hagita.Vise:\nVisualsearchengineusingmultiplenetworkedcameras.In\nICPR\n,2006.\n[11]\nB.Prosser,W.-S.Zheng,S.Gong,andT.Xiang.Personre-\nbysupportvectorranking.In\nBMVC\n,2010.\n[12]\nM.SchultzandT.Joachims.Learningadistancemetricfrom\nrelativecomparisons.In\nNIPS\n,2004.\n[13]\nUK.HomeOfi-LIDSmultiplecameratrackingscenario\n2008.\n[14]\nX.Wang,G.Doretto,T.Sebastian,J.Rittscher,andP.Tu.\nShapeandappearancecontextmodeling.In\nICCV\n,2007.\n[15]\nK.Weinberger,J.Blitzer,andL.Saul.Distancemetriclearn-\ningforlargemarginnearestneighborIn\nNIPS\n,\n2006.\n[16]\nE.Xing,A.Ng,M.Jordan,andS.Russell.Distance\nmetriclearning,withapplicationtoclusteringwithside-\ninformation.In\nNIPS\n,2003.\n[17]\nL.Yang,R.Jin,R.Sukthankar,andY.Liu.Anef\nalgorithmforlocaldistancemetriclearning.In\nAAAI\n,2006.\n[18]\nW.-S.Zheng,S.Gong,andT.Xiang.Associatinggroupsof\npeople.In\nBMVC\n,2009.\n656\n'