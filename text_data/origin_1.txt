b'Two-DimensionalPCA:\nANewApproachtoAppearance-Based\nFaceRepresentationandRecognition\nJianYang,DavidZhang,\nSeniorMember\n,IEEE,AlejandroF.Frangi,andJing-yuYang\nAbstract\nInthispaper,anewtechniquecoinedtwo-dimensionalprincipal\ncomponentanalysis(2DPCA)isdevelopedforimagerepresentation.Asopposed\n\ntoPCA,2DPCAisbasedon2Dimagematricesratherthan1Dvectorssotheimage\n\nmatrixdoesnotneedtobetransformedintoavectorpriortofeatureextraction.\n\nInstead,an\nimagecovariancematrix\nisconstructeddirectlyusingtheoriginalimage\nmatrices,anditseigenvectorsarederivedforimagefeatureextraction.Totest\n\n2DPCAandevaluateitsperformance,aseriesofexperimentswereperformedon\n\nthreefaceimagedatabases:ORL,AR,andYalefacedatabases.Therecognition\n\nrateacrossalltrialswashigherusing2DPCAthanPCA.Theexperimentalresults\n\nalsoindicatedthattheextractionofimagefeaturesiscomputationallymoreefficient\n\nusing2DPCAthanPCA.\nIndexTerms\nPrincipalComponentAnalysis(PCA),Eigenfaces,feature\nextraction,imagerepresentation,facerecognition.\n1INTRODUCTION\nPRINCIPAL\ncomponentanalysis(PCA),alsoknownasKarhunen-\nLoeveexpansion,isaclassica\nlfeatureextractionanddata\nrepresentationtechniquewidelyusedintheareasofpattern\nrecognitionandcomputervision.SirovichandKirby[1],[2]first\nusedPCAtoefficientlyrepresentpicturesofhumanfaces.They\n\narguedthatanyfaceimagecouldbereconstructedapproximately\n\nasaweightedsumofasmallcollectionofimagesthatdefinea\nfacialbasis(eigenimages),andameanimageoftheface.Within\nthiscontext,TurkandPentland[3]presentedthewell-known\n\nEigenfacesmethodforfacerecognitionin1991.Sincethen,PCA\nhasbeenwidelyinvestigatedandhasbecomeoneofthemost\nsuccessfulapproachesinfacerecognition[4],[5],[6],[7].Penev\n\nandSirovich[8]discussedtheproblemofthedimensionalityofthe\nfacespacewheneigenfacesareusedforrepresentation.Zhaoand\nYang[9]triedtoaccountforthearbitraryeffectsofilluminationin\n\nPCA-basedvisionsystemsbygeneratingananalyticallyclosed-\nformformulaofthecovariancematrixforthecasewithaspecial\nlightingconditionandthengeneralizingtoanarbitraryillumina-\n\ntionviaanilluminationequation\n.However,Wiskottetal.[10]\npointedoutthatPCAcouldnotcaptureeventhesimplest\ninvarianceunlessthisinformationisexplicitlyprovidedinthe\ntrainingdata.Theyproposedatechniqueknownaselasticbunch\ngraphmatchingtoovercometheweaknessesofPCA.\nRecently,twoPCA-relatedmethods,\nindependentcomponent\nanalysis(ICA)and\nkernelprincipalcomponentanalysis\n(KernelPCA)\nhavebeenofwideconcern.Bartlettetal.[11]andDraperetal.[12]\nproposedusingICAforfacerepresentationandfoundthatitwas\nbetterthanPCAwhencosineswereusedasthesimilaritymeasure\n(however,theirperformancewasnotsignificantlydifferentifthe\nEuclideandistanceisused).Yang[14]usedKernelPCAforface\nfeatureextractionandrecognitionandshowedthattheKernel\n\nEigenfacesmethodoutperformstheclassicalEigenfacesmethod.\nHowever,ICAandKernelPCAarebothcomputationallymore\nexpensivethanPCA.Theexperimentalresultsin[14]showedthe\nratioofthecomputationtimerequiredbyICA,KernelPCA,andPCA\nis,onaverage,8.7:3.2:1.0.\nInthePCA-basedfacerecognitiontechnique,the2Dfaceimage\nmatricesmustbepreviouslytransformedinto1Dimagevectors.\nTheresultingimagevectorsoffacesusuallyleadtoahigh-\ndimensionalimagevectorspace,whereitisdifficulttoevaluatethe\ncovariancematrixaccuratelyduetoitslargesizeandtherelatively\n\nsmallnumberoftrainingsamples.Fortunately,theeigenvectors\n(eigenfaces)canbecalculatedefficientlyusingtheSVDtechniques\n[1],[2]andtheprocessofgeneratingthecovariancematrixis\nactuallyavoided.However,thisdoesnotimplythattheeigenvec-\ntorscanbeevaluatedaccuratelyinthiswaysincetheeigenvectors\n\narestatisticallydeterminedbythecovariancematrix,nomatter\nwhatmethodisadoptedforobtainingthem.\nInthispaper,astraightforwardimageprojectiontechnique,\ncalledtwo-dimensionalprincipalcomponentanalysis\n(2DPCA),is\ndevelopedforimagefeatureextraction.Asopposedtoconven-\n\ntionalPCA,2DPCAisbasedon2Dmatricesratherthan1Dvectors.\nThatis,theimagematrixdoesnotneedtobepreviously\ntransformedintoavector.Instead,an\nimagecovariancematrix\ncanbeconstructeddirectlyusingtheoriginalimagematrices.In\ncontrasttothecovariancematrixofPCA,thesizeofthe\nimagecovariancematrix\nusing2DPCAismuchsmaller.Asaresult,\n2DPCAhastwoimportantadvantagesoverPCA.First,itiseasier\n\ntoevaluatethecovariancematrixaccurately.Second,lesstimeis\nrequiredtodeterminethecorrespondingeigenvectors.\nTheremainderofthispaperisorganizedasfollows:InSection2,\ntheideaoftheproposed2DPCAmethodanditsalgorithmare\ndescribed.Theimagereconstructionmethodusing2DPCAis\ndevelopedinSection3.InSection4,experimentalresultsare\npresentedfortheORL,theAR,andtheYalefaceimagedatabasesto\ndemonstratetheeffectivenessandrobustnessof2DPCA.Finally,\nconclusionsarepresentedinSection5.\n2TWO-DIMENSIONALPRINCIPALCOMPONENTANALYSIS2.1IdeaandAlgorithm\nLetXdenotean\nn-dimensionalunitarycolumnvector.Ourideais\ntoprojectimage\nA,an\nmnrandommatrix,onto\nXbythe\nfollowinglineartransformation[15],[19]:\nYAX:1Thus,weobtainan\nm-dimensionalprojectedvector\nY,whichis\ncalledtheprojectedfeaturevectorofimage\nA.Howdowe\ndetermineagoodprojectionvector\nX?Infact,thetotalscatterof\ntheprojectedsamplescanbeintroducedtomeasurethedis-\n\ncriminatorypoweroftheprojectionvector\nX.Thetotalscatterof\ntheprojectedsamplescanbecharacterizedbythetraceofthe\n\ncovariancematrixoftheprojectedfeaturevectors.Fromthispoint\n\nofview,weadoptthefollowingcriterion:\nJXtrSx;2IEEETRANSACTIONSONPATTERNANALYSISANDMACHINEINTELLIGENCE,VOL.26,NO.1,JANUARY2004131\n.J.YangiswiththeDepartmentofComputing,HongKongPolytechnic\nUniversity,Kowloon,HongKong,ComputerVisionGroup,Aragon\n\nInstituteofEngineeringResearch,UniversidaddeZaragoza,E-50018\n\nZaragoza,Spain,andtheDepartmentofComputerScience,Nanjing\nUniversityofScienceandTechnology,Nanjing210094,P.R.China.\nE-mail:jyang@unizar.es.\n.D.ZhangiswiththeDepartmentofComputing,HongKongPolytechnic\nUniversity,Kowloon,HongKong.E-mail:csdzhang@comp.polyu.edu.hk.\n.A.F.FrangiiswiththeComputerVisionGroup,AragonInstituteof\nEngineeringResearch,UniversidaddeZaragoza,E-50018Zaragoza,\n\nSpain.E-mail:afrangi@unizar.es.\n.J.-y.YangiswiththeDepartmentofComputerScience,Nanjing\nUniversityofScienceandTechnology,Nanjing210094,P.R.China.\n\nE-mail:yangjy@mail.njust.edu.cn.\nManuscriptreceived10Sept.2002;revised4Mar.2003;accepted17Mar.\n2003.RecommendedforacceptancebyY.Amit.\n\nForinformationonobtainingreprintsofthisarticle,pleasesende-mailto:\n\ntpami@computer.org,andreferenceIEEECSLogNumber117299.\n0162-8828/04/$17.002004IEEEPublishedbytheIEEEComputerSociety\n'b'whereSxdenotesthecovariancematrixoftheprojectedfeature\nvectorsofthetrainingsamplesand\ntrSxdenotesthetraceof\nSx.Thephysicalsignificanceofmaximizingthecriterionin(2)istofind\naprojectiondirection\nX,ontowhichallsamplesareprojected,so\nthatthetotalscatteroftheresultingprojectedsamplesismaximized.\n\nThecovariancematrix\nSxcanbedenotedby\nSxEYEYYEYTEAXEAXAXEAXTEAEAXAEAXT:So,trSxXTEAEATAEAX:3Letusdefinethefollowingmatrix\nGtEAEATAEA:4Thematrix\nGtiscalledthe\nimagecovariance\n(scatter)matrix.Itis\neasytoverifythat\nGtisan\nnnnonnegativedefinitematrix\nfromitsdefinition.Wecanevaluate\nGtdirectlyusingthetraining\nimagesamples.Supposethatthereare\nMtrainingimagesamples\nintotal,the\njthtrainingimageisdenotedbyan\nmnmatrixAjj1;2;\n;M,andtheaverageimageofalltrainingsamples\nisdenotedby\nAA.Then,\nGtcanbeevaluatedby\nGt1MXMj1AjAATAjAA:5Alternatively,thecriterionin(2)canbeexpressedby\nJXXTGtX;6whereXisaunitarycolumnvector.Thiscriterioniscalledthe\ngeneralizedtotalscattercriterion.\nTheunitaryvector\nXthatmaximizes\nthecriterioniscalledtheoptimalprojectionaxis.Intuitively,this\nmeansthatthetotalscatteroftheprojectedsamplesismaximized\naftertheprojectionofanimagematrixonto\nX.Theoptimalprojectionaxis\nXoptistheunitaryvectorthat\nmaximizesJX,i.e.,theeigenvectorof\nGtcorrespondingtothe\nlargesteigenvalue[19].Ingeneral,itisnotenoughtohaveonly\n\noneoptimalprojectionaxis.Weusuallyneedtoselectasetof\nprojectionaxes,\nX1;\n;Xd,subjecttotheorthonormalconstraints\nandmaximizingthecriterion\nJX,thatis,\nfX1;\n;Xdgargmax\nJXXTiXj0;i6\nj;i;j\n1;\n;d:\n7Infact,theoptimalprojectionaxes,\nX1;;Xd,aretheorthonormal\neigenvectorsof\nGtcorrespondingtothefirst\ndlargesteigenvalues.\n2.2FeatureExtraction\nTheoptimalprojectionvectorsof2DPCA,\nX1;\n;Xd,areusedfor\nfeatureextraction.Foragivenimagesample\nA,let\nYkAXk;k1;2;\n;d:\n8Then,weobtainafamilyofprojectedfeaturevectors,\nY1;;Yd,whicharecalledthe\nprincipalcomponent\n(vectors)ofthesample\nimageA.Itshouldbenotedthateach\nprincipalcomponent\nof2DPCA\nisavector,whereasthe\nprincipalcomponent\nofPCAisascalar.\nTheprincipalcomponentvectorsobtainedareusedtoforman\nmdmatrixBY1;\n;Yd,whichiscalledthe\nfeaturematrix\norfeatureimage\noftheimagesample\nA.2.3ClassificationMethod\nAfteratransformationby2DPCA,afeaturematrixisobtainedfor\neachimage.Then,anearestneighborclassifierisusedfor\n\nclassification.Here,thedistancebetweentwoarbitraryfeature\nmatrices,BiYi1;Yi2;;YidandBjYj1;Yj2;\n;Yjd,is\ndefinedby\ndBi;BjXdk1YikYjk\n\n2;9wherejjYikYjkjj2denotestheEuclideandistancebetweenthe\ntwoprincipalcomponentvectors\nYikandYjk.Supposethatthetrainingsamplesare\nB1;B2;;BM(whereMisthetotalnumberoftrainingsamples),andthateachofthese\n\nsamplesisassignedagivenidentity(class)\n!k.Givenatestsample\nB,if\ndB;BlminjdB;BjandBl2!k,thentheresulting\ndecisionis\nB2!k.32DPCA-B\nASEDIMAGERECONSTRUCTION\nIntheEigenfacesmethod,theprincipalcomponentsandeigen-\nvectors(eigenfaces)canbecombinedtoreconstructtheimageofa\nface.Similarly,2DPCAcanbeusedtoreconstructafaceimagein\nthefollowingway.\nSupposetheorthonormaleigenvectorscorrespondingtothe\nfirstdlargesteigenvectorsoftheimagecovariancematrix\nGtareX1;\n;Xd.Aftertheimagesamplesareprojectedontothese\naxes,theresultingprincipalcomponentvectorsare\nYkAXkk1;2;;d.Let\nVY1;\n;YdandUX1;\n;Xd,then\nVAU:10SinceX1;\n;Xdareorthonormal,from(10),itiseasytoobtainthe\nreconstructedimageofsample\nA:~AAVUTXdk1YkXTk:11Let~AAkYkXTkk1;2;\n;d,whichisofthesamesizeas\nimageA,andrepresentsthe\nreconstructedsubimage\nofA.Thatis,\nimageAcanbeapproximatelyreconstructedbyaddingupthe\nfirstdsubimages.Inparticular,whentheselectednumberof\nprincipalcomponentvectors\nd=n(nisthetotalnumberof\neigenvectorsof\nGt),wehave\n~AAA,i.e.,theimageiscompletely\nreconstructedbyitsprincipalcomponentvectorswithoutanyloss\nofinformation.Otherwise,if\nd<n\n,thereconstructedimage\n~AAisanapproximationfor\nA.4EXPERIMENTSAND\nANALYSISTheproposed2DPCAmethodwasusedforfacerecognitionand\ntestedonthreewell-knownfaceimagedatabases(ORL,AR,and\nYale).TheORLdatabasewasusedtoevaluatetheperformanceof\n\n2DPCAunderconditionswheretheposeandsamplesizeare\nvaried.TheARdatabasewasemployedtotesttheperformanceof\nthesystemunderconditionswherethereisavariationovertime,\n\ninfacialexpressions,andinlightingconditions.TheYaledatabase\nwasusedtoexaminethesystemperformancewhenbothfacial\nexpressionsandilluminationarevaried.\n4.1ExperimentsontheORLDatabase\nTheORLdatabase(http://www.cam-orl.co.uk)containsimages\nfrom40individuals,eachproviding10differentimages.Forsome\nsubjects,theimagesweretakenatdifferenttimes.Thefacial\n132IEEETRANSACTIONSONPATTERNANALYSISANDMACHINEINTELLIGENCE,VOL.26,NO.1,JANUARY2004\nFig.1.FivesampleimagesofonesubjectintheORLfacedatabase.\n'b'expressions(openorclosedeyes,smilingornonsmiling)andfacial\ndetails(glassesornoglasses)alsovary.Theimagesweretaken\nwithatoleranceforsometiltingandrotationofthefaceofupto\n\n20degrees.Moreover,thereisalsosomevariationinthescaleofup\ntoabout10percent.Allimagesaregrayscaleandnormalizedtoa\nresolutionof\n92112pixels.Fivesampleimagesofoneperson\nfromtheORLdatabaseareshowninFig.1.\nFirst,anexperimentwasperformedusingthefirstfiveimage\nsamplesperclassfortraining,andtheremainingimagesfortest.\nThus,thetotalnumberoftrainingsamplesandtestingsampleswere\n\nboth200.The2DPCAalgorithmwasfirstusedforfeatureextraction.\nHere,thesizeofimagecovariancematrix\nGtwas9292,soitwas\nveryeasytocalculateitseigenvectors.Wechosetheeigenvectors\n\ncorrespondingto10largesteigenvalues,\nX1;\n;X10,asprojection\naxes.Aftertheprojectionoftheimagesampleontotheseaxesusing\n(8),weobtainedtenprincipalcomponentvectors,\nY1;\n;Y10.TakingthelastimageinFig.1asanexample,wecandetermineits\n10constructedsubimages,\n~AAkYkXTk,k1;2;\n;10.Someof\nthesesubimagesareshowninFig.2inreversecolorforthesakeof\nclarity.Moreover,themagnitudeof\nGtseigenvaluesisplottedin\ndecreasingorderinFig.3.\nAsobservedinFig.2,thefirstsubimagecontainsmostofthe\nenergyoftheoriginalimage.Theotheronesshowthedetailed\n\nlocalinformationfromdifferentlevels.Asthevalueof\nkincreases,theinformation(theenergyofimage)containedin\n~AAkbecomesgraduallyweaker.Fig.3showsthemagnitudeoftheeigenvalues\nquicklyconvergestozero,whichisexactlyconsistentwiththe\nresultsofFig.2.Thus,wecanconcludethattheenergyofanimage\n\nisconcentratedonitsfirstsmallnumberofcomponentvectors.\nTherefore,itisreasonabletousethesecomponentvectorsto\nrepresenttheimageforrecognitionpurposes.\nOntheotherhand,byaddingupthefirst\ndsubimagestogether,\nweobtainanapproximatereconstructionoftheoriginalimage.Fig.4\n\nshowsfivereconstructedimagesofthelastimageinFig.1byadding\nthefirst\nd(d=2,4,6,8,10)subimagestogether.Thereconstructed\nimagesbecomeclearerasthenumberofsubimagesisincreased.For\ncomparison,thePCA(Eigenfaces)wasalsousedtorepresentand\nreconstructthesamefaceimage.Fig.4alsoshowsthereconstructed\nimagesasthenumberofprincipalcomponents\ndissetto5,10,20,30,\nand40.ThePCAdidnotperformaswellinthereconstructionofthis\nimage.Now,letusdesignaseriesofexperimentstocomparethe\nperformanceof2DPCAandPCA(Eigenfaces)underconditions\nwherethesamplesizeisvaried.Here,fivetestswereperformed\n\nwithavaryingnumberoftrainingsamples.Morespecifically,in\n\nthekthtest,weusedthefirst\nkimagesamplesperclassfortraining\nandtheremainingsamplesfortesting.Theproposed2DPCA\nmethodandthePCA(Eigenfaces)methodwereusedforfeature\n\nextraction.Finally,anearestneighborclassifierwasemployedfor\n\nclassification.Notethatin2DPCA,(9)isusedtocalculatethe\ndistancebetweentwofeaturematrices(formedbytheprincipal\ncomponentvectors).InPCA(Eigenfaces),thecommonEuclidean\n\ndistancemeasureisadopted.Table1presentsthetoprecognition\naccuracyofPCAand2DPCA,whichcorrespondstodifferent\nnumbersoftrainingsamples.Theperformanceof2DPCAisbetter\n\nthanPCA.Here,itshouldbepointedoutthatPCAusedall\n\ncomponents(atmost\nM1,where\nMisthetotalnumberof\ntrainingsamples)forachievingthemaximalrecognitionaccuracy\nwhenthereareoneortwosamplesperpersonfortraining.\nThe2DPCAmethodisalsosuperiortoPCAintermsof\ncomputationalefficiencyforfeatureextraction.Table2indicates\nthatfeatureextractionby2DPCAtakesmuchlesstime.Asthe\n\nnumberoftrainingsamplesperclassisincreased,therelativegain\n\nbetween2DPCAandPCAbecomesmoreapparent.\nHowever,onedisadvantageof2DPCA(comparedtoPCA)is\nthatmorecoefficientsareneededtorepresentanimage.From\n\nTable1,itisclearthatdimensionofthe2DPCAfeaturevector\n(112d)isalwaysmuchhigherthanPCAattoprecognition\naccuracy.Howdowereducethedimensionof2DPCA?Asimple\n\nstrategyistousePCAforfurtherdimensionalreductionafter\n\n2DPCA,i.e.,\n2DPCAplusPCA\n.Totestthisstrategy,wederiveeight\ncomponentvectors(\n1128featuresintotal)using2DPCAwhen\ntherearefivesamplesperclassfortraining.Then,PCAisusedfor\n\nthesecondfeatureextractionandanearestneighborclassifieris\nemployed.TheclassificationresultsareshowninFig.5.Thisfigure\nindicatesthattheperformanceof\n2DPCAplusPCA\nisstillbetter\nthanthatofPCAonlyforthesamedimensionality.\nIEEETRANSACTIONSONPATTERNANALYSISANDMACHINEINTELLIGENCE,VOL.26,NO.1,JANUARY2004\n133Fig.2.Somereconstructedsubimagesareshownininversecolor.\nFig.3.Theplotofthemagnitudeoftheeigenvaluesindecreasingorder.\nFig.4.Somereconstructedimagesbasedon2DPCA(upper)andPCA(lower).\n'b'Theperformanceof2DPCAwasalsocomparedwithother\nmethods,includingFisherfaces[16],ICA[13],[14],andKernel\n\nEigenfaces[14].Inthesecomparisons,twoexperimentalstrategies\nwereadopted.Onestrategywasusingthefirstfiveimagesperclass\nfortraining,whichismentionedabove.Theotherwasthe\nleave-one-outstrategy,thatis,theimageofonepersonisremovedfromthe\ndatasetandalloftheremainingimagesareusedfortraining.The\nexperimentalresultsunderbothstrategiesarelistedinTable3.\n\n2DPCAwasbetterthanothermethodsexceptfortherecognition\n\nratecomparedtoFisherfacesintheleave-one-outstrategy.\n4.2ExperimentontheARDatabase\nTheARfacedatabase[17],[18]containsover4,000colorfaceimages\nof126people(70menand56women),includingfrontalviewsof\nfaceswithdifferentfacialexpressions,lightingconditionsand\n\nocclusions.Thepicturesofmostpersonsweretakenintwosessions\n(separatedbytwoweeks).Eachsectioncontains13colorimagesand\n120individuals(65menand55women)participatedinboth\n\nsessions.Theimagesofthese120individualswereselectedandused\n\ninourexperiment.Onlythefullfacialimageswereconsideredhere\n(noattemptwasmadetohandleoccludedfacerecognitionineach\nsession).Wemanuallycroppedthefaceportionoftheimageand\n\nthennormalizeditto\n5040pixels.Thenormalizedimagesofone\npersonareshowninFig.6,whereFigs.6a,6b,6c,6d,6e,6e,6f,and6g\narefromSession1,andFigs.6n,6o,6p,6q,6r,6s,and6tarefrom\n\nSession2.Thedetailsoftheimagesare:Fig.6aneutralexpression,\nFig.6bsmile,Fig.6canger,Fig.6dscream,Fig.6eleftlighton;Fig.6f\nrightlighton;Fig.6gallsideslighton;andFigs.6n,6o,6p,6q,6r,6s,\n\nand6tweretakenunderthesameconditionsasFigs.6a,6b,6c,6d,\n\n6e,6e,6f,and6g.\n4.2.1VariationsOverTime\nInthisexperiment,imagesfromthefirstsession(i.e.,Figs.6a,6b,6c,\n6d,6e,6e,6f,and6g)wereusedfortraining,andimagesfromthe\n\nsecondsession(i.e.,Figs.6n,6o,6p,6q,6r,6s,and6t)wereusedfor\n\ntesting.Thus,thetotalnumberoftrainingsampleswas840.Since\n\nthetwosessionswereseparatedbyanintervaloftwoweeks,theaim\n\nofthisexperimentwastocomparetheperformanceofPCAand\n\n2DPCAundertheconditionswheretherearechangesovertime.\nFeatureswereextractedusingPCAand2DPCA,respectively.\nThen,100PCAcomponentfeatureswereobtainedand102DPCA\ncomponentfeaturevectors.Thenumberofselected2DPCA\ncomponentfeaturevectorsvariedfrom1to10.Thenumberof\n\nselectedPCAcomponentfeaturesvariedfrom10to100inintervalsof\n10.Basedontheselectedfeatures,anearestneighborclassifierwas\nemployedforclassification.Thecorrespondingrecognitionaccura-\n\nciesareillustratedinFig.7.Ingeneral,2DPCAperformedbetterthan\nPCA.Thetoprecognitionaccuracyof2DPCAwas67.6percentusing\n10featurevectors,but66.2percentusingPCAwith100component\n\nfeatures.Featureextractiontimesforbothmethodsaresummarizedin\nTable4.Featureextractionwith2DPCAismorethan20times\n\nfasterthanPCA,mainlybecausethelatterinvolvescalculatingthe\n\neigenvectorsofan\n840840matrix,whereas2DPCAcalculatesthe\neigenvectorsofa\n4040matrix.4.2.2VariationsinFacialExpressions\nInthisexperiment,theobjectivewastocomparePCAand2DPCA\nundervaryingfacialexpressions.WeselectedimagesFigs.6a,6b,6c,\n\nand6dandFigs.6n,6o,6p,and6q),whichinvolvevariationsin\nfacialexpressions.Figs.6aand6nwereusedfortrainingandthe\nothers(i.e.,Figs.6band6b,6c,and6dandFigs.6o,6p,and6q)were\n\nusedfortesting.Thus,thetotalnumberoftrainingsamplesis240.\nAsinthepreviousexperiment,PCAwasusedtoextract\n100principalcomponentfeaturesand2DPCAtoextract10princi-\n\npalcomponentfeaturevectors.Fig.7showstherecognition\naccuracyunderavaryingnumberofselectedfeatures(orfeature\nvectors).Thetoprecognitionaccuracyandthetimeconsumedfor\n\nfeatureextractionarelistedinTable4.Again,2DPCAwasmore\n\neffectiveandefficientthanPCA.\n4.2.3VariationsinLightingConditions\nInthisexperiment,ouraimwastocomparePCAand2DPCA\n\nundervaryingillumination.Imageswithvaryinglightingcondi-\ntionswereselectedfirst.TheselectedsamplesetincludedFigs.6a,\n6e,6f,and6gfromthefirstsessionandFigs.6n,6r,6s,and6tfrom\n\nthesecondsession.Fromthisset,wearbitrarilychosetwosamples\n\nfortraining,onefromthefirstsessionandanotherfromthe\n\nsecond.Theremainingsampleswereusedfortesting.Thus,there\n134IEEETRANSACTIONSONPATTERNANALYSISANDMACHINEINTELLIGENCE,VOL.26,NO.1,JANUARY2004\nTABLE1\nComparisonoftheTopRecognitionAccuracy(%)ofPCAversus2DPCA\nThevaluesinparenthesesdenotethedimensionoffeaturevectorsforthebestrecognitionaccuracy.Notethatthebestchoicesofthenumberofthecom\nponentsforthe\ntoprecognitionaccuracydependonthetestdataandarenotknownbeforehandinarealproblem.Theasterisksindicateastatisticallysignificantdi\nfferencebetween\nPCAand2DPCAatasignificancelevelof0.05inthetrials.\nTABLE2\nComparisonofCPUTime(s)forFeatureExtractionUsingtheORL(CPU:PentiumIII800MHz,RAM:256Mb)\nFig.5.Comparisonof2DPCAplusPCAandPCAaloneontheORLdatabase.\n'b'were16possiblesetsoftrainingsamples.Basedonthesesetsof\ntrainingsamples,weperformed16tests.Ineachtest,the\n\nperformanceofPCAand2DPCAwascompared.Theexperimental\n\nresultsoftrainingsamplesets{(a),(n)},{(e),(s)},and{(f),(t)}are\n\nshowninFig.8,withtherecognitionaccuracyofPCAand2DPCA\n\nwithvaryingnumberofselectedfeatures.Fig.9illustratesthetop\nrecognitionaccuracyofPCAand2DPCAfromeachtest.This\nfigureindicatesthattheperformanceof2DPCAismuchbetter\n\nthanPCAunderconditionswherelightingisvaried.Table4shows\n\ntheaveragerecognitionaccuracyfromthe16tests.Theaverage\n\nrecognitionaccuracyof2DPCAwas89.8percent,morethan\n\n10percenthigherthanPCA.Table4alsoindicatesthatfeature\n\nextractionusing2DPCAwasmuchfasterthanPCA.\n4.3ExperimentontheYaleDatabase\nThelastexperimentwasperformedusingtheYalefacedatabase,\nwhichcontains165imagesof15individuals(eachpersonhas\n\n11differentimages)undervariousfacialexpressionsandlighting\nconditions.Eachimagewasmanuallycroppedandresized\nto10080pixelsinthisexperiment.\nInthisexperiment,the\nleave-one-outstrategywasadopted.The\nexperimentalresultsusing2DPCA,PCA(Eigenfaces),ICA,and\n\nKernelEigenfacesarelistedinTable5.Therecognitionrateof\n\n2DPCAwassuperiortoPCA,ICAandKernelEigenfaces.\n4.4EvaluationoftheExperimentalResults\nTheaboveexperimentsshowedthattherecognitionrateof2DPCA\n\nisalwayshigherthanPCA.But,isthisdifferencestatistically\nIEEETRANSACTIONSONPATTERNANALYSISANDMACHINEINTELLIGENCE,VOL.26,NO.1,JANUARY2004\n135TABLE3\nComparisonof2DPCAwithOtherMethodsUsingtheORLDatabase\nNotethatICAistestedusingEuclideandistancein[14].Notethattheasterisksindicateastatisticallysignificantdifferencebetweenthemarked\nmethodand2DPCAata\nsignificancelevelof0.05.\nFig.6.SampleimagesforonesubjectoftheARdatabase.\nFig.7.Performanceof2DPCAandPCAundertheconditionofvariationsovertimeandinfacialexpressions.\n'b'significant?Inthissection,weevaluatetheexperimentalresults\nusingthenullhypothesisstatisticaltestbasedonBernoullimodel\n\n[20],[21].Iftheresulting\np-valueisbelowthedesiredsignificance\nlevel(i.e.,0.05),thenullhypothesisisrejectedandtheperformance\ndifferencebetweentwoalgorithmsareconsideredstatistically\nsignificant.Theevaluationresultsbasedonthestatisticaltest\n(1-tailed)werenotedinTables1,3,4,and5andsummarizedas\n\nfollows:1.FortheORLdatabase,2DPCAoutperformedPCAsignifi-\ncantlyinthetrialswith1,2,and4trainingsamplesperclass\n(p=0.0017,0.0492,and0.0361,respectively).\n2.FortheARdatabase,2DPCAoutperformedPCAsig-\nnificantlyunderconditionofvariationsinilluminations\n(p<0.001).3.FortheYaledatabase,2DPCAwassignificantlybetterthan\nPCAandtheothers(\np<0.006).4.Intheothertests,althoughtherecognitionrateof2DPCA\nwasstillbetterthanthatofPCA,theperformancedifference\nbetweenPCAand2DPCAwasnotstatisticallysignificant.\n5CONCLUSIONAND\nFUTUREWORKInthispaper,anewtechniqueforimagefeatureextractionand\nrepresentationtwo-dimensionalprincipalcomponentanalysis\n(2DPCA)wasdeveloped.2DPCAhasmanyadvantagesover\nconventionalPCA(Eigenfaces).Inthefirstplace,since2DPCAis\nbasedontheimagematrix,itissimplerandmorestraightforward\ntouseforimagefeatureextraction.Second,2DPCAisbetterthan\nPCAintermsofrecognitionaccuracyinallexperiments.Although\nthistrendseemstobeconsistentfordifferentdatabasesand\nconditions,insomeexperimentsthedifferencesinperformance\n\nwerenotstatisticallysignificant.Third,2DPCAiscomputationally\n136IEEETRANSACTIONSONPATTERNANALYSISANDMACHINEINTELLIGENCE,VOL.26,NO.1,JANUARY2004\nTABLE4\nComparisonofPCAand2DPCAUsingtheARDatabaseundertheConditionofVariationsoverTime,inFacialExpressionandIllumination\nNotethattheasteriskindicatesastatisticallysignificantdifferencebetweenPCAand2DPCAatasignificancelevelof0.05inthetrial.\nFig.8.Recognitionaccuracyof2DPCAandPCAforthreedifferenttrainingsamplesets:{a,n},{e,s},and{f,t}undertheconditionofvariationsinil\nlumination.Fig.9.Toprecognitionaccuracyof2DPCAandPCAcorrespondingtoallofthe16\ntestsundervaryingillumination.\nTABLE5\nComparisonofthePerformanceof2DPCA,Eigenfaces,\nICA,andKernelEigenfacesUsingtheYaleDatabase\n(NotethatICAIsTestedUsingEuclideanDistancein[14])\nNotethattheasteriskindicatesastatisticallysignificantdifferencebetweenthe\nmarkedmethodand2DPCAatasignificancelevelof0.05.\n'b'moreefficientthanPCAanditcanimprovethespeedofimage\nfeatureextractionsignificantly.However,itshouldbepointedout\n\nthat2DPCA-basedimagerepresentationwasnotasefficientas\n\nPCAintermsofstoragerequirements,since2DPCArequiresmore\n\ncoefficientsforimagerepresentationthanPCA.\nWhydoes2DPCAoutperformPCAinfacerecognition?Inour\nopinion,theunderlyingreasonisthat2DPCAismoresuitablefor\n\nsmallsamplesizeproblems(likefacerecognition)sinceitsimage\n\ncovariancematrixisquitesmall.Imagerepresentationand\n\nrecognitionbasedonPCA(or2DPCA)isstatisticallydependent\n\nontheevaluationofthecovariancematrix(althoughforPCAthe\nexplicitconstructionofthecovariancematrixcanbeavoided).The\nobviousadvantageof2DPCAoverPCAisthattheformer\n\nevaluatesthecovariancematrixmoreaccurately.\nFinally,therearestillsomeaspectsof2DPCAthatdeserve\nfurtherstudy.Whenasmallnumberoftheprincipalcomponentsof\nPCAareusedtorepresentanimage,themeansquareerror(MSE)\nbetweentheapproximationandtheoriginalpatternisminimal.\n\nDoes2DPCAhaveasimilarproperty?Inaddition,2DPCAneeds\n\nmorecoefficientsforimagerepresentationthanPCA.Although,asa\n\nfeasiblealternativetodealwiththisproblemistousePCAafter\n\n2DPCAforfurtherdimensionalreduction,itisstillunclearhowthe\n\ndimensionof2DPCAcouldbereduceddirectly.\nACKNOWLEDGMENTSThisworkispartiallysupportedbyCentreofMultimediaSignal\nProcessingandthecentralfundfromTheHongKongPolytechnic\nUniversity.And,itispartiallysupportedbygrantsTIC2002-04495-\n\nC02fromthesameSpanishMinistryofScienceandTechnology\n\n(MCyT)andAutenticUZ(UZ-2001-TEC-01)fromtheUniversityof\n\nZaragoza.ItisalsopartiallysupportedbytheNationalScience\n\nFoundationofChinaundergrantno.60072034.Finally,theauthors\n\nwouldliketothanktheanonymousreviewersfortheirconstructive\n\nadvice.REFERENCES[1]L.SirovichandM.Kirby,Low-DimensionalProcedureforCharacteriza-\ntionofHumanFaces,\nJ.OpticalSoc.Am.,\nvol.4,pp.519-524,1987.\n[2]M.KirbyandL.Sirovich,ApplicationoftheKLProcedureforthe\nCharacterizationofHumanFaces,\nIEEETrans.PatternAnalysisandMachine\nIntelligence,vol.12,no.1,pp.103-108,Jan.1990.\n[3]M.TurkandA.Pentland,EigenfacesforRecognition,\nJ.Cognitive\nNeuroscience,vol.3,no.1,pp.71-86,1991.\n[4]A.Pentland,LookingatPeople:SensingforUbiquitousandWearable\nComputing,IEEETrans.PatternAnalysisandMachineIntelligence,\nvol.22,\nno.1,pp.107-119,Jan.2000.\n[5]M.A.Grudin,OnInternalRepresentationsinFaceRecognitionSystems,\nPatternRecognition,\nvol.33,no.7,pp.1161-1177,2000.\n[6]G.W.CottrellandM.K.Fleming,FaceRecognitionUsingUnsupervised\nFeatureExtraction,\nProc.IntlNeuralNetworkConf.,\npp.322-325,1990.\n[7]D.Valentin,H.Abdi,A.J.OToole,andG.W.Cottrell,Connectionist\nModelsofFaceProcessing:aSurvey,\nPatternRecognition,\nvol.27,no.9,\npp.1209-1230,1994.\n[8]P.S.PenevandL.Sirovich,TheGlobalDimensionalityofFaceSpace,\nProc.FourthIEEEIntlConf.AutomaticFaceandGestureRecognition,\npp.264-\n270,2000.\n[9]L.ZhaoandY.Yang,TheoreticalAnalysisofIlluminationinPCA-Based\nVisionSystems,\nPatternRecognition,\nvol.32,no.4,pp.547-564,1999.\n[10]L.Wiskott,J.M.Fellous,N.Kru\nger,andC.vonderMalsburg,Face\nRecognitionbyElasticBunchGraphMatching,\nIEEETrans.Pattern\nAnalysisandMachineIntelligence,\nvol.19,no.7,pp.775-779,July1997.\n[11]M.S.Bartlett,J.R.Movellan,andT.J.Sejnowski,FaceRecognitionby\nIndependentComponentAnalysis,\nIEEETrans.NeuralNetworks,\nvol.13,\nno.6,pp.1450-1464,2002.\n[12]B.A.Draper,K.Baek,M.S.Bartlett,J.R.Beveridge,RecognizingFaceswith\nPCAandICA,\nComputerVisionandImageUnderstanding:specialissueonface\nrecognition,inpress.\n[13]P.C.YuenandJ.H.Lai,FaceRepresentationUsingIndependentCompo-\nnentAnalysis,\nPatternRecognition,\nvol.35,no.6,pp.1247-1257,2002.\n[14]M.H.Yang,KernelEigenfacesvs.KernelFisherfaces:FaceRecognition\nUsingKernelMethods,\nProc.FifthIEEEIntlConf.AutomaticFaceand\nGestureRecognition(RGR02),\npp.215-220,May2002.\n[15]K.Liuetal.,AlgebraicFeatureExtractionforImageRecognitionBasedon\nanOptimalDiscriminantCriterion,\nPatternRecognition,\nvol.26,no.6,\npp.903-911,1993.\n[16]P.N.Belhumeur,J.P.Hespanha,andD.J.Kriengman,Eigenfacesvs.\nFisherfaces:RecognitionUsingClassSpecificLinearProjection,\nIEEETrans.PatternAnalysisandMachineIntelligence,\nvol.19,no.7,pp.711-720,\nJuly1997.\n[17]A.M.MartinezandR.Benavente,TheARFaceDatabase,CVCTechnical\nReport,no.24,June1998.\n[18]A.M.MartinezandR.Benavente,TheARFaceDatabase,http://\nrvl1.ecn.purdue.edu/~aleix/aleix_face_DB.html,2003.\n[19]J.Yang,J.Y.Yang,FromImageVectortoMatrix:AStraightforwardImage\nProjectionTechniqueIMPCAvs.PCA,\nPatternRecognition,\nvol.35,no.9,\npp.1997-1999,2002.\n[20]W.Yambor,B.Draper,andR.Beveridge,AnalyzingPCA-BasedFace\nRecognitionAlgorithms:Ei-GenvectorSelectionandDistanceMeasures,\n\nEmpiricalEvaluationMethodsinComputerVision,\nH.Christensenand\nJ.Phillips,eds.,Singapore:WorldScientificPress,2002.\n[21]J.R.Beveridge,K.She,B.Draper,andG.H.Givens,Parametricand\nNonparametricMethodsfortheStatisticalEvaluationofHumanID\nAlgorithms,\nProc.ThirdWorkshopEmpiricalEvaluationofComputerVision\nSystems,Dec.2001.\n.Formoreinformationonthisoranyothercomputingtopic,pleasevisitour\nDigitalLibraryat\nhttp://computer.org/publications/dlib.\nIEEETRANSACTIONSONPATTERNANALYSISANDMACHINEINTELLIGENCE,VOL.26,NO.1,JANUARY2004\n137'