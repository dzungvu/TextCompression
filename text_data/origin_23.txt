b'IEEETRANSACTIONSONENERGYCONVERSION,VOL.21,NO.1,MARCH2006\n273Long-TermWindSpeedandPowerForecastingUsing\nLocalRecurrentNeuralNetworkModels\nThanasisG.Barbounis,JohnB.Theocharis\n,Member,IEEE\n,MinasC.Alexiadis,and\nPetrosS.Dokopoulos\n,Member,IEEE\nAbstractThispaperdealswiththeproblemoflong-termwind\nspeedandpowerforecastingbasedonmeteorologicalinformation.\n\nHourlyforecastsupto72-haheadareproducedforawindpark\n\nontheGreekislandofCrete.Asinputsourmodelsusethenumer-\nicalforecastsofwindspeedanddirectionprovidedbyatmospheric\nmodelingsystemSKIRONforfournearbypositionsupto30km\n\nawayfromthewindturbinecluster.Threetypesoflocalrecur-\n\nrentneuralnetworksareemployedasforecastingmodels,namely,\n\ntheinniteimpulseresponsemultilayerperceptron(IIR-MLP),the\n\nlocalactivationfeedbackmultilayernetwork(LAF-MLN),andthe\n\ndiagonalrecurrentneuralnetwork(RNN).Thesenetworkscontain\n\ninternalfeedbackpaths,withtheneuronconnectionsimplemented\n\nbymeansofIIRsynapticlters.Twonovelandoptimalon-line\n\nlearningschemesaresuggestedfortheupdateoftherecurrentnet-\n\nworksweightsbasedontherecursivepredictionerroralgorithm.\n\nThemethodsassurecontinuousstabilityofthenetworkduringthe\n\nlearningphaseandexhibitimprovedperformancecomparedtothe\n\nconventionaldynamicbackpropagation.Extensiveexperimenta-\n\ntioniscarriedoutwherethethreerecurrentnetworksareaddi-\n\ntionallycomparedtotwostaticmodels,anite-impulseresponse\n\nNN(FIR-NN)andaconventionalstatic-MLPnetwork.Simulation\n\nresultsdemonstratethattherecurrentmodels,trainedbythesug-\n\ngestedmethods,outperformthestaticoneswhiletheyexhibitsig-\n\nnicantimprovementoverthepersistentmethod.\nIndexTerms\nLocalrecurrentneuralnetworks,long-termwind\npowerforecasting,nonlinearrecursiveleastsquarelearning,real\n\ntimelearning.\nI.I\nNTRODUCTION\nWINDENERGYconversionsystems(WECS)appearas\nanappealingalternativetoconventionalpowergenera-\ntion,beingmostappropriateforisolatedpowersystemsonis-\n\nlandsorruralareas.Integrationofaccuratewindforecastsinthe\n\nmanagementroutinesinvolvedinWECSprovidesasignicant\n\ntoolforoptimizingoperatingcostsandimprovingreliability.\nHowever,duetohighlycomplexinteractionsandthecontri-\nbutionofvariousmeteorologicalparameters,windforecasting\n\nisaseveretask.Despitethedifculties,avarietyofapproaches\n\nhavebeensuggestedintheliterature.Theparticularpredic-\n\ntionmethoduseddependsontheavailableinformationandthe\n\ntime-scaleoftheapplication.Windforecastsintherangeofa\n\nfewsecondsareusedforwindturbinescontrol[1],[2].Time\nManuscriptreceivedDecember9,2003;revisedJune11,2004.Paperno.\nTEC-00357-2003.T.G.BarbounisandJ.B.TheocharisarewiththeElectronicandComputer\nEngineeringDivision,ElectricalandComputerEngineeringDepartment,Aris-\ntotleUniversityofThessaloniki,Thessaloniki,Greece.\nM.C.AlexiadisandP.S.DokopoulosarewiththeElectricalPowerSystems\nLaboratory,ElectricalandComputerEngineeringDepartment,AristotleUni-\nversityofThessaloniki,Thessaloniki,Greece.\nDigitalObjectIdentier10.1109/TEC.2005.847954\nscalesintheorderofseveralminutesorevenhoursareencoun-\ntered,whenpowersystemschedulingistobeaddressed[3].In\n\nthesecases,thetimeseriesapproachisusuallyfollowed,asin\n\n[4]wherearecurrenthigh-orderneuralnetwork(NN)isused\n\nforshort-termpredictionofwindpower.Furthermore,similar\n\nmodelshavebeenappliedfordaily,weekly,orevenmonthly\n\ntimeseries[5].\nLong-termpredictionofwindpowerallowsplanningthecon-\nnectionordisconnectionofwindturbinesorconventionalgen-\n\nerators,thusachievinglowspinningreserveandoptimaloper-\natingcost.Itreferstohourlydataandatimehorizonofuptotwo\ntothreedaysahead.Insuchcases,thestatisticalpropertiesof\n\nthewindarenothelpful,andhence,wehavetorelyonapprox-\n\nimatewindforecastsprovidedbythenationalmeteorological\n\nservices.Thesepredictionsarecalculatedforsomepredened\n\nreferencepoints,notnecessarilyonthepositionofthepark,so\n\ntheneedarisesforthereductionofthesepredictionstothesite\n\nofinterest.\nInthepast,considerableeffortshavebeendevotedtoutilizing\nmeteorologicalinformationtoderivetherequiredforecasts.\nMicro-andMeso-scalemodels(suchasWASPorPARK)are\nactuallydeterministicmodelsthatsuggestvariouscorrectingpa-\nrametersaccordingtotheterrainproperties(orography,rough-\nness).Theyalsotakeconsiderationofthenumber,type,and\n\nlocationofwindturbinesinthewindfarm,theposition,the\n\nhub-height,thepowercurveofeachonetoproducethetotal\n\npoweroutputofthewindfarm[6],[7].\nModeloutputstatistics(MOS)areusedtotranslatenu-\nmericalmeteorologicalinputstoactualwindpoweroutputs,\n\ne.g.,simplemethodstocorrectbiasandscalingerrorsofthe\n\ninitialforecastedvalues[8][11].ArticialIntelligencemodels\n\nareactuallyadvancedMOStechniquescombiningcomplex\n\ninput-outputarchitecture,robust,andexibleadaptivealgo-\nrithms[12].\nInthispaper,wedealwithlong-termwindspeedandpower\nforecastingforawindpark.Owingtothelargetime-scale,\n\nwearebasedonthree-daysaheadmeteorologicalpredictions\n\n(windspeedanddirection)providedatfournearbysitesof\n\nthepark.Toaccountforthecomplexdynamicsoftheprocess,\n\nthreelocalrecurrentneuralnetworkswithinternalfeedback\n\npathsareemployedtoproduce72hours-aheadwindforecasts.\n\nTheabovechoiceismotivatedbythefactthatthesemodels\n\nexhibitfasterlearningcomparedtothefullyrecurrentneural\n\nnetworks[13].First,theinniteimpulseresponsemultilayer\n\nperceptron(IIR-MLP)issuggested,havingsufcientlyrich\nnetworkarchitecture.Additionally,morerelaxedstructuresare\nconsidered,includingthelocalactivationfeedbackmultilayer\n0885-8969/$20.002005IEEE\n'b'274IEEETRANSACTIONSONENERGYCONVERSION,VOL.21,NO.1,MARCH2006\nFig.1.GeographicallocationofthewindparkofRokas,ontheGreekislandof\nCrete.Alsoshownarethenodeswheremeteorologicalpredictionsareavailable\nandtheprevailingwinddirection.\nnetwork(LAF-MLN)andthediagonalrecurrentneuralnetwork\n(DRNN)model.Twonovelandef\ncientlearningschemesare\ndeveloped,aglobalandadecoupledapproachoftherecursive\n\npredictionerror(RPE)algorithm,forupdatingthenetwork\nsweights,suitableforon-lineapplications.Theexperimental\n\nresultsshowthataccurateforecastsareobtained,withthe\n\nrecurrentforecastmodelsexhibitingsuperiorperformancewith\n\nregardtothestaticnetworks.\nII.P\nROBLEM\nFORMULATION\nLetusconsidertheRokasW/Fwithacapacityof10.2MW\nlocatedatEasternCrete,Greece.Foref\ncientmaintenanceand\nresourceplanningofWECS,itisveryhelpfulforustoknowin\n\nadvancethewindspeedandpoweratthepark,foratimehorizon\n\nincludingafewdaysahead.Thisallowsanoptimalpolicyto\nbedesigned,usingtheoptimumamountoftheavailablewind\nturbinesandschedulingthepossibleneedforstoringorsupple-\n\nmentingthegeneratedpower.\nDuetothelargetimescale,themainsourceofinformation\nisthewindmeteorologicalpredictions,near-surface\nnodepre-\ndictions,calculatedfor4speci\ncpositions(N,S,E,W)lo-\ncatedaroundthewindpark(seeFig.1).Thenodepredictions\n\naregivenonceperday,andassumeforsimplicitythattheyare\navailableatthebeginningofeachday\n,where\nisthenumberofdaysconsideredinthedataset.Foreach\nnodeandday,themeteorologicaldataareformulatedasrecords\n\ncomprisingpredictionsofthewindspeedanddirectionatthe\nsucceeding72-hahead\n(1)where,and\ndenotethemeteorologicalnodepredictionsof\nwindspeedanddirection,respectively,attime\n.Alsoavailablearethepredictionsofatmosphericpressureand\n\ntemperatureattheparksite.\nFig.2.Con\ngurationoftheforecastingapproach.Thenodepredictionsand\nthewindforecastsproducedbythemodelsaregivenatthebeginningofeach\nday.Theycoveratimeperiodof72-haheadandareupdatedevery24h.\nTherealdataprovidedbytheW/FSCADAsysteminclude\nvaluesofthewindspeedmeasuredatareferencepointwithin\n\ntheparkandthetotalpowerofthefarm,denotedas\nand,respectively.ThedataarerecordedhourlyfromApril\n1st,2000untilDecember31st,2000.\nGiventhenodepredictions,theobjectiveistodevelopanad-\nvancedforecastmodelproviding72-h-aheadwindspeedand\n\npowerforecastsatthepark,denotedas\nand,respec-\ntively.Thecon\ngurationoftheforecastingapproachisdepicted\ninFig.2.Thewindestimatesaregivenatthebeginningofeach\n\ndayandthemodelisgenerallydescribedby\n(2)wherestandsforeither\norrepresentsthe\nnonlinearmappingfunctionoftheprocess,andthevectors\nandaregivenas\n(3)Apparently,therearebothspatialandtemporalcorrelations\ninvolvedbetweenthenodepredictionsandthewindvariables\nattheparktobeforecasted,renderingthesystemahighly\n\ncomplex,dynamic,andnonstationaryprocess.Thewindvalues\n\nareaffectedbylarge-scaleatmosphericconditionsandthe\nmorphologyofthesurfacelandscape.\nEfcientforecastingdictatesthatthemodelshouldexhibit\nthefollowingproperties.First,foreach\n,thecurrentandpast\nvaluesofthenodepredictionsshouldbeconsideredasmodel\ninputs,assuggestedby\n,sothatthemodelcanprop-\nerlyidentifytheinputtrendsandvariations.Moreover,inthe\n\nabsenceofrealwindspeedandpowervaluesfortimesgreater\n\nthan,themodel\nspreviousestimates,\n,shouldbeused\n'b'BARBOUNIS\netal.\n:LONG-TERMWINDSPEEDANDPOWERFORECASTINGUSINGLOCALRNNMODELS275\ntoderivethecurrentoutputestimates,\n.Finally,themodel\nshouldbecapableofmemorizingthedynamicnatureofthe\n\nprocess.Inthispaper,weemploythreetypesofrecurrentneural\nnetworks,asadvancedforecastmodels,togeneratelong-term\nestimatesof\nand.Thesenetworksbelongtothe\nfamilyoflocal-recurrentglobal-feedforward(LRGF)models\n\nwithinternaldynamics,havestrongtemporalmodelingcapabil-\nitiesandful\nllcompletelythequalitycriteriadescribedabove.\nFurthermore,twonovelandef\ncientlearningschemesarealso\ndevisedfortheupdateofthenetworkweights.\nWhenanadvancedmodelisnotavailable,theso-calledper-\nsistentforecastscanbeobtainedwithaminimaleffortusingthe\nmostrecentinformationavailable.Followingthisapproach,the\n\nforecastatfuturetime-stepsisdetermined\nasanaverageofthe\npastvalues\n(4)wherearerealvaluesofwindspeedandpower,mea-\nsuredattimespriorto\n.Thisnaivepredictorsuggeststhatas\ntheforecastingtimelagincreases,correlationwithrecentpast\nmeasurementsbecomesnegligible,soalongerscaleaverage\nshouldbepreferredinstead.Theadvantagegainedbyanad-\n\nvancedmodelisreferredtoas%errorimprovementoverpersis-\n\ntentandservesasameanstoevaluatethemodel\nsperformance.\nIII.N\nETWORK\nARCHITECTURETheLRGFrecurrentnetworksarecomposedoflayersar-\nrangedinafeedforwardfashion.Eachlayercontainsdynamic\n\nprocessingunits(neurons)withtime-delaylinesand/orfeed-\n\nback.Dependingontheneurondynamicmodel,threenetwork\ntypesaremainlyconsidered,namely,theIIR-MLP,thelocalac-\ntivationfeedbackMLN(LAF-MLN)andtheoutputfeedback\n\nMLN.Inthispaper,wefocusontheIIR-MLPandtheLAF-\n\nMLN.Additionally,asimpli\ncationoftheLAF-MLNiscon-\nsidered,namely,theDRNN.\nA.TheIIR-MLPModel\nTheIIR-MLParchitecture,suggestedbyTsoiandBack[13],\nconsistsofneuronswherethesynapticweightsarereplacedwith\n\ninniteimpulseresponse(IIR)linear\nlters,alsorefereedtoas\nautoregressivemovingaverage(ARMA)models,asshownin\nFig.3(a).\nTocopewiththestructuralcomplexityofthenetworks,the\nfollowingnotationalconventionisemployed.TheIIR-MLPnet-\nworkisassumedtoconsistof\nlayers,with\nanddenotingtheinputandtheoutputlayer,respec-\ntively.The\nthlayercontains\nneurons,andbeingthenumberofneuronsintheinputandtheoutputlayer,respec-\ntively.\nistheoutputofthe\nthneuronofthe\nthlayerat\ntime.Inparticular,\narethenetwork\nsinputsignals,while\naretheoutput\nsignals.istheoutputofthesummingpoint,thatis,the\ninputtotheactivationfunctionofthe\nthneuronofthe\nthlayerattime\n.isthesynaptic\nlteroutputattime\ncon-nectingthe\nthneuroninthe\nthlayerwiththe\nthneuronof\nFig.3.LocalrecurrentNNsusedforwindforecasting.(a)Neuronmodelfor\nIIR-MLP.(b)NeuronmodelforLAF-MLN.(c)DRNNnetworkcon\nguration.thethlayer.\n,and\ndenotetheorderofthe\nMAandtheARpart,respectively,ofthesynapseconnectingthe\nthneuroninthe\nthlayerwiththe\nthinputcomingfromthe\nthlayer,with\n,and\n.andarethecoef\ncientsoftheMAandtheAR,respectively,ofthecorre-\nspondingsynapse.\nisthebiastermofeachneuron.Finally,\nandarethenode\nsactivationfunctionandits\nderivative.\nTheforwardrunattime\nevaluatedfor\nand,isdescribedasfollows:\n(5)(6)(7)Assumingthatthenetworkisrunningalongatrainingse-\nquence(epochwisemode)withtheweightsremaining\nxed\nthroughouttheepoch,theneuron\nsdynamicscanbedescribed\n'b'276IEEETRANSACTIONSONENERGYCONVERSION,VOL.21,NO.1,MARCH2006\ninacompactwayusinganotationemployedintheadaptive\nltertheory,asfollows:\n(8)where(9)(10)andisthedelayoperator,\n.It\ncanbeseenthattheIIR-MLParchitecturerealizesasuf\ncientlyrichclassofmodels.Itincludesseveralknownneuraltypesas\n\nspecialcases,dependingontheparametersettingsoftheIIR\n\nsynapticlters.Forinstance,theIIR-LMPcanbereducedtoa\nFIR-NN[14]byeliminatingthefeedbackconnections\n.Moreover,IIR-MLPreducestotheconventionalstaticMLP\n[15]bydiscardingtheMAandtheARpartsofthesynaptic\nl-ters.B.TheLAF-MLNModel\nTheneuronmodeloftheLAF-MLNstructure[16]isshown\ninFig.3(b).Theoutputofaneuronsumming-nodeis\nlteredthroughanautoregressive(AR)adaptive\nlterbeforefeeding\ntheactivationfunction.Itshouldbenoticedthat,regardingthe\n\nstructuralcomplexity,theLAF-MLNisconsiderablysimpler\n\ncomparedtotheIIR-MLP.Thisisduetothefactthatwhilean\n\nARpartisintroducedineverysynapticlinkinIIR-MLP,asingle\n\nARrecursionexistsforeachneuronintheLAF-MLNarchitec-\nture.Asaresult,forthesamenetworkstructure,thelatternet-\nworkcontainsasmallernumberoftunableweightscompared\n\ntotheformerone.\nTheforwardrunequationsfortheLAF-MLNaredescribed\nasfollows:\n(11)(12)(13)C.TheDRNNModel\nInordertofurtherreducethestructuralcomplexityissue,we\nconsidertheDRNN,amodi\nedformofthefullyrecurrentmodel\n[17].DRNNisatwo-layernetwork[Fig.3(c)],wherethehidden\n\nlayercontainsself-recurrentneuronswhiletheoutputlayeris\n\ncomposedoflinearneurons.Thehiddenlayerequationsare\n(14)(15)whilethenetwork\nsoutputisdeterminedby\n(16)NoticethattheDRNNcanbederivedasaspecialcaseofthe\nLAF-MLNfor\n.Particularly,weconsideronlythecon-\nstanttermsoftheMA\nltersforallneurons.More-\nover,theARpartsarereducedto\nrstorder\nltersforthehiddenlayer\nsneurons,whilefeedbackisbrokenforthe\nneuronsintheoutputlayer.\nIV.G\nRADIENTCALCULATIONS\nThelearningalgorithmtobedevelopedinthenextsectionre-\nquiresthecomputationofthegradientsofthenetwork\nsoutput\nwithrespecttoalltrainableweights.Becauseoftheexistence\nofinternaldynamics,thetraditionalprocedureofthestandard\nbackpropagation(BP)cannotbeappliedtodeterminethesegra-\n\ndients.Therefore,weemploythemethodoforderedderivatives\n\n[18],extensivelyusedintheliteratureforcalculatingpartial\nderivativesincomplexrecurrentnetworks.Noticethatsincethe\nrecursiveapproachisadopted,thechainrulederivativeexpan-\n\nsionisdevelopedinaforwardfashion.\nThegradientsrelatedifferentialchangesoftheneuronoutputs\ntodifferentialchangesofaweightwithinthenetwork.Consider\nanarbitraryweight\ndenotingeither\norofasynapseendingtothe\nthneuronofthe\nthlayer.Derivationof\nthegradientcalculationsfortheIIR-MLPmodelisgiveninthe\nAppendix.TherespectivecalculationsfortheLAF-MLNand\n\ntheDRNNproceedalongsimilarlinesandthereforetheyare\n\nomitted.Noticethatthecalculationofthegradientsisachieved\nthroughhigherorderrecurrentdifferenceequations.Thisis\n\nopposedtostaticnetworkstructureswheretheweightsare\nupdatedusingstaticrelations[15].AsregardstheIIR-MLP\nmodelandbasedonthegradientanalysisdescribedinthe\n\nAppendix,thefollowingcommentsareinorder.Thegradients\nofthesynaptic\nlteroutput\nwithregardtothe\nlterweights\nandarederivedbypassing\nand,respectively,throughtheARpartofthesynaptic\nlter.Furthermore,ateacht,thegradientsofthesynaptic\nlteroutputsbelongingtothesucceedinglayer\nwithrespectto\n(or),wheretheweightchangeis\nassumed,arecalculatedbypassingthecorrespondinggradients\nofthe\nthneuron\nsoutputatthe\nthlayerthroughthe\nlter.Hence,thegradientdynamicsisidenticaltotheforward\none,describingthedynamicsof\nthroughthe\nsynapsetoproduce\n.Finally,thegradientsofthe\nlteroutputsofthe\nthlayerwith\narederived\nintermsofthegradientsoftheneuronoutputsofthepreceding\nlayerthwithrespectto\n.Followingtheaboveobservations,the\ngradientamidstdy-\nnamicswithrespecttoanarbitraryweight\nisdescribed\nintermsofanauxiliarynetwork,\n,calledthesensitivitynet-\nwork[19].Foreach\n,theassociated\nisformedas\nasub-networkoftheoriginalone,startingwiththe\n-thnode\nofthe\n-thlayerandproceedingaheaduntiltheoutputlayer.\n'b'BARBOUNIS\netal.\n:LONG-TERMWINDSPEEDANDPOWERFORECASTINGUSINGLOCALRNNMODELS277\nisfedbythegradientsof\nwithrespectto\nwhileitsoutputisthegradientofthenetworkoutputswithregardto\n.Noticethatthegradientcalculationsarecarriedout,through\nthesensitivitynetworks,inparallelwiththeforwardnetwork,\nfollowingsimilardynamics.Thatis,thegradientsarecalculated\nonanon-linebasis,astheoriginalnetworkrunsintime.Hence,\n\ntheuseofthesensitivitynetworksprovidesatransparenttoolfor\n\ntheevolutionofthenetworkgradients.Itisassumedthatduring\non-linetrainingtheweightsarechangingsmoothly,thatis,they\nremainalmostconstant.Inthatcase,theweightgradientsof\n\nhigherorder\ncanbeobtainedasdelayedversions\nofthegradientswithrespectto\n.V.L\nEARNINGALGORITHMHavingdeterminedthenetworkgradients,weproceedtode-\nvelopingthelearningalgorithmsfortheon-lineupdateofthe\n\ntunableweights.Themostcommonalgorithmusedforon-line\ntrainingofrecurrentnetworksisreal-timerecurrentlearning\n(RTRL)[20],wheretheweightupdateisperformedalongthe\n\nnegativegradientdirection.Nevertheless,thismethodexhibits\n\nslowconvergenceratesbecauseofthesmalllearningratesre-\nquired,andmostoftenbecomestrappedtolocalminima.In\nanattempttoimprovetheperformance,weemployanoptimal\n\nlearningscheme,therecursivepredictionerror(RPE)identi\n-cationalgorithm,withenhancedtrainingqualities.Owingtothe\nsecondorderinformationusedintheupdaterecursions,better-\nconditionedtrainingisaccomplishedcomparedtotheRTRL\n\nmethod.Alongthisdirection,twonovelalgorithmsaresuggestedfor\ntrainingthelocalfeedbackrecurrentnetworksconsideredin\nthispaper,wherethestabilityissueisassuredthroughoutthe\n\nlearningprocess.Firstaglobalschemeisdeveloped,calledthe\n\nglobalRPE(GRPE),whereallweightsaresimultaneouslyup-\ndated.Additionally,tocopewiththeincreasedcomputational\ncomplexityoftheGRPE,wedevisedalocalversionoftheal-\n\ngorithm,calledthedecoupledRPE(DRPE).TheDRPEisde-\n\nrivedbypartitioningtheglobaloptimizationproblemintoaset\nofmanageablesub-problems,attheneuronlevel.Thus,consid-\nerablecomputationalandstoragesavingsaregainedwhilepre-\n\nservinghighaccuracyqualities,similartotheonesoftheGRPE.\nA.TheGRPEAlgorithm\nLetdenoteann-dimensionalcompositevectorincluding\nallsynapticweightsoftherecurrentnetworkunderconsidera-\n\ntion.Weconsideranonlinearrecurrentpredictorofthetype\n(17)wheredescribesthestructureofthenetwork.\n,avector,comprisesthenetwork\nsoutputs,\nisa\nvectorincludingthe\nnetwork\nsinputs\n,and\nrepresentstheinternalstates\ndescribingthenetwork\nsdynamics.\nTherealprocesstobemodeledbythenetwork,denotedas\n,isobtainedby\n(18)whereisthepredictionerrorforaparticularvalueof\n.AccordingtotheGRPEmethod,allnetworkweightsarecon-\n\ntinuouslydeterminedateach\nusingthefollowingrecursion:\n(19)(20)(21)(22)(23)whereistheforgettingfactor,\n.TheGRPEalgo-\nrithmprovidesarecursivewayofminimizingaquadraticcrite-\nrionofthepredictionerrorsusingthestochasticGauss-Newton\n\nsearchmethod[21].Thealgorithmisidenticaltoanonlinear\n\nrecursiveleastsquares(RLS)[22]methodthatminimizesthe\nerrorcriterion\n(24)Furthermore,therecursion(19)\n(23)hasstrongsimilaritiesto\ntheextendedKalman\nlter(EKF)algorithmusedin[23].\nisthegainmatrixcontrollingtheweightupdateand\nisthe\nerrorcovariancematrixthatde\nnethesearchchangesalongthe\nGaussNewtondirection.Assumingthatnopriorinformation\nisavailable,\nisusuallytaken\n,where\nisan\narbitrarylargenumber.\nAkeyissuefortheperformanceofthealgorithmisthematrix\ndenedasfollows:\n(25)whereisa\nmatrixcontainingthepartialderiva-\ntivesofthepredictor\nsmodel,thatis,thenetwork\nsoutputs,\nwithrespecttothetrainableweights\n.........(26)Thesegradientsarecomputedusingthesensitivitynetworks,as\ndescribedinSectionIV.\nin(22)implementsaprojectionmechanismintothe\nstabilityregion.AsdiscussedinSectionIV,thegradientdy-\nnamicsareidenticaltotheforwarddynamicsoftherecurrent\n\nnetwork.Hence,learningstabilityalsoguaranteesstableoper-\n\nationofthenetworkrun.Thenecessaryandsuf\ncientcondi-\ntionforthegradientstotendtozeroisthattheARpartsof\nthesynapticIIR\nltersshouldbestable.Thisdictatesthatthe\nzerosof\ninIIR-MLPandLAF-MLNshould\nliewithintheunitcircle,whichdeterminesthestabilityregionof\n\nthealgorithm.Particularly,fortheDRNNmodel,stabilitysug-\ngeststhattheweightsshouldliewithintheregion\n.Hence,forstabletrainingoftherecurrentnetworks,theGRPE\n\nalgorithmhastobesuppliedwithstabilitymonitoringandapro-\n\njectiontool.Inthispaperwefollowasimpleapproach,where\n'b'278IEEETRANSACTIONSONENERGYCONVERSION,VOL.21,NO.1,MARCH2006\nthecorrectiontermissuccessivelyreduceduntilthenewesti-\nmatesfallwithinthestabilityregion.\ndenotesthelearningratetakingvaluesintherange[0,\n1].Becauseofthegradientcomplexity,itscalesthecorrection\ntermintheweightupdatesandreducestheaggressivenessof\n\nGRPEduringtheinitialtrainingphase.\ndoesnotchangeat\neachtimebutaftereachpassthroughthedataoftheepoch(it-\neration).Initially,\ntakesarelativelysmallvalue,i.e.,0.01,\nthusavoidingbadestimatestobeobtained.Inthefollowingit-\n\nerations,astrainingproceeds,\nisraisedtounityfollowing\nauser-de\nnedpro\nleandtheGRPEtakesfullyover.\nB.TheDRPEAlgorithm\nTheDRPEisalocallearningschemethatisachievedbydi-\nvidingthenetworkweighsinto\ngroups,attheneuronlevel.\nEachgroupconsistsoftheMAandARweights,\nandofthesynapsespointingtoaneuron.Letusconsiderthe\n-thneuron(group)describedbya\nweightvector\n,so\nthat.Theeffectofthe\n-thneuron\nonthenetwork\nsoutputs,\nislocallygiven\nbythegradientmatrix\n(27)Apparently,theabovegradientisthe\n-thcolumnoftheglobal\nmatrixin(26).Consideralsothecovariancematrix\noftheGRPEinblock-diagonalform\n(28)Owingtotheaboveweightgrouping,GRPEisdecomposedinto\nasetofdecoupledalgorithmswheretheweightvector\n,ofeachgroupisindependentlyupdatedateachtime\nfollowingarecursionsimilartotheonein(19)\n(23)(29)(30)(31)(32)(33)Therecursionofeachgroupusestheassociatedgradient\nmatrices,and\n.Additionally,eachneuron\nrequiresthestorageofanindividualcovariancematrix\nofsize.C.AlgorithmicComplexity\nAlgorithmiccomplexityinvolvesthecomputationalcost\nandthememorydemandsofaparticularlearningalgorithm.\nThisloadismeasuredintermsofthenumberofadditionsand\nmultiplicationsrequiredtotrainanetworkforonetime-step.\n\nForsimplicity,letusconsideratwo-layeredrecurrentnetwork\n\nwithinputs,onehiddenlayerwith\nneurons,and\nneuronsintheoutputlayer.Furthermore,let\ndenotethenumberofweightspertainingtothegroupofaneuron\n\natthe\nthlayer,\n.AsregardstheIIR-MLP,wehave\nFig.4.Windspeeddistributionsofthefournodepredictionsandtheactual\nwindattheRokas\npark.whilefortheLAF-MLN\nwehave\n.Thetotalnumber\nofweightsincludedinthenetworkis\n.Computationalanalysisshowsthatthecomputationalloadof\n\ntheGRPEis\nwhilethestoragerequirementsare\n.Additionally,thecomputationalandstoragecostofthe\nDRPEis\nand,respectively.Since\n,itcanbeseen\nthatthecomputationalburdenofDRPEisconsiderablysmaller\n\ncomparedtotheGRPE.\nVI.I\nNPUTSELECTIONAsmentionedbefore,therecurrentneuralnetworkswere\ntrainedandevaluatedusing72-h-aheadmeteorologicalpredic-\ntionsatfournodeslocatedinthevicinityofthewindparkof\nRokas,Crete.Althoughwindspeed(inms\n),direction(in\ndegrees),pressure,andtemperaturepredictionsaregivenby\n\ntheatmosphericmodelingsystemofSKIRON,onlythereal\nvaluesofthewindspeedandpoweraremeasuredatthepark\nsite.Finally,themeteorological\npredictionset\nincludesa\nlinearinterpolationofthenodepredictionsderivedfortheexact\n\npositionoftheW/F.\nSelectionofthemodel\nsinputsisthe\nrststageinmodel\nbuilding.Thisproblemhastobeproperlyaddressedhavinga\ngreateffectontheperformanceoftheresultingforecastmodels.\n\nConsideringthepoolofallavailablecandidateinputs,those\n\nvariablesshouldbeselectedexhibitingasigni\ncantdegreeof\ncorrelationwithregardtothemodel\nsoutputstobeforecasted.\nThedecisionastowhichvariableswillbeincludedasmodel\nsinputsismadeonthebasisoftwocriteria:comparisonofthe\n\nwindspeeddistributionsandthedegreeofcross-correlationbe-\ntweenthenodes\nandactualwindvalues.FortheRokas\npark,thesecriteriaareshowninFig.4andTableI,respectively.Fig.4\n\nshowsthatthe(N,E,W)nodeshavesimilarwindspeedpro\nlesascomparedtotheactualoneatthepark,coveringtheentire\nspeedrange.Bycontrast,theSouthernnodefollowsadifferent\ndistributionwithitsaveragespeedbeingrelativelylow.More-\n\nover,TableIindicatesthattheSouthernnodehasthesmallest\n'b'BARBOUNIS\netal.\n:LONG-TERMWINDSPEEDANDPOWERFORECASTINGUSINGLOCALRNNMODELS279\nTABLEI\nAVERAGE\nNODEPREDICTIONSANDCROSS\n-CORRELATIONSOF\nTHEMWITHTHEREALVALUESOF\nWINDSPEEDAND\nPOWERATTHE\nROKASPARKdegreeofcross-correlationwithregardtothewindspeedand\nespeciallythewindpower,withtherestofthenodesexhibiting\n\nanadequatecorrelationofalmostequivalentlevel.Thisisex-\nplainedbythefactthat,whilethe(N,E,W)nodesareplaced\nonthesurfaceofthesea,theSouthernnodeislocatedonthe\n\nland,possiblyonaleewardposition(seeFig.1).Therefore,the\n\nSouthernnodeisdiscardedfrombeingusedasforecastmodel\ninput.Theinputdatabasedoninterpolatedvalueswerediscarded\nbecausethelinearinterpolationisaveryroughtoolindeedto\n\ndescribesuchacomplexnonlinearsystemastheoneundercon-\nsideration.Datamanipulationjusti\nestheabovedecision.Fi-\nnally,afterextensiveexperimentation,itwasfoundthatinclu-\n\nsionofthetemperatureandtheatmosphericpressureasinputs\n\ndidnotofferimprovedperformanceoftheresultingmodels.\nOnthecontrary,thepresenceoftwomoreinputswasactually\nslowingdownthelearningprocess.Therefore,thesevariables\n\narealsonotincludedintheinputset.\nInviewoftheabovediscussion,sixmajorinputsareem-\nployedasinputstotheforecastmodels,comprisingthewind\nspeedsanddirectionsoftheN,E,andWnodes.Beforetraining,\n\nthedatawerenormalizedwithintherange\n.Asforthe\nwinddirections,inorderforthenetworkstodiscriminatebe-\ntweenvalueslocatedaroundthecriticalpoint0or360degrees\nandestablishthecorrectassociations,theywere\nrstbiased,that\nis,thedegreeaxiswasshifted.Particularly,thebiaswassetto\ndegrees,fortheRokas\npark,avaluedecidedbyobserving\nthedistributionofthedirectionsinthedata.\nConcluding,ascanbeseenfromFig.2,therealvaluesof\nwindspeedandpowerforadaytimeperiod,involvenodepre-\n\ndictionsattheinputsideobtainedatthecurrent,one-dayand\ntwodaysbefore.Therefore,todiscriminatebetweenthethree\ndifferentnode-predictionscorrespondingtothesameoutput\n\ndata,wehaveintroducedanadditionalinput,theinputindex\n\ndenotedas\nandtakingvalues\n,and\n,respectively.\nThemodel\nsinputvectorcontainsseveninputtermsintotal,\n,andisformulatedasfollows:\nNoticethatonlythecurrentvaluesofthewindspeedsand\ndirectionsareusedasinputstotherecurrentmodelsateach\n,leadingtoparsimoniousforecastmodelswithasmallnumberof\nparameters.Itshouldbementionedthatatthebeginningofaday\nonlythemeteorologicalnodepredictionsaregiven,whilethe\nactualwindandpowervaluesareunknown(Fig.2).Neverthe-\n\nless,becauseoftheMAandtheARpartsofthesynaptic\nlters,theoutputestimatesarerecurrentlyderivedusingpastvaluesof\nFig.5.Selectionofthetrainingandcheckingdatapatterns.Eachsquare\ndenotesa24-hourbatch.\ntheinputs,aswellasthenetwork\nsoutputs(estimates)atpre-\nvioustime-steps\nTheaboveformulationindicatesthattherecurrentmodelsful-\nllalltherequirementsimposedbyanef\ncientforecastmodel,\nassuggestedby(2).Ourmethodcombinesthetime-seriesap-\nproach[4],[5],andtheatmosphericmodeling,simultaneously.\nOntheotherhand,intheabsenceoffuturetargetdata,whencon-\n\nventionalstatic(memoryless)NNsareemployedformulti-step\n\naheadprediction,weusuallyfollowtwoapproaches.According\ntothe\nrstapproach,aseparatemodelisdeveloped,providing\nthewindforecastsateachtime-stepahead.Thesecondapproach\n\nconsistsoffeedingbackthemodel\nsoutputestimatesasexplicit\ninputsthroughtapped-delaylines.Ineithercase,wearefaced\nwithtwodrawbacks.First,theorderofthepastvaluestobein-\ntroducedtothenetworkisunknowninpractice.Secondly,the\n\ninclusionofadditionalinputsaggravatestheparametriccom-\n\nplexityofthemodels.\nAfterhavingdeterminedthemodelinputs,thetrainingand\ntestingdatapatternsarecreated,asshowninFig.5.Thepatterns\n\narearrangedindatabatchescontaining72hourlynodepredic-\n\ntions(inputs),alongwiththe72respectivevaluesofwindspeed\norpowermeasurements.Thedatabatchesareselectedinsuch\nawaysothatneitherthetrainingnorthecheckingdatasetsare\n\noverlapping,thusguaranteeingcompleteindependencebetween\n\nthesetwosets.Finally,inordertoensurecontinuityofthenet-\nwork\nsstateswiththeonesofthenext72-hourdatabatch,we\nintroducedinfrontofeachbatchthe24-hourdatapairsofthe\n\npreviousday.Theseextra24harenotusedfortraining;theyare\n\nsimplypassedthroughthenetworktodeveloptheproperstates.\nVII.S\nIMULATION\nRESULTS\nTheavailabledataaredividedintotrainingandachecking\ndataset,composedof3264and960patterns,respectively.The\ntrainingdatasetisusedfortrainingoftherecurrentmodels\n\nusingthelearningalgorithmssuggestedinSectionV.\nMoreover,thecheckingdatasetisusedtoevaluatethefore-\ncastperformanceoftheresultingmodels.Foreachrecurrent\n'b'280IEEETRANSACTIONSONENERGYCONVERSION,VOL.21,NO.1,MARCH2006\nnetworktype,twoseparateforecastmodelsaredeveloped,pro-\nvidingatthebeginningofeachday,72-h-aheadforecastsofthe\n\nwindspeedandpoweratthepark.On-linetrainingiscarriedout\nonthedatabatchesfor400epochs.\nIIR-MLPnetworkswithtwohiddenlayersandsevenneurons\nperlayerareselected.BothMAandARpartsoforder3are\n\nconsideredfortheIIRsynaptic\nltersinthehiddenneurons.\nEspeciallyfortheoutputneuron,anARpartoforder5ischosen.\nThisallowsthemodeltolearnmoreef\ncientlythedependenceof\nthecurrentoutputwithregardtoitspast.Structureswithsimilar\n\nnumberofparametersarechosenfortheothertworecurrent\n\nnetworksused.Particularly,anetworkwithtwohiddenlayers\nandeightneuronsperlayerisconsideredfortheLAF-MLN.The\norderoftheMApartsissetto4whiletheARpartsarethesameas\n\ninthecaseofIIR-MLPmodels.Finally,aDRNNmodelwithone\nhiddenlayercomposedof32self-recurrentneuronsisselected.\nInordertovalidateourinputselection,weconsideredthree\nscenarios(models),inwhichonlytheone(W),two(N,W),or\n\nthree(N,W,E)mostcorrelatednodesareusedasinputstothe\nnetworks.Hence,therespectivenetworkshavethree,\nve,and\nseveninputs,respectively:theselectednodes\npredictionsofthe\nspeedanddirection,andtheinputindex.\nThenetworkweights\narerandomlyselectedinitially\nintherange\nwhile,involvedintheARparts\nofthesynaptic\nlters,areinitializedsothattherootsofthere-\nsultingpolynomial\nlieinsidetheunitcircle,\nasrequiredforstableoperationofthelearningalgorithm.Asan\nactivationfunction,thehyperbolictangent,\n,isusedinourexperiments.Inordertoavoidexcessiveerrors\n\nduringthetrainingstagecausedbybadinitialestimatesofthe\nweights,thelearningrate\nwassetinitiallytoasmallvalue,\n.Inthefollowing,aslearningproceeds,\nisgrad-\nuallyincreasedtounity,followingtheformula\n,where\nissetto0.8.Thecorrelationmatrix\nisinitializedas\n,where\nistheidentitymatrix\nwithsizeequaltotheoneoftheweightvector.\nFinally,duringlearning,stabilitymonitoringoftheRPEal-\ngorithmsiscontinuouslyperformed.Assumingthatthecurrent\nestimateslieoutsidethestabilityregion,theprojectionmech-\nanismisactivated.Accordingly,thecorrectiontermissucces-\n\nsivelymultipliedbyafactorof0.2untiltherevisedweightes-\n\ntimatesobtainedful\nllthestabilityconditionsforeachneuron\nandnetworktype.\nInordertojustifythebene\ntgainedbyusinglocalrecurrent\nNNs,apartfromtheIIR-MLP,theLAF-MLNandtheDRNN,\n\ntwoadditionalstaticmodelsareexaminedforcomparison,\nnamely,astaticMLPandaFIRneuralnetworkwherethe\nconnectionweightsarerealizedbylinearFIR\nlters[14].The\nFIR-NNsarefunctionallyequivalenttostaticMLPs,although\nwithbettermodelingcapabilitiessinceduetotheFIRsynapses,\npastvaluesoftheinputsarealsotakenintoconsideration.The\n\nnetworkshadagainthree,\nve,orseveninputs,dependingon\nthenodepredictionsbeingused.\nToestablishafaircomparisonbasis,thestructureofthecom-\npetingnetworksisselectedsothattheycontainapproximately\n\nthesamenumberofparametersastherecurrentnetworks.Par-\n\nticularly,astaticMLPischosenwithtwohiddenlayersand20\nTABLEII\nMAEANDRMSEFOR\nWINDPOWERAND\nSPEEDFORECASTSOBTAINEDBY\nTHREEMODELTYPESINCLUDINGTHREE(N,W,E),T\nWO(N,W),\nANDONE(W)I\nNPUTNODES,ANDTRAINEDBYTHE\nGRPEA\nLGORITHMTABLEIII\nMAEANDRMSEFOR\nWINDPOWERAND\nSPEEDFORECASTSOBTAINEDBY\nTHREEMODELTYPESINCLUDINGTHREE(N,W,E),T\nWO(N,W),\nANDONE(W)I\nNPUTNODES,ANDTRAINEDBYTHE\nDRPEA\nLGORITHMneuronsperlayer,andaFIR-NNwithtwohiddenlayersand\nlinearFIR\nltersofsixthorder.Furthermore,aftertheneces-\nsarymodi\ncationstothecomputationofthenetworkgradients,\nallforecastmodelsaretrainedbymeansofthesuggestedGRPE\n\nandDRPEalgorithms.Undertheseconditions,themodelsare\n\nevaluatedintermsofrepresentationpowerandtheircapabilities\ntoproduceef\ncientmultistageforecasts.Nevertheless,anaddi-\ntionalcaseisconsideredwherethestaticMLPistrainedusing\n\ntheconventionalBPalgorithm.\nBasedonthedataavailablefortheRokas\npark,foreach\ninputcase(3,2,1inputnodes)andnetworktype,anexhaustive\n\nsetofexperimentsiscarriedout.Asameasuretoevaluatethe\nperformanceoftheforecastmodelsthemeanabsolute(MAE)\nandtherootmeansquareerror(rmse)areused.Thebestresults\n\nachievedforeachcasearecitedinTablesIIandIII,wherethe\n\nmodelsaretrainedbyGRPEandtheDRPE,respectively.\n'b'BARBOUNIS\netal.\n:LONG-TERMWINDSPEEDANDPOWERFORECASTINGUSINGLOCALRNNMODELS281\nFig.6.Powerforecasterrors(MAE)forahorizonof72hobtainedbythe\nIIR-MLP,LAF-MLN,DRNN,andthestaticMLP(trainedbyBP)withthree\n\ninputnodes,alongwiththeerrorsofthepersistentmethod.\nItcanbeseenthatthewindspeedandpowerperformance\nisimprovedwhenadditionalnodesareincludedasinputs.The\n\nbestresultsareattainedforeachnetworktypewhenthecom-\n\npletemodelsareconsidered,includingallthreenodes(N,E,W).\nSincethemeteorologicalpredictionsatthethreemostcorrelated\nnodescontainalmostanequivalentamountofinformation,the\n\naboveobservationveri\nesexperimentallyourinputselection.\nForthemodelstrainedbyGRPE(TableII)itcanbeseen\nthattherecurrentforecastmodelsexhibitconsistentlybetter\nperformancecomparedtothestaticmodels,FIR-NNandthe\n\nstaticMLP,thusjustifyingtheiruseformultiple-stepwind\n\nforecasting.Owingtotherichnessofthenetworkarchitecture,\nIIR-MLPshowsthebestperformance,outperformingthe\nLAF-MLNandtheDRNNmodelsinallcases.Particularly,\n\nIIR-MLPprovidesforthewindpowerandspeedaMAE(rmse)\n\nof1.2117MW(1.5263)and1.9755ms\n(2.7211).Regarding\nthepowerforecasts,itoutperformstheFIR-NNandthestatic\nMLPby11.82%and12.7%intermsofMAE.Furthermore,\n\nforthespeedforecasts,animprovementof7.12%and9.44%is\n\nobtained,respectively.NoticethatthestaticmodelsinTableII\naretrainedusinganenhancedlearningscheme,theGRPEal-\ngorithm.AssumingthattheMLPistrainedbytheconventional\n\nBPmethod,aconsiderablylargerimprovementisachieved.In\nthatcase,theIIR-MLPoutperformsthestaticMLPby24.94%\nand21.10%forthewindpowerandspeed,respectively.\nFig.6depictstheforecastingerrors(MAE)ofthewind\npower,forthecompletemodelsofthethreerecurrentnetworks\ntrainedbyGRPEandthestaticMLP,alongwiththeerrors\nobtainedbythepersistentmethod.Fig.7showsthepercentage\n\nimprovementinwindpowerforecastingofeachnetworkmodel\n\noverthepersistentmethod,onthebasisofMAEcriterion.In\nviewoftheabove\ngures,thefollowingobservationsarein\norder.\nThepersistenterrorisalmostmonotonicallyincreasing\nwhenlargertime-stepsareconsideredinthefuture.This\nbehavioriscontinuedforthe\nrst50stepsahead,settling\ntoahigherrorlevelfortherestofthetimehorizon.Nev-\n\nertheless,goodestimatesareobtainedforthe\nrstfew\ntime-stepsasexpected.Thisisthetimerange(upto6\n8Fig.7.Percentageimprovementoverthepersistentmethodofthepower\nforecastsachievedbyIIR-MLP,LAF-MLN,DRNN,andthestaticMLP\n\n(trainedbyBP)withthreeinputnodes.\nFig.8.Speedforecasterrors(MAE)forahorizonof72hobtainedbythe\nIIR-MLP,theLAF-MLN,theDRNN,andthestaticMLP(trainedbyBP)with\nthreeinputnodes,alongwiththeerrorsofthepersistentmethod.\nhahead)whereitissuggestedtouseshort-termmodels\n(oracouplingofthemwithlong-termmodels)inorderto\noutperformpersistentforecast.\nComparedtothestaticMLP,therecurrentmodelsexhibit,\nconsistently,thebestforecastingerrorsforalltime-steps\nahead;thebestperformanceisshownbyIIR-MLP.In\ncontrasttothepersistentmethod,theerrorsmoveinthe\n\nvicinityoftheMAEvalue(1.2117MW)fortheentire\n\ntimehorizon.Thisindicatesthecapabilityoftherecurrent\nmodelstoproducerobustmulti-stepaheadpredictions.\nAsaresult,considerableimprovementisattainedover\n\nthepersistentforecasts.Particularly,anaverageimprove-\n\nmentofover50%isobtainedfortime-stepslargerthat\n20,althoughsmallerimprovementisshownforshorter\ntimelags.Similarobservationsarealsovalidforthewind\n\nspeed,asshowninFigs.8and9wheretheforecasting\nerrorsandimprovementoverthepersistentmethodare\ngiven.\nTheabilityofthemodeltolearntheprocessdynamicsand\nprovideef\ncientforecastsisdemonstratedinFig.10.Atypical\n72-hcurvebelongingtothecheckingdatasetisconsidered,\n'b'282IEEETRANSACTIONSONENERGYCONVERSION,VOL.21,NO.1,MARCH2006\nFig.9.Percentageimprovementoverthepersistentmethodofthespeed\nforecastsachievedbyIIR-MLP,theLAF-MLN,theDRNN,andthestaticMLP\n(trainedbyBP)withthreeinputnodes.\nFig.10.Realwindpower(solidline)andpredictedwindpower(dashedline)\n\ninMW,foratypicalpowerforecastcurveofthecheckingdataset.\nincludingtheactualvaluesofthewindpowerattheparkand\ntheoutputsofanIIR-MLPmodel.Asshown,theforecastsare\n\ngood,followingthetrendsoftherealpowerclosely.Similarly,in\n\nFig.11atypicalcurveisplottedincludingwindspeedforecasts\nontheparksite,withthenodes\nrespectiveforecastsprovided\nbytheSKIRONsystem.\nFromtheresultsshowninTableIIIitcanbeconcludedthat\ntheforecastmodelstrainedbythesimpli\nedlocalalgorithm,the\nDRPE,exhibitslightlyinferiorperformanceascontrastedtothe\nonesobtainedbytheGRPE(TableII).Noticehowever,thatas\n\nrevealedfromthecomplexityanalysis,DRPEhasconsiderably\n\nlessrequirementsthanGRPE,intermsofcomputationalcost\nandstorageneeds.Nevertheless,theoverallpictureremainsthe\nsame,thatis,therecurrentmodelsoutperformthestaticforecast\n\nmodels,withthebestresultsachievedbytheIIR-MLP.\nVIII.C\nONCLUSIONThreelocalrecurrentneuralnetworksareemployedinthis\npaper,providing72time-stepsaheadforecastsofthewind\n\nspeedandpowerattheRokas\nwindparkontheGreekislandof\nCrete.Forecastingisbasedonmeteorologicaldatagivenatfour\nFig.11.Realwindspeed(solidline)andpredictedwindspeed(dashedline)\ninmeterspersecond(m/s),foratypicalspeedforecastcurveofthechecking\ndataset,alongwiththerespectivepredictionsforthreesurroundingnodes.\nnodesnearbytheparksite.Twonovellearningalgorithmsare\nintroducedforthetrainingoftherecurrentforecastmodels,the\n\nGRPEandtheDRPE,thathaveconsiderablysmallercomputa-\n\ntionalandstoragerequirements.Extensiveexperimentationand\nmodelcomparisonrevealstheeffectivenessofthesuggested\nlearningmethods.Moreover,itisshownthattherecurrent\n\nforecastmodelsoutperformthestaticrivalsintermsofforecast\n\nerrorsandtheimprovementgainedoverthepersistentmethod.\nAPPENDIXInviewofthemultilayerstructureoftheIIR-MLP,wecan\ndistinguishthreedistinctcasesasdescribedbelow.\nCase1:\nGradientsoftheneuron\nsoutput\nwithrespect\ntosynapticweights\n.First,from(2)and(3),wehave\n(A.1)Applyingtheorderedderivativesforwardchainrulewithrespect\ntos,we\nnallyget\n(A.2)andfollowinganadaptive\nlternotationas\n(A.3)whereanddenoteanordinaryandanordered\nderivative.Similarly,differentiationwithrespectto\nsleadsto\nthefollowingrelations:\n(A.4)(A.5)'b'BARBOUNIS\netal.\n:LONG-TERMWINDSPEEDANDPOWERFORECASTINGUSINGLOCALRNNMODELS283\nCase2:\nGradientsoftheneuron\nsoutput\nofthe\nthlayerwithrespecttosynapticweights\nofthe\nthlayer.\nUsingthenetwork\nsarchitectureandtheforwardchainfor-\nmula,weget\n(A.6)(A.7)Therequiredgradientsarederivedthrough\n(A.8)Case3:\nGradientsoftheneuron\nsoutput\nofthe\nth,layerwithrespecttosynapticweights\nofthethlayer.\nBasedonthenetwork\nsstructure,wehave\n(A.9)Theaboveequationcanberewrittenas\n(A.10)Therequiredderivativesfortheneuronoutputsare\n(A.11)where(A.12)ACKNOWLEDGMENT\nSKIRONisaweatherforecastingsysteminitiallydeveloped\nfortheHellenicMeteorologicalServicebasedontheEta/NCEP\nmodel.Themeteorologicalnumericalpredictionsarenowpro-\n\nducedonadailybasisbytheAtmosphericModelingand\nWeatherForecastingGroup(AM&WFG)oftheUniversityof\nAthens,Athens,Greece[24].Theauthorsespeciallywishto\n\nthankProf.G.KallosandDr.P.Katsafadosfortheircollabora-\ntion.ActualdatafromtheRokasW/FatCreteareprovidedby\nPublicPowerCorporationofGreece.Alldataweregathered\n\nandgiventotheauthorsundertheframeoftheMORE-CARE\n\nprojectsupportedbytheEuropeanCommission.\nREFERENCES[1]E.A.Bossanyi,\nShort-termwindpredictionusingKalman\nlters,Wind\nEng.\n,vol.9,no.1,pp.1\n8,1985.\n[2]J.O.G.TandeandL.Landberg,\nA10sec.forecastofwindturbine\noutputwithneuralnetworks,\ninProc.4thEuropeanWindEnergyConf.\n(EWEC93),Lbeck-Travem\nnde,Germany,1993,pp.747\n777.[3]G.C.ContaxisandJ.Kabouris,\nShort-termschedulinginwind/diesel\nautonomoussystem,\nIEEETrans.PowerSyst.\n,vol.6,no.3,pp.\n11611167,Aug.1991.\n[4]G.N.Kariniotakis,G.S.Stavrakakis,andE.F.Nogaret,\nWindpower\nforecastingusingadvancedneuralnetworksmodels,\nIEEETrans.En-\nergyConvers.\n,vol.11,no.4,pp.762\n767,Dec.1996.\n[5]A.MoreandM.C.Deo,\nForecastingwindwithneuralnetworks,\nMa-rineStructures\n,vol.16,pp.35\n49,2003.\n[6]L.LandbergandS.J.Watson,\nShort-termpredictionoflocalwindcon-\nditions,Boundary-LayerMeteorol.\n,vol.70,p.171,1994.\n[7]L.Landberg,A.Joensen,G.Giebel,H.Madsen,andT.S.Nielsen,\nShort-termpredictiontowardthe21stcentury,\ninProc.BritishWind\nEnergyAssociation\n,vol.21,Cambridge,U.K.,1999.\n[8]L.LandbergandA.Joensen,\nAmodeltopredicttheoutputfromwind\nfarms\nAnupdate,\ninProc.BritishWindEnergyAssociation\n,vol.20,\nCardiff,Wales,U.K.,1998.\n[9]S.J.Watson,G.Giebel,andA.Joensen,\nTheeconomicvalueofaccu-\nratewindpowerforecastingtoutilities,\ninProc.EWEC99\n,Nice,France,\n1999,pp.1109\n1012.[10]T.S.NielsenandH.Madsen,\nExperienceswithstatisticalmethods\nforwindpowerprediction,\ninProc.EWEC99\n,Nice,France,1999,pp.\n10661069.[11]E.Akylas,\nInvestigationoftheeffectsofwindspeedforecastsandeco-\nnomicEvaluationoftheincreasedpenetrationofwindenergyforthe\n\nislandofCrete,\ninProc.EWEC99\n,Nice,France,1999,pp.1074\n1077.[12]G.Kariniotakis,D.Mayer,J.A.Halliday,A.G.Dutton,A.D.Irving,R.\nA.Brownsword,P.S.Dokopoulos,andM.C.Alexiadis,\nLoad,wind,\nandhydropowerforecastingfunctionsofthemore-careEMSsystem,\ninProc.MedPower2002\n,Athens,Greece,Nov.2002.\n[13]A.C.TsoiandA.D.Back,\nLocallyrecurrentgloballyfeedforwardnet-\nworks:Acriticalreviewofarchitectures,\nIEEETrans.NeuralNetw.\n,vol.5,no.3,pp.229\n239,May1994.\n[14]E.A.Wan,\nTemporalbackpropagationforFIRneuralnetworks,\ninProc.Int.JointConf.NeuralNetworks,\n,vol.1,1990,pp.575\n580.[15]S.Haykin,\nNeuralNetworks:AComprehensiveFoundation\n.New\nYork:IEEEPress,1994.\n[16]P.Frasconi,M.Gori,andG.Soda,\nLocalfeedbackmultilayerednet-\nworks,\nNeuralComput.\n,vol.4,pp.120\n130,1992.\n[17]C.-C.KuandK.Y.Lee,\nDiagonalrecurrentneuralnetworksfordy-\nnamicsystemscontrol,\nIEEETrans.NeuralNetw.\n,vol.6,no.1,pp.\n144156,Jan.1995.\n[18]P.J.Werbos,\nBeyondRegression:NewToolsforPredictionandAnal-\nysisintheBehavioralSciences,\nPh.D.dissertation,CommitteeonAppl.\nMath.,HarvardUniv.,Cambridge,MA,1974.\n[19]E.A.WanandF.Beaufays,\nDiagrammaticderivationofgradientalgo-\nrithmsforneuralnetworks,\nNeuralComput.\n,vol.8,pp.182\n201,1996.\n[20]R.J.WilliamsandJ.Peng,\nAnef\ncientgradient-basedalgorithmfor\non-linetrainingofrecurrentnetworkstructures,\nNeuralComput.\n,vol.\n2,pp.490\n501,1990.\n[21]L.LjungandT.S\nderstrm,TheoryandPracticeofRecursiveIdenti-\ncation,Cambridge,U.K.:MITPress,1983.\n[22]S.Shah,F.Palmieri,andM.Datum,\nOptimallteringalgorithmsfor\nfastlearninginfeedforwardneuralnetworks,\nNeuralNetw.\n,vol.5,pp.\n779787,1992.\n[23]G.V.PuskoriusandL.A.Feldkamp,\nNeurocontrolofnonlineardy-\nnamicalsystemswithKalman\nltertrainedrecurrentnetworks,\nIEEETrans.NeuralNetw.\n,vol.5,no.2,pp.279\n297,Mar.1994.\n[24]G.Kallos,S.Nickovic,A.Papadopoulos,andP.Katsafados,\nTheSK-\nIRONforecastingsystemanditscapabilitytopredictextremeweather\n\neventsintheMediterranean,\ninProc.7thInt.Symp.NaturalandMan-\nMadeHazards(HAZARDS-98)\n,Chania,Greece,May1998.\n'b'284IEEETRANSACTIONSONENERGYCONVERSION,VOL.21,NO.1,MARCH2006\nThanasisG.Barbounis\nwasborninLamia,Greece,\nin1977.Hegraduatedinelectricalengineeringin\n1999fromtheAristotleUniversityofThessaloniki,\nThessaloniki,Greece,whereheiscurrentlypursuing\nthePh.D.degree.\nHisresearchinterestsincludearti\ncialneuralnet-\nworks,fuzzylogicsystems,andmodelingofnon-\nlinearsystems.\nJohnB.Theocharis\n(M90)graduatedinelectrical\nengineeringin1980andreceivedthePh.D.degreein\n1985,bothfromtheAristotleUniversityofThessa-\nloniki,Thessaloniki,Greece.\nHeiscurrentlyanAssociateProfessorintheDe-\npartmentofElectronicandComputerEngineering,\n\nAristotleUniversityofThessaloniki.Hisresearchac-\ntivitiesincludefuzzysystems,neuralnetworks,adap-\ntivecontrol,andmodelingofcomplexnonlinearsys-\ntems.MinasC.Alexiadis\nwasborninThessaloniki,\nGreece,inJuly1969.HereceivedtheDipl.Eng.\ndegreein1994andthePh.D.degreein2003,both\nfromtheDepartmentofElectricalandComputer\nEngineering,AristotleUniversityofThessaloniki,\nThessaloniki,Greece.\nHisresearchinterestsincluderenewableenergy\nsourcesandarti\ncialintelligenceapplicationsin\npowersystems.\nPetrosS.Dokopoulos\n(M77)wasborninAthens,\nGreece,inSeptember1939.HereceivedtheDipl.\nEng.degreefromtheTechnicalUniversityofAthens,\nAthens,Greece,in1962andthePh.D.degreefrom\ntheUniversityofBrunswick,Brunswick,Germany,\nin1967.\nHewaswiththeLaboratoryforHighVoltage\nandTransmission,UniversityofBrunswick\n(19621967),theNuclearResearchCenteratJulich,\nJulich,Germany(1967\n1974),andtheJointEuro-\npeanTorus(1974\n1978).Since1978,hehasbeena\nFullPofessorattheDepartmentofElectricalEngineering,AristotleUniversity\nofThessaloniki.HehasworkedasaConsultanttoBrownBoveriandCie,\nMannheim,Germany,toSiemens,Erlagen,Germany,toPublicPowerCorpo-\nration,Greece,andtoNationalTelecommunicationOrganization,Greece.His\nscienticeldsofinterestaredielectrics,powerswitches,generators,power\ncables,alternativeenergysources,transmission,anddistributionandfusion.\n'