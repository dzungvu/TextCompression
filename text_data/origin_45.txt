b'LearningDeepNeuralNetworksforVehicleRe-IDwith\nVisual-spatio-temporalPathProposals\nYantaoShen\n1\nTongXiao\n1\nHongshengLi\n1\n;\n\nShuaiYi\n2\nXiaogangWang\n1\n;\n\n1\nDepartmentofElectronicEngineering,TheChineseUniversityofHongKong\n2\nSenseTimeGroupLimited\n1\nf\nytshen,xiaotong,hsli,xgwang\ng\n@ee.cuhk.edu.hk2\nyishuai@sensetime.comAbstractVehiclerisanimportantproblemand\nhasmanyapplicationsinvideosurveillanceandintelligent\n\ntransportation.Itgainsincreasingattentionbecauseof\n\ntherecentadvancesofpersonrtechniques.\n\nHowever,unlikepersonrthevisualdiffer-\n\nencesbetweenpairsofvehicleimagesareusuallysub-\n\ntleandevenchallengingforhumanstodistinguish.In-\n\ncorporatingadditionalspatio-temporalinformationisvi-\n\ntalforsolvingthechallengingrtask.Exist-\n\ningvehiclermethodsignoredorusedover-\n\nmodelsforthespatio-temporalrelationsbetween\n\nvehicleimages.Inthispaper,weproposeatwo-stage\n\nframeworkthatincorporatescomplexspatio-temporalin-\n\nformationforeffectivelyregularizingther\n\nresults.Givenapairofvehicleimageswiththeirspatio-\n\ntemporalinformation,acandidatevisual-spatio-temporal\n\npathisstgeneratedbyachainMRFmodelwitha\n\ndeeplylearnedpotentialfunction,whereeachvisual-spatio-\n\ntemporalstatecorrespondstoanactualvehicleimagewith\n\nitsspatio-temporalinformation.ASiamese-CNN+Path-\n\nLSTMmodeltakesthecandidatepathaswellasthepair-\n\nwisequeriestogeneratetheirsimilarityscore.Extensive\n\nexperimentsandanalysisshowtheeffectivenessofourpro-\n\nposedmethodandindividualcomponents.\n\n1.Introduction\nVehiclerecognitionisanactiveresearchincom-\nputervision,whichincludesapplicationssuchasvehicle\n\n[\n42,35,26],vehicledetection[\n31],andve-\nhiclesegmentation[\n30].Vehiclere(re-ID),\nwhichaimsatdeterminingwhethertwoimagesaretaken\n\nfromthesamevehicle,hasrecentlydrawnincreasingatten-\n\ntionfromtheresearchcommunity[\n10,45,27].Ithasim-\nportantapplicationsinvideosurveillance,publicsecurity,\n\nandintelligenttransportation.\nDerivedfrompersonalgorithms[\n1,3,\nCorrespondingauthors\n!"#\n!"#$%&"\'()*\'+,\n-$."*\',/*01\n!"#$%&"\'()*\'+,\n-$."*\',/*/+\n!!"#$%&"\'()*\'+,\n-$."*\',/*+2\n(a)Similarvehicleobservedat\nB\n!"#!"#$%&"\'()*+,\n-$."*\n/0*12!"#$%&"\'()*+2\n-$."*\n/0*,0!(b)Nosimilarvehicleobservedat\nB\nFigure1:Illustrationofspatio-temporalpathinformation\n\nasimportantpriorinformationforvehicle\n\n(a)ForvehicleswiththesameIDat\nAandC\n,ithastobe\nobservedat\nB\n.(b)Ifavehiclewithsimilarappearanceand\npropertimeisnotobservedat\nB\n,vehiclesat\nAandC\nareunlikelytobethesamevehicle.\n12],mostexistingvehicleapproaches[\n10,45,27]relyonlyonappearanceinformation.Suchaprob-\nlemsettingisparticularlychallenging,sincedifferentcars\n\ncouldhaveverysimilarcolorsandshapes,especiallyfor\n\nthosebelongingtothesamemanufacturer.Subtlecuesfor\n\nsuchaslicenseplatesandspecialdecora-\n\ntions,mightbeunavailableduetonon-frontalcameraview-\n\npoints,lowresolution,orpoorilluminationofthevehicle\n\nimages.Therefore,itisnotpracticaltouseonlyappearance\n\ninformationforaccuratevehicle\nTocopewithsuchlimitations,therearepreliminaryat-\ntemptsonincorporatingspatio-temporalinformationofthe\n\ninputimagesformoreaccuratevehicleIn\n\n[28],Liu\netal\n.utilizedthetimeandgeo-locationinforma-\ntionforeachvehicleimage.Aspatio-temporalafis\n\ncalculatedbetweeneverypairofimages.However,itfavors\n11900\n'b'pairsofimagesthatareclosetoeachotherinbothspatial\n\nandtemporaldomains.Suchaspatio-temporalregulariza-\n\ntionisobviouslyoverMoreimportantly,vital\n\nspatio-temporalpathinformationofthevehiclesprovided\n\nbythedatasetisignored.Thenecessityofsuchspatio-\n\ntemporalpathpriorisillustratedinFigure\n1.Ifavehicle\nisobservedatbothcamera\nAandC\n,thesamevehiclehas\ntoappearatcamera\nB\naswell.Therefore,givenapairof\nvehicleimagesatlocation\nAandC\n,ifanimagewithsim-\nilarappearanceisneverobservedatcamera\nB\nataproper\ntime,theirmatchingshouldbeverylow.\nInthispaper,weproposetoutilizesuchspatio-temporal\npathinformationtosolvetheproblem.Themaincontribu-\n\ntionofourmethodistwo-fold.(1)Weproposeatwo-stage\n\nframeworkforvehicleItproposes\n\naseriesofcandidatevisual-spatio-temporalpathswiththe\n\nqueryimagesasthestartingandendingstates.Inthesec-\n\nondstage,aSiamese-CNN+Path-LSTMnetworkisutilized\n\ntodeterminewhethereachquerypairhasthesamevehi-\n\ncleidentitywiththespatio-temporalregularizationfromthe\n\ncandidatepath.Inthisway,allthevisual-spatio-temporal\n\nstatesalongthecandidatepathareeffectivelyincorporated\n\ntoestimatethevalidnessofthepath.Such\n\ninformationisforthetimeexploredforvehiclere-\n\n(2)Toeffectivelygeneratevisual-spatio-\n\ntemporalpathproposals,wemodelthepathsbychainMRF,\n\nwhichcouldbeoptimizedefbythemax-sumalgo-\n\nrithm.Adeepneuralnetworkisproposedtolearnthepair-\n\nwisevisual-spatio-temporalpotentialfunction.\n\n2.RelatedWorks\nVehicler\nBecauseofthequickad-\nvancesofpersonapproaches,vehiclere-\n\nstartedtogainattentionsinrecentyears.Feris\n\netal\n.[\n10]proposedanapproachonattribute-basedsearch\nofvehiclesinsurveillancescenes.Thevehiclesareclassi-\n\nbydifferentattributessuchascartypesandcolors.The\n\nretrievalisthenconductedbysearchingvehicleswithsimi-\n\nlarattributesinthedatabase.Dominik\netal\n.[\n45]utilized3D\nboundingboxesforrectifyingcarimagesandthenconcate-\n\nnatedcolorhistogramfeaturesofpairsofvehicleimages.\n\nAbinarylinearSVMistrainedtoverifywhetherthepair\n\nofimageshavethesameidentityornot.Liu\netal\n.[\n27,28]proposedavehicledatasetVeRi-776with\n\nalargenumberofcarscapturedby20camerasinaroad\n\nnetwork.Vehicleappearances,spatio-temporalinformation\n\nandlicenseplatesareindependentlyusedtolearnthesim-\n\nilarityscoresbetweenpairsofimages.Fortheappearance\n\ncues,adeepneuralnetworkisusedtoestimatethevisual\n\nsimilaritiesbetweenvehicleimages.Othervehiclerecog-\n\nnitionalgorithmsmainlyfocusedoncarmodel\n\n[\n35,26,42]insteadofidentifyingthevehicles\nwiththesameordifferentidentities.\nDeepneuralnetworks.\nInrecentyears,convolutional\ndeepneuronnetworkshaveshowntheireffectivenessin\n\nlarge-scaleimage[\n22],objectdetection[\n23]andvisualrelationshipdetection[\n25].Forsequentialdata,\nthefamilyofRecurrentNeuralNetworksincludingLong-\n\nShortTermMemoryNetwork(LSTM)[\n14]andGatedRe-\ncurrentNeuralNetwork[\n4]haveachievedgreatsuccess\nfortasksincludingimagecaptioning[\n18],speechrecogni-\ntion[\n11],visualquestionanswering[\n2],personsearch[\n24],immediacyprediction[\n5],video[\n44]and\nvideodetection[\n17].TheseworksshowthatRNNisable\ntocapturethetemporalinformationinthesequentialdata\n\nandlearneffectivetemporalfeaturerepresentations,which\n\ninspiresustouseLSTMnetworkforlearningfeaturerepre-\n\nsentationsforclassifyingvisual-spatio-temporalpaths.\nPersonr\nPersonis\nachallengingproblemthatdrawsincreasingattentionin\n\nrecentyears[\n1,3,12,37].State-of-the-artpersonre-\nmethodsadopteddeeplearningtechniques.\n\nAhmedetal\n.[\n1]designedapairwisevCNN\nmodelforpersonwithapairofcropped\n\npedestrianimagesasinputandemployedabinaryv\n\ntionlossfunctionfortraining.Xiao\netal\n.[\n40,41]trained\nCNNwithlosstolearnthedeepfeatureofper-\n\nson.Ding\netal\n.[\n8]andCheng\netal\n.[\n3]trainedCNNwith\ntripletsamplesandminimizedfeaturedistancesbetweenthe\n\nsamepersonandmaximizethedistancesbetweendifferent\n\npeople.Besidesthefeaturelearning,alargenumberofmet-\n\nriclearningmethodsforpersonwerealso\n\nproposed[\n34,32,21,38,43].Forperson\ninmulti-camerasystem,Hamdoun\netal\n.[\n12]proposedan\napproachthatmatchessignaturesbasedoninterest-points\n\ndescriptorscollectedonshortvideosequencesforperson\n\nschemeinmulti-camerasurveillancesys-\n\ntems.Spatio-temporalrelations.\nSpatio-temporalrelations\narewidelyexploitedforobjectsassociationinmulti-camera\n\nsystems[\n12,39,7,19,16,9,33],Ellis\netal\n.[\n9]presented\namethodtolearnboththetopologicalandtemporaltran-\n\nsitionsfromtrajectorydatawhichareobtainedindepen-\n\ndentlyfromsingleviewtargettrackinginamulti-camera\n\nnetwork.Neumann\netal\n.[\n33]presentedanapproachthat\ncombinesthestructureandmotionestimationina\n\nframeworktorecoveranaccurate3Dspatio-temporalde-\n\nscriptionofanobject.Loy\netal\n.[\n29]proposedanapproach\nformulti-cameraactivitycorrelationanalysiswhichesti-\n\nmatesthespatialandtemporaltopologyofthecameranet-\n\nwork.\n\n3.Approach\nForvehicleionwithcomputervision,cam-\nerasinaroadnetworkareneededtocaptureimagesof\n\npassing-byvehicles.Duetofactorsincludinginappropri-\n\natecameraviewpoints,lowresolutionoftheimagesand\n\nmotionblursofvehicles,carplateinformationmightnot\n\nalwaysbeavailableforsolvingthetask.Givenapairof\n\nvehicleimageswiththeirspatio-temporalinformation,the\n\nsimilarityscorebetweenthetwovehicleimagesisneeded\n\ntodeterminewhetherthetwoimageshavethesameiden-\n\ntity.Eachimageisassociatedwiththreetypesofinforma-\n\ntion,i.e.,visualappearance,thetimestamp,andthegeo-\n1901\n'b'!"#$%&%\'())\'*+,\'\n-#",."&%\'!"$"/#,"01\n2!34\n!"#$%&\n\'#(%)"*\n\')+,(*-%&.\n/-*(*#%&\n(#56"6#0%\'!7#0"#/\'-#08&\n-#08\'-,+7+&#/\'9%5%,#0"+5\n(/#&&"*":#0"+5\'."08\n-#08\';%<=/#,">#0"+5\nFigure2:Illustrationoftheoverallframework.Givenapairofvehicleimages,thevisual-spatio-temporalpathproposalis\n\ngeneratedbyoptimizingachainMRFmodelwithadeeplylearnedpotentialfunction.Thepathproposalisfurthervalidated\n\nbythePath-LSTMandregularizesthesimilarityscorebySiamese-CNNtoachieverobustperformance.\n\nlocatoinofthecamera.Wecallsuchinformationthe\nvisual-spatio-temporalstate\nofthevehicleimages.Ourproposed\napproachtakestwovisual-spatio-temporalstatesasinput\n\nandoutputstheirsimilarityscorewithatwo-stageframe-\n\nwork,whichisillustratedinFigure\n2.Instage1,insteadof\njustconsideringthesimplepairwiserelationsbetweentwo\n\nqueries,ourproposedapproachgeneratesacandidate\n\nvisual-spatio-temporalpathwiththetwoqueriesasstarting\n\nandendingstates.Instage2,thecandidatevisual-spatio-\n\ntemporalpathactsasregularizationpriorsandaSiamese-\n\nCNN+path-LSTMnetworkisutilizedtodeterminewhether\n\nthequerieshavethesameidentity.\n\n3.1.Vpathproposals\nGivenapairofqueries,existingvehicleorpersonre-\nalgorithmsmainlyconsidersthepairwisere-\n\nlationsbetweenthequeries,\ne.g\n.,thecompatibilityofthe\nvisualappearancesandspatio-temporalstatesofthetwo\n\nqueries.AsillustratedinFigure\n1,suchpairwiserelations\nareusuallyoverandcannoteffectivelydistin-\n\nguishdifcasesinpractice.Thevisual-spatio-temporal\n\npathinformationcouldprovidevitalinformationforachiev-\n\ningmorerobustTheproblemofiden-\n\ntifyingcandidatevisual-spatio-temporalpathsismodeled\n\naschainMarkovRandomFields(MRF).Givenapairof\n\nqueries,candidatespatialpathsarewiththe\n\ntheirgeo-locationsasstartingandendinglocations.The\n\nvisual-spatio-temporalstatesalongthespatialpathsarethen\n\noptimizedwiththedeeplylearnedpairwisepotentialfunc-\n\ntiontogeneratecandidatevisual-spatio-temporalpaths.\nToobtaincandidatespatialpathsforapairofstartingand\nendinglocations,allpossiblespatialpathsthatthesameve-\n\nhiclehaspassedbyarecollectedfromthetrainingset.For\n\nalargeroadnetwork,themultiplecandidatespatialpaths\n\nbetweeneverypairoflocationscouldbepre-collected.\n3.1.1ChainMRFmodelforvisual-spatio-temporal\npathproposal\nFromthesetofcandidatespatialpaths,ourapproachpro-\n\nposesonecandidatevisual-spatio-temporalpathforregu-\n\nlarizingthevehicleonresult.Theproblemof\n\nidentifyingvisualandtemporalstatesalongthecandidate\n\nspatialpathsismodeledasoptimizingchainMRFmodels.\nLetN\ndenotethenumberofcamerasonacandidatespa-\ntialpath,whereeachofthe\nN\ncamerasisassociatedwith\noneoftherandomvariables\nX\n=\nfX\n1\n;X\n2\n;\n\n;X\nN\ngonachainMRFmodel.Forthe\ni\n-thrandomvariable(cam-\nera)X\ni\n,itsdomainisthesetofall\nk\nvisual-spatio-temporalstates(all\nk\nimageswiththeirspatio-temporalinforma-\ntion)atthiscamera,\nS\ni\n=\nfs\ni;\n1\n;\n\n;s\ni;k\ng,where\ns\ni;j\n=fI\ni;j\n;t\ni;j\n;l\ni\ngisatripletofthe\nj\nthvisualimageatthe\ni\nthcamera,itstimestamp\nt\ni;j\n,andthecameralocation\nl\ni\n.Letp\nandq\nrepresentthevisual-spatio-temporalstates\nofthetwoqueries.Obtainingtheoptimalvisual-spatio-\n\ntemporalpathbasedonacandidatespatialpathcanbe\n\nachievedbymaximizingthefollowingdistribution,\np\n(\nx\nj\nx\n1\n=\np;x\nN\n=\nq\n)=\n1Z\n \n(\np;x\n2\n)\n \n(\nx\nN\n\n1\n;q\n)\nN\n\n2\nY\ni\n=2\n \n(\nx\ni\n;x\ni\n+1\n)\n;\n(1)where \n(\nx\ni\n;x\ni\n+1\n)\nisthepairwisepotentialfunctionof\nx\ni\nandx\ni\n+1\nbeingofthesamecar.Ideally,if\nx\ni\nandx\ni\n+1\nde-notethestateswiththesamevehicleidentity,aproperpo-\n\ntentialfunctionwouldhavealargevalue,whilesmalloth-\n\nerwise.The\n \nfunctionislearnedasadeepneuralnetwork\nandisintroducedindetailsinthenextsubsection.\nTheaboveprobabilityneedstobemaximizedwith\n1902\n'b'propertimeconstraints,\nx\n\n=argmax\nx\np\n(\nx\nj\nx\n1\n=\np;x\nN\n=\nq\n)\n;\n(2)subjectto\nt\ni;k\n\ni\n\nt\ni\n+1\n;k\n\ni\n+1\n8\ni\n2f\n1;\n\n;N\n\n1g;\n(3)wherek\n\ni\nandk\n\ni\n+1\nrepresenttheindicesoftheoptimal\nvisual-spatio-temporalstatesfor\nx\ni\nandx\ni\n+1\n,respectively.\nTheaboveconstraintsstatethattheobtainedvisual-spatio-\n\ntemporalpathmustbefeasibleintime,\ni.e.,thetimestamps\nofvehicleimagesmustbekeepincreasingalongthepath.\nThedistributioncanbeefoptimizedbythemax-\nsumalgorithm,whichisequivalenttodynamicprogram-\n\nmingforchainmodels[\n6].Themaximumoftheprobability\ncanbewrittenas,\nmax\nx\np\n(\nx\nj\nx\n1\n=\np;x\nN\n=\nq\n)\n(4)=\n1Z\n \n(\np;x\n2\n)\n \n(\nx\nN\n\n1\n;q\n)max\nx\n2\n\nmax\nx\nN\n\n1\nN\n\n1\nY\ni\n=2\n \n(\nx\ni\n;x\ni\n+1\n)\n(5)=\n1Z\nmax\nx\n2\n\n \n(\np;x\n2\n)\n \n(\nx\n2\n;x\n3\n)\n\n\nmax\nx\nN\n\n1\n \n(\nx\nN\n\n1\n;x\nq\n)\n\n\n\n(6)Afterobtainingtheoptimalstateforeachrandomvari-\nable(camera)onthecandidatespatialpath,thecandidate\n\nvisual-spatio-temporalpathisgenerated.\nForapairofqueries,multiplecandidatevisual-spatial-\ntemporalpathsareobtained.weanempiricalaver-\n\nagedpotentialfortheoptimedsolutionofeachcandidate\n\npath,\nS\n(\nx\n\n)=\n1N\n\n1 \n \n(\np;\n2)+\nN\n\n2\nX\ni\n=2\n \n(\nx\n\n\ni\n;x\n\n\ni\n+1\n)+\n \n(\nx\n\n\nN\n\n1\n;q\n)\n!\n;\n(7)where1=(\nN\n\n1)\nnormalizestheoverallforcan-\ndidatevisual-spatio-temporalpathswithdifferentlengths.\n\nThenwechoosethevisual-spatio-temporalproposalamong\n\nthecandidatepaths.\nForeverypairofqueries,eveniftheydonothavethe\nsameidentity,theproposedalgorithmalwaystriestogener-\n\natethemostfeasiblepathintermsofbothvisualandspatio-\n\ntemporalcompatibilitybetweenneighboringcamerasasthe\n\npathproposals.Someexamplesofthecandidatevisual-\n\nspatio-temporalpathsareshowninFigure\n3.Forefy,whengeneratingvisual-spatio-temporal\npathsforallstatepairsinthedataset,ourmethodutilizes\n\nasystematicwaytoavoidredundantcomputation.Forin-\n\nstance,supposecameras\nAandC\nhavetwopossiblepaths\nA\nB\n1\n\nC\nandA\nB\n2\n\nC\n.Whencalculatingpathpro-\nposalsbetweenqueriesoncameras\nAandC\n,thesub-paths\nA\nB\n1\nandA\nB\n2\narealsocomputedduringthecomputa-\ntionprocess,andcanbereusedbyotherquerieson\nA\nB\n1\nandA\nB\n2\n.Thedetailsoftimecomplexityanalysiswill\nbeintroducedinSection\n4.4.!"!!#!$"!!%!"#$%&"\'()*\'+,\n-$."*\'/0*11*++\n23.*/,\n!"#$%&"\'()*\'+,\n-$."*\'/0*11*+4\n23.*/5\n!"#$%&"\'()*\'+,\n-$."*\'/0*16*7/\n23.*7/\n!"#$%&"\'()*\'+,\n-$."*\'/0*16*,5\n23.*7,\n!"#$%&"\'()*\'+,\n-$."*\'/0*16*+/\n23.*//\n!"#$%&"\'()*\'+,\n-$."*\'/0*16*+6\n23.*/7\n!"#$%&"\'()*\'+,\n-$."*\'/0*16*+/\n23.*70\nFigure3:Anexamplevisual-spatio-temporalpathproposal\n\nontheVeRidataset[\n28]byourchainMRFmodel.\n!"#$"%\n!"#$"%\n&"\'%()"#\n*+#(\',-\n.+/+,\')+%0\n!"#$"%&\n123\n.4\'%+5%"/45)\',-\n.+/+,\')+%0\nFigure4:ASiamese-CNNislearnedasthepairwisepoten-\n\ntialfunctionforthechainMRFmodel,whichtakesapair\n\nofvisual-spatio-temporalstatesasinputsandestimatestheir\n\npairwisesimilarity.\n\n3.1.2Deepneuralnetworksaspairwisepotentialfunc-\ntionsThepairwisepotentialfunction\n \n(\nx\ni\n;x\ni\n+1\n)\nin(\n1)evaluates\nthecompatibilitybetweentwovisual-spatio-temporalstates\n\nforneighboringrandomvariables\nx\ni\nandx\ni\n+1\n.Welearnthe\npotentialfunction\n \nasatwo-branchdeepneuralnetwork,\nwhosestructureisillustratedinFigure\n4.Thevisualbranch\nandspatio-temporalbranchestimatepairwisecompatibility\n\nbetweenpairwisevisualandspatio-temporalstates.\nThevisualbranch(Siamese-Visual)isdesignedasa\nSiamesenetworkwithasharedResNet-50[\n13].Ittakes\ntwoimages\nI\ni;k\nandI\ni\n+1\n;j\natcameras\nx\ni\nandx\ni\n+1\nasin-\nputsandutilizesfeaturesfromtheglobalpoolinglayers\n\ntodescribetheirvisualappearances.Thevisualsimilarity\n\nbetweenthetwoimagesiscomputedastheinner-product\n\nofthetwoglobalpoolingfeaturesfollowedbyasigmoid\n\nfunction.Theotherbranchcomputesthespatio-temporalcompat-\nibility.Giventhetimestamps\nft\ni;k\n;t\ni\n+1\n;j\ngandthetwogeo-\nlocationsfl\ni\n;l\ni\n+1\ngofatcameras\ni\nandi\n+1\n,theinputfea-\nturesofthebrancharecalculatedastheirtimedifference\n\nandspatialdifference,\n\nt\ni;i\n+1\n(\nk;j\n)=\nt\ni\n+1\n;j\n\nt\ni;k\n;\n(8)\nd\ni;i\n+1\n=\nj\nl\ni\n+1\n\nl\ni\nj\n;\n(9)1903\n'b'!"##!"#$!"#%\n!"$#!"##&\'()*+\',-.\n/,!01)2\'/,34/55/5!\n&\'()*+\',-.\n/,!01)2\'/,34/54/!3\n&\'()*+\',-.\n/,33%\n1)2\'/,34/5#/65\n&\'()*+\',-.\n/,33%\n1)2\'/,34/5#/5!\n&\'()*+\',-.\n/,!01)2\'/,34/54/53\n&\'()*+\',-.\n/,!01)2\'/,34/5$/3!\n78)9:);\',\n\n<=>\'?>)8+\n(a)Invalidpath.Empiricalaveragedpotential:0.946\n!"#$!"#!!"#%\n&\'()*+\',-.\n/,!$0)1\'/,23/44/4!\n&\'()*+\',-.\n/,!$0)1\'/,23/43/!5\n&\'()*+\',-.\n/,!$0)1\'/,23/43/%!\n&\'()*+\',-.\n/,!$0)1\'/,23/46/$!\n78)9:);\'\n<=>\'?>)8+\n(b)Validpath.Empiricalaveragedpotential:0.916\nFigure5:Examplesofempiricalaveragedpotentialfavor-\n\ninglongerpaths.Theinvalidlongerpathin(a)hasahigher\n\naveragedpotentialthanthevalidpathin(b).\n\nwheret\ni;k\ndenotesthetimestampofthe\nk\n-thstate\natcamera\ni\n.Thescalarspatio-temporalcompatibil-\nityisobtainedbyfeedingtheconcatenatedfeatures,\n\n[\nt\ni;i\n+1\n(\nk;j\n)\n;\n\nd\ni;i\n+1\n]\nT\n,intoaMulti-LayerPerception\n(MLP)withtwofully-connectedlayersandaReLUnon-\n\nlinearityfunctionafterthelayerandasigmoidfunction\n\nafterthesecondlayer.\nTheoutputsofthetwobranchesareconcatenatedandin-\nputintoa\n2\n1fully-connectedlayerwithasigmoidfunc-\ntiontoobtainthecompatibilitybetweenthetwostates,\n\nwhichtakesallvisual,spatialandtemporalinformationinto\n\nconsideration.Fortrainingthepairwisepotentialnetwork,Siamese-\nCNN,wepretraintheResNet-50networktoclassify\n\nvehicleidentitywiththecross-entropyloss\n\nfunction.Allpairsofvisual-spatio-temporalstatesatneigh-\n\nboringrandomvariables(cameras)arethencollectedfor\n\nthewholenetwork.Ifapairhasthesamevehi-\n\ncleidentities,theyaretreatedaspositivesamples,whilethe\n\npairswithdifferentidentitiesaretreatedasnegativeones.\n\nThepositive-to-negativesamplingratioissetto1:3.The\n\ntwo-branchnetworkistrainedwitha0-1cross-entropyloss\n\nfunctionandstochasticgradientdescent.\n\n3.2.forquerypair\nOurproposedcandidatevisual-spatio-temporalpathpro-\nposalalgorithmgeneratesthemostfeasiblepathforeach\n\nquerypair,eveniftheydonothavethesameidentity.One\n\nnaivesolutionofrankingthesimilaritiesofquerypairs\n\nwouldbedirectlytreatingtheirmaximumprobability(Eq.\n\n(1))ortheempiricalaveragedpotential(Eq.(\n7))asthe\nsimilarityscoresforranking.However,therearelimitations\n\nwheneitherofthestrategiesisadopted.Forcalculatingthe\n\nmaximumprobabilityinEq.(\n1),thepartitionfunction\nZ\nneedstobecalculated,whichisgenerallytime-consuming.\n\nFortheempiricalaveragedpotentialinEq.(\n7),itisbiased\nandwouldfavorlongerpaths.Anexmapleisillustratedin\n\nFigure5.Giventwopairsofnegativequerieswithdifferent\npathlengths,sincethepathproposalalgorithmtriestogen-\n\neratemostfeasiblepathsforbothpairs,theremightbeonly\n!"#$\n%&\'()*\n+&,,-.-/0-\'\n"1)2&3\n42-513.)*\n+&,,-.-/0-\'\n!"#$\n6-)2(.-\n758-99&/:\n!"#!"$%\n#!"$&\n#!"$\'\n#!"#$\nFigure6:ThenetworkstructureofthePath-LSTM.Ittakes\n\nvisualandspatio-temporaldifferencesofneighboringstates\n\nalongthepathproposalasinputs,andestimatesthepath\n\nvalidnessscore.\n\noneidentityswitchalongeachpath.Theempiricalaveraged\n\nforthelongerpathwouldbehigherbecausethe\n\nlowpairwisewouldbediminishedbyalarger\n\nN\n.Givenapairofqueries,weutilizetheircandidatevisual-\nspatio-temporalpathaspriorstodeterminewhetherthe\n\nquerypairhasthesameidentityornotwithaSiamese-\n\nCNN+path-LSTMnetwork.Thenetworkstructureisillus-\n\ntratedinFigure\n6.wheretheSiamese-CNNhasthesame\nstructureastheoverallnetworkinSection\n3.1.2.Itdirectly\ntakesthequerypairasinputandestimatesthesimilaritybe-\n\ntweenthequeries.\nForthecandidatevisual-spatio-temporalpath,apath-\nLSTMisadoptedtojudgewhetherthepathisvalidor\n\nnot.Theframeworkofpath-LSTMnetworkisshownin\n\nFigure6.Eachstepofthepath-LSTMprocessesastep\nalongthecandidatepathandthelengthoftheLSTMis\n\nthereforeN\n\n1.Ateachstep,theinputfeaturesofthe\npath-LSTM,y\ni\n,istheconcatenationofvisualdifference\n\nI\n\ni;i\n+1\n,spatialdifference\n\nd\n\n\ni;i\n+1\n,andtemporaldiffer-\nence\nt\n\n\ni;i\n+1\nbetweenthevisual-spatio-temporalstatesat\ncamerasi\nandi\n+1\n,followedbyafully-connectedlayer\nwith32outputneuronsandaReLUnon-linearityfunction,\n\ni.e.,y\ni\n=\nf\n([\nI\n\n\ni;i\n+1\n;\n\nd\n\n\ni;i\n+1\n;\n\nt\n\n\ni;i\n+1\n]\nT\n)\n,where\nf\ndenotesthefeaturetransformationbythefully-connectedlayer.\nGiventhevisual-spatio-temporalstatesonthecandidate\npath,theimage\nI\ni;k\ni\nanditsassociatedtimestamp\nt\ni;k\ni\nisedatcamera\ni\n,where\nk\n\ni\ndenotestheoptimizedindex\nofthevisual-spatio-temporalstate.Thevisualdifference\n\n\nI\n\n\ni;i\n+1\niscalculatedasabsolutedifferencebetweenthevi-\nsualfeaturesof\nI\ni;k\ni\nandI\ni\n+1\n;k\ni\n+1\n,whichareobtainedas\ntheResNet-50globalpoolingfeaturesfollowedbya32-\n\nneuronfully-connectedlayerandaReLUfunction,\n\nI\n\n\ni;i\n+1\n=\n\n\n\n\n\nR\n\nI\ni;k\ni\n\n\nR\n\nI\ni\n+1\n;k\ni\n+1\n\n\n\n\n\n\n;\n(10)whereR\ndenotesthefeaturetransformationfortheinput\nimages.Thespatialdifference\n\nd\ni;i\n+1\niscalculatedas\n\nd\ni;i\n+1\n=\nl\ni\n+1\n\nl\ni\n,andthetemporaldifferenceis\n\nt\ni;i\n+1\n=\nt\ni\n+1\n;k\ni\n+1\n\nt\ni;k\ni\n:\n(11)1904\n'b"TheLSTMconsistsofamemorycell\nc\nt\nandthreecon-\ntrolgates:inputgate\nig\n,outputgate\nog\nandforgetgate\nfg\nateachtimestep\nt\n.Withtheinputfeature\ny\nt\n,TheLSTM\nupdatesthememorycell\nc\nt\nandhiddenstate\nh\nt\nwiththefol-\nlowingequations,\nfg\nt\n=\n\n(\nW\nf\n\n[\nh\nt\n\n1\n;y\nt\n])+\nb\nf\n)\n(12)ig\nt\n=\n\n(\nW\ni\n\n[\nh\nt\n\n1\n;y\nt\n])+\nb\ni\n)\n(13)og\nt\n=\n\n(\nW\no\n\n[\nh\nt\n\n1\n;y\nt\n])+\nb\no\n)\n(14)~c\nt\n=tanh(\nW\nc\n\n[\nh\nt\n\n1\n;y\nt\n]+\nb\nc\n)\n(15)c\nt\n=\nfg\nt\nc\nt\n\n1\n+\nig\nt\n~c\nt\n(16)h\nt\n=\nog\nt\ntanh(\nc\nt\n)\n(17)whererepresentstheelement-wisemultiplication,\nW\nandb\naretheparameters.\nThenumberofhiddenneuronsofourPath-LSTMisset\nto32.ThehiddenfeatureofthePath-LSTMatthelaststep\n\nisfedintoafully-connectedlayertoobtainthevalid-path\n\nscore,whichisaddedwiththepairwisesimilar-\n\nityscoregeneratedbytheSiamese-CNNtorepresentthe\n\nsimilarityscore.Inthisway,thePath-LSTMprovides\n\nimportantregularizationforestimatingmatchingsim-\n\nilarity.\nBoththeSiamese-CNNandPath-LSTMarepretrained\nseparatelyandthenjointly.Theirtrainingsam-\n\nplesarepreparedsimilarlytothoseforlearningthepairwise\n\npotentialfunctioninSection\n3.1.2.However,thetraining\nsamplesherearenolongerrestrictedtoonlyvisual-spatio-\n\ntemporalstatesfromneighboringcamerasbutfromany\n\ncamerapairintheentirecameranetwork.ThePath-LSTM\n\nispretrainedwiththeAdamalgorithm[\n20].Thewhole\nSiamese-CNN+Path-LSTMnetworkistheninan\n\nend-to-endmannerwithstochasticgradientdescentand0-1\n\ncross-entropylossfunction.\n\n4.Experiments\n\n4.1.Datasetandevaluationmetric\nForevaluatingtheeffectivenessofourvehiclere-\nframework,weconductexperimentsonthe\n\nVeRi-776dataset[\n28],whichistheonlyexistingvehiclere-\ndatasetprovidingspatialandtemporalannota-\n\ntions.TheVeRi-776datasetcontainsover50,000imagesof\n\n776vehicleswithidentityannotations,imagetimestamps,\n\ncamerageo-locations,licenseplates,cartypesandcolors\n\ninformation.Eachvehicleiscapturedby2to18camerasin\n\nanurbanareaof1\nkm\n2\nduringa24-hourtimeperiod.The\ndatasetissplitintoatrainsetconsistingof37,781imagesof\n\n576vehicles,andatestsetof11,579imagesbelongingto\n\n200vehicles.Asubsetof1,678queryimagesinthetestset\n\nareusedastoretrievecorrespondingimagesfromallother\n\ntestimages.\nThemeanaverageprecision(mAP),top-1accuracyand\ntop-10accuracyarechosenastheevaluationmetric.Given\n\neachqueryimageinthetestimagesubsetforretrieving\n\nothertestimages,theaverageprecisionforeachquery\nq\niscalculatedby\nAP(\nq\n)=\nP\nn\n\nk\n=1\nP(\nk\n)\n\nrel\n(\nk\n)\nN\ngt\n(18)whereP(\nk\n)\ndenotestheprecisionatcut-off\nk\n,rel\n(\nk\n)\nisanindicationfunctionequaling1iftheitematrank\nk\nisamatchedvehicleimage,zerootherwise,\nn\nisthenumber\nforretrieval,and\nN\ngt\ndenotesthenumberofgroundtruth\nretrievalsforthequery.Themeanaverageprecisionforall\n\nqueryimagesisthencalculatedby\nmAP=\nP\nQ\n\nq\n=1\nAP(\nq\n)\nQ\n;\n(19)whereQ\nisthenumberofallqueries(1,678forthedataset).\nFollowingtheexperimentalsetupinLiu\netal\n.[\n28],foreach\nqueryimage,onlyimagesofthesamevehiclesfromother\n\ncameraswouldbetakenintoaccountforcalculatingthe\n\nmAP,top-1andtop-5accuracies.\nSinceourproposedmethodgeneratesonevisual-spatio-\ntemporalcandidatepathforeachpairofqueryimages,we\n\ncanextendtheevaluationmetricstothewholesequence\n\nofimages.Foreverypairofqueryimagesthathavethe\n\nsamevehicleidentity,weobtainthevehicle'sactualvisual-\n\nspatio-temporalpathandcompareitwithourcandidatepath\n\nusingJaccardSimilarity[\n15],JS\n(\nPp\n;P\ng\n)=\nPp\n\\\nPg\nPp\n[\nPg\n;\n(20)wherePp\nisthesetofretrievedimagesontheproposalpath\nbetweenthequerypair,and\nPg\nisthesetofthegroundtruth\nimagesbetweenthem.WefurthertheaverageJac-\n\ncardSimilarityforallqueryimages,\nAJS\n(\nPp\n;P\ng\n)=\n1Q\nQ\nX\nq\n=1\nPp\nq\n\\\nPg\nq\nPp\nq\n[\nPg\nq\n:\n(21)4.2.ComparedWithVehiclemethods\nWecompareourproposedapproachwiththestate-of-\nthe-artmethods[\n27,28]anddesignseveralbaselinesonthe\nVeRi-776datasettoevaluatetheeffectivenessofourpro-\n\nposedmethod.\nSiamese-CNN+Path-LSTM\ndenotesourapproach\nwhichtakespairsofqueryvisual-spatio-temporal\n\nstatesforSiamese-CNNandproposedvisual-spatio-\n\ntemporalpathforthePath-LSTMtogeneratethe\n\nsimilarityscore.Notethatourapproachdidnotutilize\n\ntheplateinformationintheimagesasthatin[\n28].FACT\nandFACT+Plate-SNN+STR.\nLiuetal\n.[\n27]pro-\nposedtheFACTmodelthatcombinesdeeplylearned\n\nvisualfeaturefromGoogleNet[\n36],BOW-CNand\nBOW-SIFTfeaturetomeasureonlythevisualsimi-\n\nlaritybetweenpairsofqueryimages.In[\n28],they\nfurtherintegratedvisualappearance,plateandspatio-\n\ntemporalinformationforvehicle\n1905\n"b'Forappearancesimilarity,thesameFACTmodelis\n\nadopted.TheyutilizedaSiameseNeuralNetwork\n\n(Plate-SNN)tocomparevisualsimilaritybetween\n\nplateregions.Thespatio-temporalsimilarityiscom-\n\nputedas\nSTR\n(\ni;j\n)=\nj\nT\ni\n\nT\nj\nj\nT\nmax\n\n\n(\nC\ni\n\nC\nj\n)\nD\nmax\n;\n(22)whereT\ni\nandT\nj\narethetimestampsoftwoqueries,\n\n(\nC\ni\n;C\nj\n)\nisthespacedistancebetweentwocameras,\nandT\nmax\nandD\nmax\narethemaximumtimedistance\nandspacedistanceinthewholedataset.\nSiamese-Visual.\nThisbaselinegeneratesthesimilarity\nbetweenaquerypairwithonlypairwisevisualinfor-\n\nmationbyusingonlythevisualbranchoftheSiamese-\n\nCNNinSection\n3.2.Nospatio-temporalinformation\nisusedforobtainingthesimilarityscore.\nSiamese-Visual+STR.\nInsteadoflearningspatio-\ntemporalrelationsbydeepneuralnetworks,thisbase-\n\nlinesumsupthescoresbytheabove\nSiamese-Visual\nandthespatial-temporalrelationscore(STR,Eq.(\n22)proposoedin[\n28].Theweightbetweenthetwoterms\naremanuallysearchedforthebestperformance.\nSiamese-CNN.Thebaselineisthesameasthe\nSiamese-CNNinSection\n3.2.Comparedwiththe\nabovebaseline,itusesbothvisualandspatio-temporal\n\ninformationofthetwoqueriesfordeterminetheirsim-\n\nilarityscore.Candidatevisual-spatio-temporalpaths\n\narenotusedinthisbaseline.\nChainMRFmodel.\nAfterobtainingthecandidate\nvisual-spatio-temporalpathforaquerypairbythe\n\nchainMRFmodelinSection\n3.1.1,wedirectlyutilize\ntheempiricalaveragebyEq.(\n7)asthepairwisesimi-\nlarityofthequerypair.\nPath-LSTMonly.\nTheproposedPath-LSTMesti-\nmatethevalidnessscoreoftheproposedvisual-spatio-\n\ntemporalpath.WetestonlyusePath-LSTMresult\n\nwithoutcombiningitwiththeSiamese-CNN.\nSiamese-CNN-VGG16.ThisisthesameasSiamese-\nCNNbutonlyreplacesResNet50withVGG16.\nPath-LSTM-VGG16.\nThisisthesameasPath-LSTM\nbutonlyreplacesSiamese-CNNwithSiamese-CNN-\n\nVGG16.\nSiamese-CNN-VGG16+Path-LSTM-VGG16.\nThisis\nassameasSiamese-CNN+Path-LSTMbutonlyre-\n\nplacesResNet50withVGG16.\n4.3.ExperimentResults\nThemAP,top-1andtop-5accuraciesofmethodsare\nlistedinTables\n1and2.Figure\n7showstheCMCcurvesof\nthecomparedmethods.Examplevehicle\n\nresultsbyourapproachareshowninFigure\n8.MethodmAP(%)\nFACT[\n27]18.49FACT+Plate-SNN+STR[\n28]27.77Siamese-Visual\n29.48Siamese-Visual+STR\n40.26Siamese-CNN54.21ChainMRFmodel\n44.31Path-LSTM\n54.49Siamese-CNN-VGG16\n44.32Path-LSTM-VGG16\n45.56Siamese-VGG16+\nPathLSTM-VGG16\n46.85Siamese-CNN+Path-LSTM\n58.27Table1:mAPbycomparedmethodsontheVeRi-776\n\ndataset[\n28].Methodtop-1(%)\ntop-5(%)\nFACT[\n27]50.9573.48FACT+Plate-SNN+STR[\n28]61.4478.78Siamese-Visual\n41.1260.31Siamese-Visual+STR\n54.2374.97Siamese-CNN79.3288.92ChainMRFmodel\n54.4161.50Path-LSTM\n82.8989.81Siamese-CNN-VGG16\n54.4161.50Path-LSTM-VGG16\n47.7962.63Siamese-VGG16+\nPathLSTM-VGG16\n50.9561.62Siamese-CNN+Path-LSTM\n83.4990.04Table2:Top-1andtop-5accuraciesbycomparedmethods\n\nontheVeRi-776dataset[\n28].05101520253035404550\nRank0.40.50.60.70.80.91Matching RateSiamese-VisualSiamese-Visual + STRSiamese-CNNChain MRF modelpath-LSTMSiamese-CNN + path-LSTMFigure7:TheCMCcurvesofdifferentmethods.\nOurproposedtwo-stageapproach,\nSiamese-CNN+Path-\nLSTM,outperformsstate-of-the-artmethods[\n27,28]and\nallcomparedbaselines,whichdemonstratestheeffective-\n\nnessofouroverallframeworkandindividualcomponents.\n\nComparedwith\nSiamese-CNN,whichonlytakespairwise\nvisualandspatio-temporalinformationintoaccount,our\n\nnalapproachhasagainof\n4%\nintermsofmAPandtop-\n1accuracy.Suchaperformanceincreaseshowsthatthe\n\nPath-LSTMwithvisual-spatio-temporalpathproposaldoes\n1906\n'b'!"#$%&"\'()*\'+\n,-.\n*\'//\n0$."*/1*22*23\n!"#$%&"\'()*\'+,\n-./\n*\'01\n2$/"*13*43*43\nFigure8:Examplevehicleresults(top5)\n\nbyourproposedapproach.Thetruepositiveisingreenbox\n\notherwisered.ThethreerowsareresultsofSiamese-Visual,\n\nSiamese-CNNandSiamese-CNN+Path-LSTM.\n\nprovidevitalpriorsforrobustlyestimatingthevehiclesimi-\n\nlarities.Comparedwith\nPath-LSTMonly\n,whichonlycalcu-\nlatespath-validnessscoreswiththeproposedvisual-spatio-\n\ntemporalpath,ourapproachalsohasa\n4%\nincreasein\ntermsofmAPandtop-1accuracy.Thisisbecausetogen-\n\neratethecandidatepath,ourproposedchainMRFmodel\n\nalwaystriestodiscoverthemostfeasiblevisual-spatio-\n\ntemporalpath.Thevisual-spatio-temporalstatechanges\n\nalongthepathsmightsometimesbesubtleanddifto\n\nbecapturedbyonlypairwisedifferencesofstatesatneigh-\n\nboringcameras.Theobviousstatedifferencebetweenthe\n\nquerypaircansometimesbemoreeasilycapturedbythe\n\nSiamese-CNN.Therefore,the\nPath-LSTM\nactsasastrong\npriorforregularizingthe\nSiamese-CNNresultsandtheir\ncombinationshowsthebestretrievalperformance.\nComparedwiththe\nChainMRFmodel\n,the\nPath-LSTM\nhasa\n10%\nmAPgainandanincreaseof\n25%\ntop-1ac-\ncuracy.Suchresultsdemonstratethattheempiricalaver-\n\nageisnotarobustpath-validnessindicatorofthecandidate\n\npaths.Ourtrained\nPath-LSTM\nisabletocapturemoresub-\ntlestatechangesonthecandidatepathforestimatingcor-\n\nrectpath-validnessscores.Comparedwith\nSiamese-Visual\n,Siamese-CNNhasgainsonmAP(\n\n25%\n)and\ntop-1accuracy(\n\n40%\n).Itdemonstratesthat,unlikeper-\nsonthespatio-temporalinformationisvi-\n\ntalforvehiclewherethevisualdifferences\n\nbetweendifferentvehiclesmightbesubtleforvehicles\n\nwiththesamecolor.Comparedwith\nSiamese-Visual+STR\n,whichadoptsthespatio-temporalrelationscorein[\n28],ourSiamese-CNNachievesmoreaccurateretrievalperfor-\nmance.Ourdeepneuralnetworkisabletocapturemore\n\ncomplexspatio-temporalrelationsbetweenquerypairs.\nThePath-LSTMshowsstrongcapabilityonregularizing\ntheretrievalresultswithcandidatevisual-spatio-temporal\n\npaths.TheeffectivenessofPath-LSTMreliesonthecor-\nrectnessofthecandidatepaths.Ifthecandidatepathdoes\n\ncorrespondtotheactualpath,thePath-LSTMmighthave\n\nnegativeimpactonthesimilarityscore.Forallpairs\n\nofqueriesthathavethesamevehicleidentities,weobtain\n\ntheirground-truthvisual-spatio-temporalpathsandcom-\n\nparethemwithourproposedones.TheaveragedJaccard\n\nSimilarityiscalculated.OurproposedchainMRFmodel\n\nwithdeeplylearnedpotentialfunctionachievesanAJSof\n\n96.39%.WealsotestreplacingResNet50withVGG16inour\npipeline.Ourproposedoverallframework(Siamese-\n\nVGG16+PathLSTM-VGG16)andindividualcomponents\n\n(Path-LSTM-VGG16)outperformourVGG16baseline\n\n(Siamese-CNN-VGG16).\n\n4.4.TimeComplexityAnalysis\nIntheworstcase,allpairwisepotentialsneedtobecal-\nculated,resultingacomplexityof\nO\n(\nMK\n2\n)\n,where\nM\nisthenumberofedges(connectingneighboringcameras)in\n\nthecameranetwork,and\nK\nistheaveragenumberofstates\nateachcamera.Afterthat,thetimecomplexityofdynamic\n\nprogrammingforallpathproposalsisalso\nO\n(\nMK\n2\n)\n,which\nutilizesthetechniquedescribedinSection\n3.1.1toavoid\nredundantcomputation.Amortizedoverthetotalnumber\n\nofQ\nquerypairs,eachquerypairhasanaveragedtime\ncomplexityof\nO\n(\nMK\n2\n=Q\n)\n.Inpractice,fortesting,pair-\nwisescoresarecalculatedbetween19.4millionquerypairs\n\n(11579galleriesand1678queries).Becauseofoursys-\n\ntematicwayofavoidingredundantcomputation,eachquery\n\npaironlyrequires0.016sonaverage.\n\n5.Conclusions\nInthispaper,weproposedatwo-stageframework\nforvehiclewithbothvisualandspatio-\n\ntemporalinformation.Existingmethodsignoredorused\n\nlimitedspatio-temporalinformationforregularizingthere-\n\nresults.Ourproposedapproachincorporates\n\nimportantvisual-spatial-temporalpathinformationforreg-\n\nularization.AchainMRFmodelwithdeeplylearnedpair-\n\nwisepotentialfunctionisadoptedtogeneratevisual-spatio-\n\ntemporalpathproposals.Suchcandidatepathproposalsare\n\nevaluatedbyaSiamese-CNN+Path-LSTMtoobtainsimi-\n\nlarityscoresbetweenpairsofqueries.Theproposedap-\n\nproachoutperformsstate-of-the-artsmethodsontheVeRi-\n\n776dataset.Extensivecomponentanalysisofourframe-\n\nworkdemonstratestheeffectivenessofouroverallframe-\n\nworkandindividualcomponents.\nAcknowledgments.\nThisworkissupportedinpartby\nSenseTimeGroupLimited,inpartbytheGeneralResearch\n\nFundthroughtheResearchGrantsCouncilofHong\n\nKongunderGrantsCUHK14213616,CUHK14206114,\n\nCUHK14205615,CUHK419412,CUHK14203015,\n\nCUHK14239816,CUHK14207814,inpartbytheHong\n\nKongInnovationandTechnologySupportProgramme\n\nGrantITS/121/15FX,andinpartbytheChinaPostdoctoral\n\nScienceFoundationunderGrant2014M552339.\n1907\n'b'References\n[1]E.Ahmed,M.Jones,andT.K.Marks.Animproveddeep\nlearningarchitectureforpersonIn\nProceed-\ningsoftheIEEEConferenceonComputerVisionandPattern\n\nRecognition\n,pages39083916,2015.\n1,2[2]D.Bahdanau,K.Cho,andY.Bengio.Neuralmachine\ntranslationbyjointlylearningtoalignandtranslate.\narXivpreprintarXiv:1409.0473\n,2014.\n2[3]D.Cheng,Y.Gong,S.Zhou,J.Wang,andN.Zheng.Person\nbymulti-channelparts-basedcnnwithim-\n\nprovedtripletlossfunction.In\nProceedingsoftheIEEECon-\nferenceonComputerVisionandPatternRecognition\n,pages\n13351344,2016.\n1,2[4]K.Cho,B.VanMerri\nenboer,D.Bahdanau,andY.Bengio.\nOnthepropertiesofneuralmachinetranslation:Encoder-\n\ndecoderapproaches.\narXivpreprintarXiv:1409.1259\n,2014.\n2[5]X.Chu,W.Ouyang,W.Yang,andX.Wang.Multi-taskre-\ncurrentneuralnetworkforimmediacyprediction.In\nPro-\nceedingsoftheIEEEInternationalConferenceonComputer\n\nVision\n,pages33523360,2015.\n2[6]T.H.Cormen.\nIntroductiontoalgorithms\n.MITpress,2009.\n4[7]R.Cucchiara,A.Prati,andR.Vezzani.Amulti-cameravi-\nsionsystemforfalldetectionandalarmgeneration.\nExpertSystems,24(5):334345,2007.\n2[8]S.Ding,L.Lin,G.Wang,andH.Chao.Deepfea-\nturelearningwithrelativedistancecomparisonforperson\n\nPatternRecognition\n,48(10):29933003,\n2015.2[9]T.Ellis,D.Makris,andJ.Black.Learningamulti-camera\ntopology.In\nJointIEEEWorkshoponVisualSurveillance\nandPerformanceEvaluationofTrackingandSurveillance\n\n(VS-PETS),pages165171,2003.\n2[10]R.S.Feris,B.Siddiquie,J.Petterson,Y.Zhai,A.Datta,\nL.M.Brown,andS.Pankanti.Large-scalevehicledetec-\n\ntion,indexing,andsearchinurbansurveillancevideos.\nIEEETransactionsonMultimedia\n,14(1):2842,2012.\n1,2[11]A.GravesandN.Jaitly.Towardsend-to-endspeechrecog-\nnitionwithrecurrentneuralnetworks.In\nICML,volume14,\npages17641772,2014.\n2[12]O.Hamdoun,F.Moutarde,B.Stanciulescu,andB.Steux.\nPersonreinmulti-camerasystembysigna-\n\nturebasedoninterestpointdescriptorscollectedonshort\n\nvideosequences.In\nDistributedSmartCameras,2008.\nICDSC2008.SecondACM/IEEEInternationalConference\n\non,pages16.IEEE,2008.\n1,2[13]K.He,X.Zhang,S.Ren,andJ.Sun.Deepresiduallearn-\ningforimagerecognition.In\nProceedingsoftheIEEECon-\nferenceonComputerVisionandPatternRecognition\n,pages\n770778,2016.\n4[14]S.HochreiterandJ.Schmidhuber.Longshort-termmemory.\nNeuralcomputation\n,9(8):17351780,1997.\n2[15]P.Jaccard.\nEtudecomparativedeladistributionaledans\nuneportiondesAlpesetduJura\n.Impr.Corbaz,1901.\n6[16]O.Javed,K.Z.Rasheed,andM.Shah.Mod-\nelinginter-cameraspacetimeandappearancerelationships\n\nfortrackingacrossnon-overlappingviews.\nComputerVision\nandImageUnderstanding\n,109(2):146162,2008.\n2[17]K.Kang,H.Li,T.Xiao,W.Ouyang,J.Yan,X.Liu,and\nX.Wang.Objectdetectioninvideoswithtubeletproposal\n\nnetworks.In\nCVPR,2017.\n2[18]A.KarpathyandL.Fei-Fei.Deepvisual-semanticalign-\nmentsforgeneratingimagedescriptions.In\nProceedings\noftheIEEEConferenceonComputerVisionandPattern\n\nRecognition\n,pages31283137,2015.\n2[19]V.KettnakerandR.Zabih.Bayesianmulti-camerasurveil-\nlance.In\nComputerVisionandPatternRecognition,1999.\nIEEEComputerSocietyConferenceon.\n,volume2,pages\n253259.IEEE,1999.\n2[20]D.KingmaandJ.Ba.Adam:Amethodforstochasticopti-\nmization.arXivpreprintarXiv:1412.6980\n,2014.\n6[21]M.Koestinger,M.Hirzer,P.Wohlhart,P.M.Roth,and\nH.Bischof.Largescalemetriclearningfromequiva-\n\nlenceconstraints.In\nComputerVisionandPatternRecogni-\ntion(CVPR),2012IEEEConferenceon\n,pages22882295.\nIEEE,2012.\n2[22]A.Krizhevsky,I.Sutskever,andG.E.Hinton.Imagenet\nwithdeepconvolutionalneuralnetworks.In\n\nAdvancesinneuralinformationprocessingsystems\n,pages\n10971105,2012.\n2[23]H.Li,Y.Liu,W.Ouyang,andX.Wang.Zoomout-and-in\nnetworkwithrecursivetrainingforobjectproposal.\nCoRR,abs/1702.05711,2017.\n2[24]S.Li,T.Xiao,H.Li,B.Zhou,D.Yue,andX.Wang.Person\nsearchwithnaturallanguagedescription.In\nCVPR,2017.\n2[25]Y.Li,W.Ouyang,X.Wang,andX.Tang.Vip-cnn:Visual\nphraseguidedconvolutionalneuralnetwork.In\nCVPR,2017.\n2[26]H.Liu,Y.Tian,Y.Yang,L.Pang,andT.Huang.Deeprela-\ntivedistancelearning:Tellthedifferencebetweensimilarve-\n\nhicles.In\nProceedingsoftheIEEEConferenceonComputer\nVisionandPatternRecognition\n,pages21672175,2016.\n1,2[27]X.Liu,W.Liu,H.Ma,andH.Fu.Large-scalevehiclere-\ninurbansurveillancevideos.In\nMultimediaandExpo(ICME),2016IEEEInternationalConferenceon\n,pages16.IEEE,2016.\n1,2,6,7[28]X.Liu,W.Liu,T.Mei,andH.Ma.Adeeplearning-based\napproachtoprogressivevehicleforurban\n\nsurveillance.In\nEuropeanConferenceonComputerVision\n,pages869884.Springer,2016.\n1,2,4,6,7,8[29]C.C.Loy,T.Xiang,andS.Gong.Multi-cameraactivity\ncorrelationanalysis.In\nComputerVisionandPatternRecog-\nnition,2009.CVPR2009.IEEEConferenceon\n,pages1988\n1995.IEEE,2009.\n2[30]S.MahendranandR.Vidal.Carsegmentationand\nposeestimationusing3dobjectmodels.\narXivpreprint\narXiv:1512.06790,2015.\n1[31]B.C.Matei,H.S.Sawhney,andS.Samarasekera.Vehi-\ncletrackingacrossnonoverlappingcamerasusingjointkine-\n\nmaticandappearancefeatures.In\nComputerVisionandPat-\nternRecognition(CVPR),2011IEEEConferenceon\n,pages\n34653472.IEEE,2011.\n1[32]B.McFeeandG.R.Lanckriet.Metriclearningtorank.In\nProceedingsofthe27thInternationalConferenceonMa-\n\nchineLearning(ICML-10)\n,pages775782,2010.\n2[33]J.NeumannandY.Aloimonos.Spatio-temporalstereousing\nmulti-resolutionsubdivisionsurfaces.\nInternationalJournal\nofComputerVision\n,47(1-3):181193,2002.\n2[34]S.Paisitkriangkrai,C.Shen,andA.vandenHengel.Learn-\ningtorankinpersonwithmetricensembles.\n\nInProceedingsoftheIEEEConferenceonComputerVision\nandPatternRecognition\n,pages18461855,2015.\n21908\n'b'[35]J.Sochor,A.Herout,andJ.Havel.Boxcars:3dboxesascnn\ninputforimprovedvehiclerecognition.In\nPro-\nceedingsoftheIEEEConferenceonComputerVisionand\n\nPatternRecognition\n,pages30063015,2016.\n1,2[36]C.Szegedy,W.Liu,Y.Jia,P.Sermanet,S.Reed,\nD.Anguelov,D.Erhan,V.Vanhoucke,andA.Rabinovich.\n\nGoingdeeperwithconvolutions.In\nProceedingsoftheIEEE\nConferenceonComputerVisionandPatternRecognition\n,pages19,2015.\n7[37]X.Wang,G.Doretto,T.Sebastian,J.Rittscher,andP.Tu.\nShapeandappearancecontextmodeling.In\nComputerVi-\nsion,2007.ICCV2007.IEEE11thInternationalConference\n\non,pages18.IEEE,2007.\n2[38]K.Q.WeinbergerandL.K.Saul.Distancemetriclearning\nforlargemarginnearestneighbor\nJournalof\nMachineLearningResearch\n,10(Feb):207244,2009.\n2[39]F.Wu,S.Li,T.Zhao,andK.N.Ngan.Model-basedface\nreconstructionusingsiftwregistrationandsphericalhar-\n\nmonics.In\nPatternRecognition(ICPR),201623rdInterna-\ntionalConferenceon\n,pages17741779.IEEE,2016.\n2[40]T.Xiao,H.Li,W.Ouyang,andX.Wang.Learningdeep\nfeaturerepresentationswithdomainguideddropoutforper-\n\nsonIn\nProceedingsoftheIEEEConference\nonComputerVisionandPatternRecognition\n,pages1249\n1258,2016.\n2[41]T.Xiao,S.Li,B.Wang,L.Lin,andX.Wang.Jointdetec-\ntionandionfeaturelearningforpersonsearch.In\n\nCVPR,2017.\n2[42]L.Yang,P.Luo,C.ChangeLoy,andX.Tang.Alarge-scale\ncardatasetfor-grainedcategorizationandv\n\nInProceedingsoftheIEEEConferenceonComputerVision\nandPatternRecognition\n,pages39733981,2015.\n1,2[43]D.Yi,Z.Lei,S.Liao,andS.Z.Li.Deepmetriclearning\nforpersonIn\nPatternRecognition(ICPR),\n201422ndInternationalConferenceon\n,pages3439.IEEE,\n2014.2[44]J.Yue-HeiNg,M.Hausknecht,S.Vijayanarasimhan,\nO.Vinyals,R.Monga,andG.Toderici.Beyondshortsnip-\n\npets:DeepnetworksforvideoIn\nProceed-\ningsoftheIEEEconferenceoncomputervisionandpattern\n\nrecognition\n,pages46944702,2015.\n2[45]D.ZapletalandA.Herout.Vehicleforau-\ntomaticvideotrafsurveillance.In\nProceedingsofthe\nIEEEConferenceonComputerVisionandPatternRecog-\n\nnitionWorkshops\n,pages2531,2016.\n1,21909\n'